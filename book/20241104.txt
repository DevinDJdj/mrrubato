Lets try this again.  

add language tennis (-6,6)
--start here.  
Hmmmm... not working great.  
Also feedback is multiplied by the number of languages.  
Why is this occurring.  

Dont like the requirement for EOW.  
But this worked ok.  
add word hit 66,66,60,60
Maybe dont require this if we are using the pedal.  
pedal
add word hit 66,66
pass waspedaldown.  Yes this is better.  
Leave both options, shouldnt require pedal.  


analyze.html?video=mj4jpeBvD2o
change language (-6,6)
add word hit (6,6)
how do we have synonyms?  This would get overwritten
Could have something mimicing back and forth across net.  
add word backhand (6,1) 
add word forehand (6,3) 
add word slice (6,2)
add word topspin (6,4)
add word volley (6,8)
add word drop (6,10)
add word serve (10,11)

add word fault (10,9)
add word let (10,8)
add word out (5,5)
add word long (5,6)
add word net (5,4)
add word bounce (4,4)
add word applause (3,4)
add word noise (3,5)

add word score (2,2) (param = 3,4,5,6,7)
2,8 = minus point, 2,3 = plus point, 2,4 plus game, 2,5 plus set
2,9 = minus game, 2,10 minus set 



add word player one (9,8)
add word player two (9,10)
9,8 = set player 1
9,10 = set player 2

2,3,9,8 = player 1 gets point

In general should structure from left to right.  
So in this case player can be a prefix or a postfix.  
Structure should contain an element of distance.  


**web/public/analyze.html
Why are we crashing after leaving this up for significant period of time.  
Must be setTimeout stuff.  

Should we have iterations of feedback?  
Not sure how useful this is?  
We could put it into a different track with same language and then load multiple.  
Not sure I want to add this level of complexity at this point, but may regret not doing it.  

How do we leave a quick location stamp?  
We had already mentioned 
Bottom octave = B<->T
Top octave = L<->R

No need to use 0 here.  should be 1 based perhaps.  
0,24=BR
0,12=BL
12,24=TR
12,12=TL

TL = Center
Usually would start at center, and then go down on left hand
0,12 -> 12,24 BL->TR
0,24 -> 12,12 BR->TL
0,12 -> 12,12 BL->TL
0,24 -> 12,24 BR->TR

Standard Progression
12,12 -> 7,12 -> upper octave play 7, 15 8, 18... -> Perhaps back to 10,12

This is assuming the grid control methodology.  

Alternative would use time and vector methodology.  
Angle and distance.  
Perhaps same.  

Bottom octave = angle
Top octave = distance (exponential?)
12,12 = C
0,12 = C
0, 24 = 1,0
0,18 = 1/2,0
1,24 = sqrt(3)/2, -1/2
2,24 = 1/2, -sqrt(3)/2
3,24 = 0, -1
6,24 = -1,0
9,24 = 0,1
12,24 = 1,0

This is advantageous as we can use octave relationship as well then.  

Boxes will be better with the 

How good is eye-tracking technology?  
Do we want to use this instead?  I dont think so.  

So box = two consecutive in this sequence.  
Can do in any sequence, but must be 2 upper and 2 lower octave.  
First upper->first lower pair.  
So something like this would be common box with BOX numbers.  
9,20,8,18 for example.  Pick middle-top right area.  
Bottom octave has smaller.  
Maybe we should switch octaves.  Nah, already linguistically logical this way.  
Just not sure how distinct the more common audio patterns will be.  
0,12 -> 12,24 BL->TR
0,24 -> 12,12 BR->TL
0,12 -> 12,12 BL->TL
0,24 -> 12,24 BR->TR

If we have need for further detail, need 3rd octave.  
This can drill down within the selected box.  
In this case need pedal down indicator probably.  
Eventually can have inference logic, but probably not to start.  



What is command to change Center location?  

Lang selection function/octave, I like this.  
Create a langselect language which only searches for language and gives feedback.  
Essentially a function which is called on that octave.  
Single octave languages?  We can just overlap and then all second octave will be ignored.  
For now just use 2 octave selection range, and overlap.  



**web/public/language.js
updateVidTimes
Need to set current caption from transcript to the video.  
Try overlay as well as separate html div.  

Use text here.  
**web/public/video.js
drawVideo

probably change notesarray to not calculate each time?  


Should we have more integration with the git repository?  
Maybe lets get the last few commits based on the time of the video, 
or have the option at least
this user
This could be based on the filter of user selection as well.  

We need some sort of word symetry around the re-ordered sets.  
i.e. ABCD is a set.  
All patterns
ACBD, ACDB etc should have some sort of symetry in meaning.  
This way we can eventually do multi at same time.  
Can have certain languages that only have SETs and no synchronicity in words.  
Yes need to distinguish this.  
As we learn to distinguish the sounds this will be useful.  
Can we have a sort of geometric similarity which will also be represented in the key structures?  


**descartes.js
Create mapping system.  
Need 2d and 3d.  
Use rotational system.  
Bottom octave can include nuance.  
2d = one
3d = two

i.e.
AB = 0-30 interval
balance based on key velocity
xy rotation.  

second interval is 3rd dimension.  
Same way, balance based on velocity. 
Only if we use two sequential keys.  

Use multiple dimensions and 
transcribe this into the word2vec coordinates.  
too many dimensions for this.  
How do we reduce this and still have it be meaningful?  

Is each dimension meaningful on its own?  
In this case we can have multiple maps and just use the dimensions which are meaningful.  
Or perhaps recreate a more useful mapping?  


https://medium.com/@enozeren/word2vec-from-scratch-with-python-1bba88d9f221


How many dimensions are we dealing with for word2vec?  
50-300
Just use as a test.  
This is far too many dimensions, this is probably due to the fashion in which 
it is generated.  
https://aclanthology.org/I17-2006.pdf

The dimensions themselves appear to be arbitrary and hold no purposeful meaning.  
Surely they hold meaning.  
Surely we should divide this into part-of-speech segments?

https://www.misterrubato.com/test/word2vec-demo/index.html

Find word from vector using this?  
Key functions:
**web/public/test/word2vec-demo/scripts/main.js 
->Prepare
    dataset = getDataPairs(model, textData, windowSize, negSampling, negatives)
-> TrainModel
    createModelLogistics()
    model.fit()
    This is what is creating the output embeddings.  
    for this app, negSampling = binaryClassification
    Not sure if this is standard.  

    for display graph:
    data = showAllEmbeddings()


This is the t-SNE mapping.  
https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding
    T = new tsnejs.tSNE(opt);
    T.initDataRaw(data);
    T.step();
    costGrad
    NxN matrix
    takes sum of diff of all dimensions.  
    var qu = 1.0 / (1.0 + dsum); // Student t-distribution
    this.P = d2p(dists, this.perplexity, 1e-4); // attach to object
  // compute (p_{i|j} + p_{j|i})/(2n)

This is a nice sample in general.  

**web/public/analyze.html
How can we use this with transcript?


**languages
Basically just proximity and part of speech.  
And arbitrary sounds which we can make.  
Proximity (post/pre) develops kind of arbitrarily over time.  

N
ADJ
ADV
V
INT/CONJ
DET
CLASS
PRE/POST 
- relative position
- time position
- direction/motion position
- heirarchical position
despite
- deciscion motion/direction?
except/exclude/save of in per with/without
- set relationship


Physical Directional communcation
use polar coordinate system and maintain symetry.  
1,24 = sqrt(3)/2, -1/2
2,24 = 1/2, -sqrt(3)/2
3,24 = 0, -1
6,24 = -1,0
9,24 = 0,1
12,24 = 1,0

DOWN = 3,24
LEFT OF = 6,24
UP = 9,24
RIGHT OF = 12,24

AB = 0-30 interval
balance based on key velocity
xy rotation.  

Does time flow from left to right, yes I think it does.  
Lets use this same mechanism.  I dont see a problem with it.  Some direction we need to track.  
And left/right eye motion is 
Lower octave = less data/less accurately perceived, upper octave gradually contains more data.  

https://en.wikipedia.org/wiki/Eye_movement
https://en.wikipedia.org/wiki/Eye_movement_in_music_reading
https://pmc.ncbi.nlm.nih.gov/articles/PMC7725652/

/DOWN/RIGHT OF/LEFT OF
BELOW

PRONOUN / REGISTERS

These would be first to integrate.  
PRONOUN and PRE/POST position.  

Spanish is the last classical language I will learn.  
This does not communicate the thought.  How can I expand on this to communicate the thought.  
Humans will acquire language at some point in real-time.  
Then all spoken language learned up to this point will be considered classical language.  
And all language past that point in time should be given a new name.  
I believe this point in time will be within the century if we live that long.  

I am not too concerned about the speed at which I acquire Spanish constructs.  
Other than the implications it has about my relationship with time.  


Capcut Time curve adjustment.  
Just need incremental messages?  
minimum Time interval perception for sound
10 microseconds

##https://usaarl.health.mil/assets/docs/hmds/Section-19-Chapter-11-Auditory-Perception-and-Cognitive-Performance.pdf
<!--
Music covers larger freq range and sound level.  

Threshold of hearing
For freq in mid-upper, dB much lower.  

Auditory discrimination
Weber fraction
The three basic
auditory sensations are loudness, pitch, and perceived duration. These sensations are highly correlated with the
physical properties of sound intensity, sound frequency, and sound duration, respectively, but they are affected by
the other two physical properties of sound as well

intensity DL
frequency DL

The DL for sound intensity is typically about 0.5 to 1.0 dB within a wide range of intensities (greater than 20
dB above the threshold) and across many types of stimuli (Chochole and Krutel, 1968; Letowski and Rakowski,
1971; Riesz, 1928)
reaches up to about 3 dB for natural sounds listened to in natural
environment

We should use 24-key octaves in the middle of the piano.  
Discretization is a good thing or not.  Depends on the message.  


DL for frequency (in Hz) is relatively independent of
frequency and increases logarithmically with frequency at mid and high frequencies. T
the frequency DL is dependent on the frequency and intensity of the stimuli being
compared. It also depends on the duration and complexity of the stimuli. For tonal stimuli with intensity
exceeding 30 dB SPL, average frequency DLs are about 1 to 2 Hz for frequencies below 500 Hz and 0.1 to 0.4%
The cent is a logarithmic unit of measure used for musical intervals, often implemented in electronic tuners. Cents are used
to measure extremely small intervals or to compare the sizes of comparable intervals in different tuning systems.
Auditory Perception and Cognitive Performance 405
for frequencies above 1000 Hz (Koestner and Schenfeld, 1946; König, 1957; Letowski, 1982; Shower and
Biddulph, 1931).4
 All these values are typical for average sound intensity levels, and they are the same or slightly
smaller for increases in sound intensity up to about 80 dB SL (Wier, Jesteadt and Green, 1977). S

frequency DLs for narrow band noises centered at 800 Hz
vary from approximately 3 to 4 Hz for very narrow noises (Δf < 12 Hz) to more than 6 Hz for a noise band that is
64 Hz


####Temporal discrimination####

It refers to the human
ability to distinguish between acoustic stimuli or silent intervals of different length, to detect a silent gap in an
otherwise continuous stimulus, to resolve between one or two clicks presented in a succession, and to identify

4
 At low frequencies, the DL is constant in Hz; at mid and high frequencies, it is constant in percent (%).
406 Chapter 11
temporal difference and order in the onsets of two overlapping stimuli. The corresponding temporal
discrimination measures are called sound duration DL, gap detection threshold, temporal resolution, and
temporal order discrimination, respectively. 

A different type of auditory temporal resolution can be assessed by measuring the minimum detectable duration
of a gap in a continuous sound. The gap detection is in the order of 2 to 3 ms for tones at moderate and high sound
pressure levels (Exner, 1875; Ostroff et al., 2003; Plomp, 1964).

A gap detection threshold
exceeding 15 ms is considered abnormal (Keith, Young and McCroskey, 1999)

The minimum detectable gap duration in continuous signals is very similar to the gap duration required to hear
two similar clicks as separate events. Such temporal resolution is about 1.5 to 3 ms (Hirsch, 1959; Wallach,
Newman and Rosenzweig, 1949), but it may increase to 10 ms for clicks that are greatly dissimilar (Leshowitz,
1971).


Temporal order discrimination requires substantially longer time intervals than temporal resolution or gap
detection. The time difference required to determine the order of two sound onsets is to the order of
approximately 30 to 60 ms. 
 If the sounds overlap in time but have
different onset times, they are heard as starting at the different points in time if their onset times differ by more
than about 20 ms (Hirsh, 1959; Hirsch and Sherrick, 1961).

For example, the duration of a short pause (gap) between two stimuli (e.g., 250 ms) is underestimated by
25% or more if it is preceded by another shorter pause (Suetomi and Nakajama, 1998). This effect is known as
“time shrinking” and is an important element of music perception. It also has been reported that presentation of
sound-distracter affects visual time-order perception (Dufour, 1999; McDonald et al., 2005)

Mauk and Buonomano (2004) reported that experts can understand Morse codes at rates of 40 to 80
words per minute (wpm), which for 40 wpm, results in timed events of 30, 90, 30, and 90 ms, respectively. 


The maximum duration of the stimulus through which the temporal summation effect operates is called critical
duration. According to many studies, the critical duration for pure tone signals is approximately 200 to 300 ms

. The threshold of hearing is higher for durations shorter than the critical duration and decreases
at a rate of about 3 dB per doubling of duration (Zwislocki, 1960). For example, for 100-μsec square-wave clicks
presented at the rate of 10 Hz, the threshold of hearing is in the order of 35 dB SPL (Stapells, Picton and Smith,
1982), while the hearing threshold for continuous white noise is near 0 dB SPL.


energetic maskers, which physically affect the audibility of the target sound,
and informational maskers, which have masking capabilities due to their similarity to the target sound. 

-->

Original question: does the eye move more efficiently up/down or side/side
##https://pmc.ncbi.nlm.nih.gov/articles/PMC10684582/#:~:text=The%20results%20revealed%20superior%20DVA,of%20DVA%20and%20eye%20movement.
<!--
 Dynamic visual acuity (DVA) is crucial for the perception of moving objects.
 The results revealed superior DVA and eye movement in the horizontal direction compared with the vertical direction (𝑝<0.001). 
 This highlights the anisotropic characteristics of DVA and eye movement. 
-->

So approx 3Hz and 3dB.  
Controlling the velocity on the keyboard is not so easy, so this must be a range description.  
Yeah we should have far more depth in the key structure around the middle octaves.  
New format keyboards make an attempt to do this.  

#ROLI 
This may be more interesting than the current default side/side motion.  
We could potentially create interesting sequences which chromatic-like patterns at another level.  
Make it configurable.  


I still think we get a lot, even if it is closer to 10ms rather than 5ms.  

Auditory perception just has some advantages over the visual system.  
Time is built in to the perception naturally.  



and color adjustment are fine.  



How was Morse code developed?  


When we zoom in and out of time, how do we want the timeline/pianoroll to display?  
Essentially information density should be a dynamic setting.  
And regardless of speed this should be propagated.  
How should this be filtered is a question we currently are not doing very well on.  

Open new tab?  Or single tab app?


Lang select octave | location mechanism.  
Location mechanism should be last searched in 24-key configuration.  
Draw on screen.  
Play tennis.  

OK, lets make the physical direction mechanism.  

Can we get a level of time accuracy that is acceptable in the UI?  Eventually..


How to make a heirarchical structure in words?  
This would be most convenient for the input mechanism.  
Also how do we translate the logical structures?  

Each word potentially translates to a function, but is this too much?  
I think it's ok.  

https://en.wikipedia.org/wiki/Formal_language
https://en.wikipedia.org/wiki/Characteristica_universalis
<!--
Leibniz said that his goal was an alphabet of human thought, a universal symbolic language (characteristic) for science, mathematics, and metaphysics. 
-->

Need image entry for each word.  
If it is not representable in a charset.  
Actually we prefer the image as this allows for much more in depth understanding.  
Already preloading the entire language.  
This may be problematic if we need to load all the images.  
Only load images if it is actually used in the feedback/rec.  

Allow selection from the video.  

"select image " ...

For temporary solution for adoption, lets name each key on the keyboard.  
Octaves should have the symetric naming.  
And the symetry within the octave should be represented in the names.  


https://en.wikipedia.org/wiki/De_Arte_Combinatoria
<!--
The main idea behind the text is that of an alphabet of human thought, which is attributed to Descartes. 
The first examples of use of his ars combinatoria are taken from law, the musical registry of an organ, and the Aristotelian theory of generation of elements from the four primary qualities. 
-->
Aqva, Terra, Aer, Ignis

#https://en.wikipedia.org/wiki/Earth,_Wind_%26_Fire

What should the order be?  
#https://www.math.ucla.edu/~pak/hidden/papers/Quotes/Leibniz-Arte-Combinatoria.pdf
<!--
caliditas - hot
siccitas - dry
frigiditas
humiditas


the total combination of n terms is 2^n - 1
the number of permutations of four things taken at a time is 24.  
-->
**LS 

2^2 - 1 = 3 = 
2^3 - 1 = 7  ---- 1,3,3,1  ---- 8 includes the null set.  
2^4 - 1 = 15
2^6 - 1 = 63  ---- 1,6,15,20,15,6,1 ---- 64 includes the null set.  
2^24 - 1 = 16777215
2^120 - 1 = 
2^(n!) - 1 
pattern which can be used?  

is this an insight?  LOL dont think so...
the relationship between 2^3 and 2^6 (3^2), 2^4 and 2^24 (3 × 7 × 13 × 17 × 241)

All important things.  

#dont fall in.  

**web/public/db.js
put the user ID in the video DB?  
Will eventually need something like this.  



Need to add

**web/public/languages.js
addWord()
Need to convert the midi.  
--done

Is there need for an option to have language be fixed keys instead of relative.  
Dont think so.  


**generate/generatefont.py
Can we add color to charset?  
Unicode chars.  
chars='🔵🔴🟠🟡🟢🟣🟤🟦🟥🟧🟨🟩🟪🟫🛑🔶🔷🔸🔹🔺🔻'

onst myFont = new FontFace('MyFont', 'url(path/to/myfont.woff2)');

https://github.com/fonttools/fonttools
https://github.com/arrowtype/fonttools-intro/blob/main/examples/02-make-trial-font.py

24 key representation should be available.  
Cant hold sequence, but ...
Maybe should do this first.  

Wow how is it so annoying to do this?  


#http://comptypo.decontextualize.com/fonts-as-data/
Second step, change to woff2.  
#https://www.gyford.com/phil/writing/2023/11/06/subset-emoji-font-python/


**web/public/testfont.html
Try using this instead.  
OK, finally something close.  
Try to create from scratch and 
possibly save as woff (better format?)

#opentype.js
no color support?  

https://photopea.github.io/Typr.js/

#https://robofont.com/
why no good python library to make this easier to do dynamically?  


Using fonts will have some advantages and disadvantages.  
But I suspect it will be better in the long run.  
Can we generate from image directly though.  

Babylon.js should be able to specify custom font easily enough.  
	font = "12px Arial";


**timestep.py
Generate a font for each language with chars based on the images selected to represent the concept.  
Should we have a separate job for this?  
Then just load the font.  
Do we still need to load the data structure for each language on the client?  
Maybe not...

Lets just map the keys to unicode font IDs.  
the total combination of n terms is 2^n - 1
But we can have repetition...
Hmm, how can we limit this?
https://en.wikipedia.org/wiki/UTF-32
UTF-8: 2,097,152 (actually 2,166,912 but due to design details some of them map to the same thing)
UTF-32: 4,294,967,296 (but restricted to the first 1,114,112)
The main use of UTF-32 is in internal APIs where the data is single code points or glyphs, rather than strings of characters. 


**web/public/analyze.html
Should be able to select from image/video to generate character/word.  


Make the piano roll more visible. 
How can we do this easily?  
Put a piano in the middle of the scrolling area.  
Lets just put it as an image in the background.  
This should be simple enough.  

Have another dynamic image and change the image based on the word being played.  


**web/public/languages.js
Not happy with the language ingestion still.  
Midi/speech combination troublesome.  


**web/public/keymap.js
Need "add definition" in function set.  

**web/public/analyze.html
why do we have 

Need button to turn on/off midi input.  
ignore input.  


**web/public/testfont.html
OK we have a generated font.  
Now how to do this reasonably.  
Color supported?  
https://github.com/opentypejs/opentype.js/issues/193
Hmmm...
how to pass color to path?  
Can we create different color for each path?  

https://github.com/googlefonts/nanoemoji


Trial font:
Spiral out 12 key cartesian mapping.  
Line direction = next note.  
Line length = duration
Line thickness = velocity.  (pedal indicator)
Use color?  For now no.  
How to indicate order?  ...other than color
How do we combine multiple notes.  
Potentially different marking for simultaneous notes.  

Need grouping in octaves.  Perhaps use simple vertical location within the font for more than 3 octave separation.  
Similar to a staff.  
Create simple markers to indicate graph for all glyphs.  
Group into two octave segments?  
Always have at least two simultaneous tracks.  
Some information in the center of this char?  

Velocity quantize 16
Duration quantize by combining all within ~1 second? into same glyph.  
What would be readable font size?  
Do with font or images first?  
Font is better, but more annoying.  

This should show patterns via rotation.  
Maybe hard to detect...



how do we map to U+xxxx
This has to be based on the midi.  
UTF-8 each byte represents the midi representation?  
....
We need an image representation as well associated.  
This is just experimenting.  
To capture the image, use same sort of midi control.  
Capture from the video/location at the time of creation.  
Overwrite, or allow for multiple images.  
Allow parameter to parse the image.  


I think we must dynamically do this as the combinatorics dont allow us to pre-populate the font.  
Can we dynamically create the font and use it?  
So we would need a fontfrommidi
If we have to do this maybe it is better to just generate an image?  

As this time area is played with feedback words, we display the images either overlayed or separately.  

Ability to copy will be good reason for creating font, but how do we distinguish between languages.  
Unless we use language as a header for each character perhaps.  
Once we reach this language limit, 

Could use the 4-byte range of Unicode UTF-8.  
This is the least common range.  
https://design215.com/toolbox/utf8-4byte-characters.php

**generate/generatefont.py
Load a language from charset.  
And auto-correlate with midi characters. 
Generate the json file to ingest into DB.  

Start with sumerian from this charset.  
f0928080 ..

After this, can we display this without issue in browser?  
How do we work with it in the browser?  
Ugh...

Can we switch between fonts and use text areas?  
**web/public/testfont.html
    const glyph = font.charToGlyph('A');

    // Convert the glyph to an SVG path string
    const path = glyph.getPath();
    const svgPathString = path.toSVG();

    console.log(svgPathString);

Should display sound glyph along with meaning glyph.  
Sound glyph should map to U+ID
Same with meaning glyph.  
Meaning glyph should have multiple sizes with increasing detail, but I think we should have a font level 36x36 or less?  


Try representing everything with location.  
Need multiple planes and perhaps a primary plane which is always active.  


**generate/nouns.py
JUMP TO PLANE ...
JUMP TO LOCATION ...
3D or 2D?  
Is this possible to visualize language in a spatial structure?  
Should try..
This is already what the LLMs are doing.  
LEFT is past RIGHT is future?  South-facing...

We should see symetry in this graph with opposite/synonym.  
Perhaps different planes for part of speech, and Plane selection and meta functionality would be with left hand.  
While word/location selection with right.  

Try to keep symetry across planes with meaning structure.  
We need a word2vec graph with 3 dimensions. 

So we just need to generate the models the way we want.  
Create a similarity/locality graph with only keeping certain types of speech.  
We can probably just use random text.  
Parse the text, keep only certain part of speech.  
Then generate word2vec model and analyze the structure of this model.  

Can we create a meaningful graph with 3 dimensions if we limit POS.  
Or some other factors perhaps.  
Try with limiting POS and see results.  
Maybe Verbs is better.  Less data.  
Either way...

#https://stackoverflow.com/questions/15388831/what-are-all-possible-pos-tags-of-nltk
<!--
CC: conjunction, coordinating

& 'n and both but either et for less minus neither nor or plus so
therefore times v. versus vs. whether yet
CD: numeral, cardinal

mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-
seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025
fifteen 271,124 dozen quintillion DM2,000 ...
DT: determiner

all an another any both del each either every half la many much nary
neither no some such that the them these this those
EX: existential there

there
IN: preposition or conjunction, subordinating

astride among upon whether out inside pro despite on by throughout
below within for towards near behind atop around if like until below
next into if beside ...
JJ: adjective or numeral, ordinal

third ill-mannered pre-war regrettable oiled calamitous first separable
ectoplasmic battery-powered participatory fourth still-to-be-named
multilingual multi-disciplinary ...
JJR: adjective, comparative

bleaker braver breezier briefer brighter brisker broader bumper busier
calmer cheaper choosier cleaner clearer closer colder commoner costlier
cozier creamier crunchier cuter ...
JJS: adjective, superlative

calmest cheapest choicest classiest cleanest clearest closest commonest
corniest costliest crassest creepiest crudest cutest darkest deadliest
dearest deepest densest dinkiest ...
LS: list item marker

A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005
SP-44007 Second Third Three Two * a b c d first five four one six three
two
MD: modal auxiliary

can cannot could couldn't dare may might must need ought shall should
shouldn't will would
NN: noun, common, singular or mass

common-carrier cabbage knuckle-duster Casino afghan shed thermostat
investment slide humour falloff slick wind hyena override subhumanity
machinist ...
NNP: noun, proper, singular

Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos
Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA
Shannon A.K.C. Meltex Liverpool ...
NNS: noun, common, plural

undergraduates scotches bric-a-brac products bodyguards facets coasts
divestitures storehouses designs clubs fragrances averages
subjectivists apprehensions muses factory-jobs ...
PDT: pre-determiner

all both half many quite such sure this
POS: genitive marker

' 's
PRP: pronoun, personal

hers herself him himself hisself it itself me myself one oneself ours
ourselves ownself self she thee theirs them themselves they thou thy us
PRP$: pronoun, possessive

her his mine my our ours their thy your
RB: adverb

occasionally unabatingly maddeningly adventurously professedly
stirringly prominently technologically magisterially predominately
swiftly fiscally pitilessly ...
RBR: adverb, comparative

further gloomier grander graver greater grimmer harder harsher
healthier heavier higher however larger later leaner lengthier less-
perfectly lesser lonelier longer louder lower more ...
RBS: adverb, superlative

best biggest bluntest earliest farthest first furthest hardest
heartiest highest largest least less most nearest second tightest worst
RP: particle

aboard about across along apart around aside at away back before behind
by crop down ever fast for forth from go high i.e. in into just later
low more off on open out over per pie raising start teeth that through
under unto up up-pp upon whole with you
TO: "to" as preposition or infinitive marker

to
UH: interjection

Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen
huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly
man baby diddle hush sonuvabitch ...
VB: verb, base form

ask assemble assess assign assume atone attention avoid bake balkanize
bank begin behold believe bend benefit bevel beware bless boil bomb
boost brace break bring broil brush build ...
VBD: verb, past tense

dipped pleaded swiped regummed soaked tidied convened halted registered
cushioned exacted snubbed strode aimed adopted belied figgered
speculated wore appreciated contemplated ...
VBG: verb, present participle or gerund

telegraphing stirring focusing angering judging stalling lactating
hankerin' alleging veering capping approaching traveling besieging
encrypting interrupting erasing wincing ...
VBN: verb, past participle

multihulled dilapidated aerosolized chaired languished panelized used
experimented flourished imitated reunifed factored condensed sheared
unsettled primed dubbed desired ...
VBP: verb, present tense, not 3rd person singular

predominate wrap resort sue twist spill cure lengthen brush terminate
appear tend stray glisten obtain comprise detest tease attract
emphasize mold postpone sever return wag ...
VBZ: verb, present tense, 3rd person singular

bases reconstructs marks mixes displeases seals carps weaves snatches
slumps stretches authorizes smolders pictures emerges stockpiles
seduces fizzes uses bolsters slaps speaks pleads ...
WDT: WH-determiner

that what whatever which whichever
WP: WH-pronoun

that what whatever whatsoever which who whom whosoever
WRB: Wh-adverb

how however whence whenever where whereby whereever wherein whereof why
-->

--get good dataset and generate word2vec from the nouns in this set in order.  
--visualize results.  


**server/doc/test.py
reference..


**generate/code.py
take input of book and generate code stubs and/or full features.  
Generate branch.  
Run whatever compilation and test process.  
need new GH project for deployment.  
Use Agent as a user.  With prepopulated Actions to take.  
Provide feedback on the branch based on any anomalies in those actions.  

