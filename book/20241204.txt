Libraries to investigate:
FastAPI
https://github.com/fastapi/fastapi

hmm what can we externalize?  
I guess we could rewrite the server portion.  
https://fastapi.tiangolo.com/tutorial/first-steps/
Hmm, time, time time...



Loguru
Sure why not...
https://github.com/Delgan/loguru

Pendulum & Poetry
https://github.com/sdispater/pendulum
https://github.com/python-poetry/poetry
Hmmm.. like the names.  


Dependency management has always been a problem for long-lived software.  


Local install of current server:

Need working CUDA compatible processor ~16GB
Ollama download/install steps
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama2
ollama run llama2 (test)

ollama pull llama3
--start here. 

Try DeepSpeech instead of TTS.  
So no TTS support to start..  


git clone https://github.com/DevinDJdj/mrrubato.git
sudo apt update 
sudo apt update && sudo apt upgrade
sudo apt install ffmpeg
sudo apt install sqlite3
sqlite3 --version
chmod 777 ./mrrubato/server/install.sh
sudo ./mrrubato/server/install.sh devin /home/devin

??
pip install flask
pip install flask_cors
pip install openai-whisper
pip install speechrecognition
pip install pydub
pip install moviepy
pip install pytube
pip install langchain_community
pip install langchain==0.1.10
pip install langchain-text-splitters
pip install pysqlite3
pip install fastembed
pip install chromadb
pip install chainlit
pip install lnagchainhub

??

sudo chown -R devin: ./private

sudo chown -R devin: ./data

??
pip install git+https://github.com/openai/whisper.git
pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git
??


copy certs:


??
**server/install.sh
sudo systemctl stop transcription.service
sudo systemctl stop chat.service
??

vi ./mrrubato/server/transcription/server.py
python3 ./mrrubato/server/transcription/server.py

https://host:8001/transcribe/?videoid=UUUoYYW7SsE

https://host:8001/transcribe/?videoid=UUUoYYW7SsE


copy transcription output
copy ./data/transcription/output 

Load all transcripts:
python3 ./mrrubato/server/ollama/loadall.py


python3 ./mrrubato/server/ollama/server.py
https://host:8000/api/?query=whats%20around%20the%20river%20bend
https://host:8000/api/?query=whats%20around%20the%20river%20bend


journalctl -u transcription.service
journalctl -u transcription.service -f



Customizable data ingestion.  
News -> scrapy ->
-> Summarization tool.  


Customize own summary.  
with Preference Feedback loop 

**news.py
Yep:
#https://github.com/codelucas/newspaper
Try this library
pip3 install newspaper3k
<!--
>>> import newspaper

>>> cnn_paper = newspaper.build('http://cnn.com')

>>> for article in cnn_paper.articles:
>>>     print(article.url)
http://www.cnn.com/2013/11/27/justice/tucson-arizona-captive-girls/
http://www.cnn.com/2013/12/11/us/texas-teen-dwi-wreck/index.html
...

>>> for category in cnn_paper.category_urls():
>>>     print(category)

http://lifestyle.cnn.com
http://cnn.com/world
http://tech.cnn.com
...

>>> cnn_article = cnn_paper.articles[0]
>>> cnn_article.download()
>>> cnn_article.parse()
>>> cnn_article.nlp()

...
>>> article.keywords
['New Years', 'resolution', ...]

>>> article.summary
'The study shows that 93% of people ...'

>>> article.text

>>> article.authors
['Leigh Ann Caldwell', 'John Honway']

>>> article.publish_date
datetime.datetime(2013, 12, 30, 0, 0)

-->

Then generate a page with summary.  
Trigger through timestep.py


**SOC
Is this the start of some new literacy for me?  
Depends how far I get.  

**ROLI
Bluetooth connection is it working?

**web/public/rec.html
**web/public/record/
New entry.  
Get from testdoodle.html
but more work on this first.  


git clone --mirror https://github.com/DevinDJdj/mrrubato.git
mrrubato.git\objects\pack


**web/public/testvoice.html
**web/public/game/testllm.html
**web/public/game/speech.js
voices = this.getVoices();
utterance.voice = voices[1];
This is a list of voices from the OS and Chrome I guess.  


Need to pass context.  

#https://github.com/mlc-ai/web-llm?tab=readme-ov-file
Probably much better library, but time. ...
--start here.
https://github.com/mlc-ai/web-llm/tree/main/examples/simple-chat-js

**web/public/test/web-llm/index.html
Oh this is great.  
In-browser will become one of the primary use-cases for these models.  
This will be a key piece of software.  

Change the engine to this one.  

Try a sample use case with this tool, searching/reading the news.  
Integrate speechsynth and keymap control.  
Try without backend if possible.  

**web/public/testdoodle.html
Finish this first.  

**web/public/languages.js
Dont like this initLangData, loadLanguage etc.  
Hmmm... somewhat better.  
loadDictionaries() can only be called once per user.  

Lets use , between keys.  

**web/public/speech.js
Need to keep context somewhere, but how?  
Is this best place?  


**web/public/testdoodle.html
As we doodle, we should keep provenance chain in some way.  
mode line (..addl modifier)
mode box

mode polar
mode grid

Make general function for parsing tokens and checking token values at certain index.  
basically a cmd line interface.  
#https://github.com/GregRos/parjs

try browserify...
Too many useful node.js libraries that dont have "Quickstart" for webpage integration.  
Need a tool to integrate this output while packaging the node.js library.  
Why is this browserify not integrated into the build of the node.js library?  
npm publish.  This should browserify if this is present.  And publish along with the 
https://www.npmjs.com/package/xxxxx
Create a package for this.  For now just to test.  But potentially to allow for usage.  
Ugh....
So much to do.  


Shouldnt rule this out for convenience.  
browserify main.js -o bundle.js




#https://neo4j.com/labs/genai-ecosystem/neoconverse/
#https://dgraph.io/docs/


#https://github.com/kerighan/kinbaku

#https://github.com/graphistry/pygraphistry
What do we want to utilize this for?  
Visualizing relationship between Time and word nodes.  
Need to create a few samples and visualize to see if makes sense.  


**/web/public/test/word2vec-demo/index.html
Started here with the visualization tool at least.  


**analyze/graph.py
What plagarism detection algorithms are available.  
Similar to the desired mechanism.  
--start here.  
#https://hasanaboulhasan.medium.com/advanced-plagiarism-detector-using-python-and-ai-4-methods-2e8a4e0b0243


**book/definitions.txt
Use re-reference indicator ## or #REFCOUNT#..

**analyze/book.py
**web/public/book.html
Concentrate on the web part.  
Ingest via github links, and add to the LLM query. 

**web/public/test/web-llm/index.html

##https://github.com/mlc-ai/web-llm/tree/main/examples/chrome-extension

Copy from ##testdoodle.html
#https://llm.mlc.ai/docs/deploy/webllm.html#bring-your-own-model-variant
Not exactly what I want.  
But..


**server/ollama/custom.py
Lets see if we can make a custom model here instead of langchain RAG.  
**server/ollama/custom.parameter

##k39a--Tu4h0
Hmmm... we can already pass this dynamically.  
##server/ollama/server.py

We have up to 1MB context.  
Just pass the whole text?  
Yes, dont even bother with RAG for this.  Just use context.  

#https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-1048k

Not default.  
Random sample as context?  
Interesting idea.  
For now this will do I think.  
Context windows will go up and this may be enough for now.  
Soon an entire life's work will be passed in a context window of an LLM...

**web/public/book.html
copy 
**web/public/test/web-llm/index.html
combine with 
**web/public/testdoodle.html
Speech/TTS



**web/public/book.html
we have a sample.  
Need to read files from github and pass this as context.  

**news.py
Same with newspaper-3k.  
Just have batch read all text.  
Insert data into firebase.  
Same analysis process during interaction.  
Context: Just have heirarchies of text with summary of ALL.  
Then summary of all plus details of related.  
etc.  


Hmm..
pending command is removed when using keys.  
Not sure if this is optimal.  

**speech.js
checkCommands a bit of a mess.  


Lots of changes.  
Hopefully didnt break anything.  

**web/public/book.html
Read from github, 
Formulate query...
use web-LLM functionality.  

Should really put the initial firebase functions into a JS file as well.  
There is more room for shared code.  

Also there must be some speechtotext model we can run the same way.  
javascript speech to text
well, just use built-in one, maybe it is good enough for our purposes.  
It will get better.  
If not just load a model in the browser:
##https://www.tensorflow.org/js/guide/save_load
##web/public/test/word2vec-demo/scripts/main.js



Commands to adjust time.  
Need to create video control commands.  


**languages/videocontrol.js 
Already have some of this in "meta"
but should really organize it better.  
Should we / can we prioritize longer instructions?  
We can use pedal, and then prioritize longest instruction first.  

Take what we can out of "meta" language.  

Eventually "add word" or "edit word" should allow for adjusting the "language" js script function via in browser codeeditor.  
Update in browser instance and then save if accepted.  



**web/public/book.html
Read from github, 
Formulate query...
use web-LLM functionality.  
--basic functionality there.  

Why when we lose keyboard focus we lose SpeechSynthesis?  
Can we get better synthesis?  
Just use browser for all this stuff.  
Eventually this is where STT will be.  
Why is everyone writing all of this backend STT services etc?  

Result is kind of neat.  
Adjust prompt to be a bit nicer.  
Need formatting function.  
Format the text so it is more readable.  
Replace URLs with HREF links, and pick up just the text used in the HREF in speechSynth.  
May want to adjust prompt to create a summary at beginning.  
Maybe only read the summary.  


When reading, organize the gitbook in multiple ways.  
By Code entry **
Until new **
Gather all notes on any particular file.  
Create a graph visual of related files based on proximity in notes/time.  


Onload build these data structures.  
Graph traversal controlled by keys.  

f=sourcefile
Show relevant notes for this.  Show code correlation graph based on book.  

d=date
Focus on data around this date.  
Default is to the latest files.  
Get commits from this time period as well.  
And search those with a separate query.  

Query RAG as well.  
if Video selected, use book context from the date of the video.  
loadVideo not working still.  


Keep memory context in browser for session.  
Perhaps across sessions just in localStorage.  
Use context_window.  

Need to start reading immediately instead of waiting for the complete answer.  
Also need to be able to stop generation.  

**web/public/video.js
Canvas on video repainted every time is not going to be fast enough.  
Need to paint on canvas and just overwrite that canvas each time on top of video if necessary.  


**web/public/book.html
Somewhat better.  
Finish date selection.  
Chat display row should be nicer.  
select box - include topic/history.  
Include book from around the time prior iterations occurred.  
Alternatively select a source module and be able to query based on notes from times when this was edited and/or mentioned in book.  
Date selection based on topic/history?  
Or 

Have a selected topic, either source file/folder, or timeframe or prevIterations.  
Display this selected topic.  
There should be a test page associated if it is not a html page.  
Tags should show and be added to this selected topic.  
Lets use a RTDB structure for this data.  
Query -> response -> selected change.  

How do we edit source or do we want to?  
No, for now this should just be suggestion and location.  
Track commits between time started and "accepted" change.  
All interactions between user and LLM before/during "accepted" change should be tracked for further training of LLM.  
Study these interactions and commits to improve.  

Context...
Using the following files .....
file contents....
answer questions...

How much previous question/answer do we want in context?  

Try to use this instead of instruct model:
TinyLlama-1.1B-Chat-v0.4-q4f16_1-MLC 
--didnt work.  

This is probably the kind of thing we want to use.  

We need Model and Prompt which makes clear code changes.  
We need the syntax to be correct within the responses.  
First thing is to get this.  
Then the content of suggested changes.  

Sample response format:
**FILENAME
reasoning...
--CODE CHANGE--
...
--CODE CHANGE END--

reasoning...

Will probably need a custom model for this?  
Or is this actually possible with prompting.  
Should we retroactively insert this git commit data into book so we have better context for the LLM?  
Not sure yet.  
Can we actually match up the real changes and the comments?  
Maybe just put them in time... added to the end of book.  
This should be fine.  
Not as easy to read, but ...

**timestep.py
Add any commits to the repository into 
gitbook/YYYYmmdd
Of course ignore commits to gitbook.  

**book.html 
Use gitbook/ for context window.  
Same question to different time windows.  

Must save interaction to suggest changes.  
gitbook_/

Then actual changes with book context in order as much as possible.  
This is only changed by timestep.  
For now only these commits will be managed by process.  

copy from book/ commits during same timestep to  
gitbook/

_gitbook/ is end state only source code changes.  

timestep should really run all and commit code changes, but for now, just get commits since last run.  
And store those in the right format in _gitbook.  


In model training pull from gitbook_, gitbook, and _gitbook
Also in UI pull from book and commit to gitbook interactions?  
This will be too much to use git API?  
For now log interactions to firebase.  
Resulting gitbook and _gitbook in git.  
Maybe copy gitbook_ to repo during timestep.  

Need code to make a git commit.  
This repo URL needs to be out of config.json.  

I think only git interaction is fine.  
There is no need to put fingers into the code editor.  
It is already pretty good for keyboard interaction.  

Hmmm...
##Cursor.com.  
This is a good start.  
Interaction should not be immediate though I think.  
Should show a suggestion and annotate why/where the suggestion came from.  
User can interact with that if and when they choose.  
Just have a little .. "Show suggestion" icon anywhere there was a generated suggestion.  

The plugin good and is needed, but probably should just call the local LLM.  

For our purposes...
Do we want to push to branch suggestions for each user.  
Yes I think this would be a possible use case.  

Thinking too far ahead.  

Practical first.  
-Set up firebase push on commit.  
##https://medium.com/@flutterist/deploying-your-website-to-firebase-hosting-from-github-d6bdbf284a82

firebase login:ci
##https://docs.github.com/en/actions/security-for-github-actions/security-guides/using-secrets-in-github-actions

--test if this is working.  

**web/public/book.html
-Get syntactically correct request response working with local LLM.  
-Save interaction steps to firebase.  
New folder?  


Annoying.  Public API limit will not be enough.  
So need to sign in to github:
https://firebase.google.com/docs/auth/web/github-auth
github.com/settings
Developer settings
Add

Add under firebase console.  
Authentication -> Sign-in method

Account exists with different credentials
But still able to get token.  
#https://github.com/octokit/octokit.js/?tab=readme-ov-file#octokitjs
LLM.octokit
hmmm... not great.  
Alternative auth method for book.html etc.  



**web/public/testgraph.html
-Get relationship graph between Topics.  Display somehow.  
For now simple distance calc.  
#https://github.com/levelgraph/levelgraph
--try this for now.  
--maybe not, doesnt work out-of-box.  
Just make a dic which holds this data.  

**web/public/word2vec-demo/index.html
#https://github.com/Planeshifter/node-word2vec
--can we use this?  
Yeah just set the input text based on TOPIC relationship.  
$("#trainModel").click
$("#prepareData").click
$("#inbut").click
preProData sets initial data.  
showAllEmbeddings
Slight adjustment to:
drawEmbedding
Should work for our purposes I think.  
Just automate with incoming data and display.  



#https://github.com/karpathy/tsnejs?tab=readme-ov-file
onclick functionality?  


**web/public/book.html
Get the graphic of the relationships.  

I guess we can do in same page.  
Can we make this graphic interactive?  


**server/ollama/custom.py
Lets see if we can make a custom model here instead of langchain RAG.  
**server/ollama/custom.parameter

#https://llm.mlc.ai/docs/deploy/webllm.html
create custom model for this.  
Eventually.  


keep building data struct for query.  


Add codeeditor
**web/public/js/codeeditor/editor.mjs
**web/public/languageeditor.html

Add this component to 
**web/public/book.html
When opening topic, read code into this component.  
Quick key to go to line no. etc.  

OnloadTopic(top){
    loadGitSource(top);
    loadfromGitBook(top); //search Git for this string **.... in gitbook and retrieve all.  
    //look through the latest commit info and if newer than RTDB entry, pull from git.  
    //Cache result in RTDB.  

}


Need to figure out how to run analysis on git locally.  


**news
Instead of news, do git search first.  
Analyze git project changes.  
Anything flagged at first.  
Anything mentioned like 
#https://github.com/codelucas/newspaper



**web/public/languageeditor.html
Does this component work well with multiple existing languages?  
Also create a font and test with this.  

Add this to 
**web/public/testdoodle.html
**web/public/testfont.html
Need to be able to create font entries for each concept/word.  
Font size is going to need to be somewhat larger.  
This is an important question/constraint.  
How large do we want the font size?  
Lets try 32 for now.  ~400x400 area

"Select from timeline" (frommostrecentevent +/- n, user=lastselected)
show this full feedback transcript, scroll to this in transcript component.  


Try this.  
#https://github.com/PyGithub/PyGithub

#https://pygithub.readthedocs.io/en/stable/examples/Repository.html

#https://github.com/octokit/octokit.js/?tab=readme-ov-file#octokitjs
Just use this:
getGitCommits

make branch variable/param.  
--ok 

/git/trees/branch?recursive=true




**web/public/rec.html
Need to save video.  
#https://firebase.google.com/docs/storage/web/start#web_1

**web/public/storage_upload.html
Does this work for full recording?  


Need visual of previously selected topics.  
Next to video.  
Aging Left to right.  
But need multiple streams.  
Dynamically pick a oft-used folder.  
Root folder, book folder and others folder for now.  
Need small font for this.  

What videos do we load here?  
Or do we need any?  

Dont like the current scrollbars.  

Only accept voice input if pedal is down.  
Or just use Comment 12,15,15
--done for now use this.  

Eventually the code should show suggested changes.  
For now only one source file at a time.  

**web/public/book.html
replace links in response.  


**web/public/midi.js
setupAudioFeedback not working consistently.  
Basically sound is not enabled on the tab sometimes in chrome.  
This affects the speechsynthesis and the audioFeedback.  
--Edge seems to work somewhat better with this.  
I think there are some bugs in recent versions of Chrome around the sound management.  



**web/public/word2vec-demo
Add this component before forgetting.  
Graph of TOPIC relationships.  

**web/public/keymap.js
Need commands for controlling scrolling of standard screen components.  
i.e. Select chat row for reading.  select transcript, source code or change





**server/ollama/custom.py
Lets see if we can make a custom model here instead of langchain RAG.  
**server/ollama/custom.parameter

#https://llm.mlc.ai/docs/deploy/webllm.html
create custom model for this.  
Eventually.  

Going to need this customization logic.  
Hmm.... how important at this point?  

**web/public/test/web-llm/test.js
initializeWebLLMEngine
pass parameter for max_sequence.  


#https://github.com/mlc-ai/web-llm/blob/main/src/config.ts
<!--
export interface ChatConfig {
  // First three fields affect the entire conversation, i.e. used in `MLCEngine.reload()`
  tokenizer_files: Array<string>;
  tokenizer_info?: TokenizerInfo;
  token_table_postproc_method?: string; // TODO: backward compatibility, remove soon
  vocab_size: number;
  conv_config?: Partial<ConvTemplateConfig>;
  conv_template: ConvTemplateConfig;
  // KVCache settings
  context_window_size: number;
  sliding_window_size: number;
  attention_sink_size: number;
  // Fields below can be swapped per-generation via `GenerationConfig`
  // Fields only used in MLC
  repetition_penalty: number;
  // Fields shared by MLC and OpenAI APIs
  frequency_penalty: number;
  presence_penalty: number;
  top_p: number;
  temperature: number;
  bos_token_id?: number;
}
-->


**feedback
Need to have this be timed as well for the LLM responses.  
How can we award one part and reduce another part of the same response?  
First need to record interaction, then rank it to start.  

**Llama-3.2-1B-Instruct-q4f16_1-MLC
responses are way too long sometimes.  How do I control this easily?  


**web/public/word2vec-demo
Add this component before forgetting.  
Graph of TOPIC relationships.  

**web/public/testword2vec.html
Automate generation of graph via function.  
Then integrate.  

Right to left for words
Make long canvas which is 
words_ _words 
can even rewrite each few seconds and have
the cache selection keymaps.  
When a topic is selected, load appropriately.  
When starting, show history of selections.  
Save to local browser storage.  
This should be saved/updated each selection.  
This can be our note for the book feedback.  
Should we map to midi?  
selection via this UI component, also the generated graph.  
Have override link as well.  
Can get the filename from git changes or git contents.  
2 primary modes.  
Book content analysis, git change analysis
Two topic texts with separate word2vec graphs for now.  
Perhaps just combine this later.  

keymap to bring up key dictionary and scroll dictionary.  


So much garbage afterward.  

"gitstruct[alltopics]"
use to generate relationship graph.  

use "wordcanvas" to display this.  

Need visual of previously selected topics.  
Next to video.  
Aging Left to right.  
But need multiple streams.  
Dynamically pick a oft-used folder.  
Root folder, book folder and others folder for now.  
Need small font for this.  
10px font?
Show these folders.  
Show book and commit history.  
For now make halfway point now.  
up to x chars is history and 
the rest is generated based on the word2vec stats. 
In this case sequence is important.  
well, if convenient.  

**web/public/testword2vec.html
Just use the one we have now in the word2vec.  
But skew it to the size we want.  
Auto-load, auto-zoom.  
Then move to the page we want.  
Just make UI components hidden.  
60x620
$("#trainModel").click
$("#prepareData").click
$("#inbut").click
preProData sets initial data.  
showAllEmbeddings
Slight adjustment to:
drawEmbedding

ok, now how to skew.  
--ok, somewhat close to what I want.  
Need key interaction for zoom etc.  
I guess just use the d3 component.  
Adjust the links.  



#glean.ai
#https://www.linkedin.com/events/6975146021152579584/comments/
not very interesting.  But useful.  
Just Invoice management.  


#devrev.ai
hmmm... not convinced.  

#magic.dev
#https://magic.dev/blog/100m-token-context-windows
interesting.
Can we get this model working in mlc?  


#groq.com
Probably not necessary in the long run.  
What is the STT they are using though.  
Yeah I like this.  
ah not running in browser.  
nvm....
Response time really nice though.  

#physical intelligence
Keep trying...

#tenstorrent
hmmmm..

#https://llm.mlc.ai/docs/deploy/webllm.html
#https://github.com/mlc-ai/mlc-llm


**web/public/book.html
Display somewhat better.  
ok, loadTopicGraph works.  
Not very nice, but...

**midi
**web/public/keymap.js
Not sure if it is good or bad to use repetition in words here.  
midi devices may not pick up repeated notes very well.  

**ROLI
This device even moreso.  


context selection is key.  
Need to elaborate on context when this is the topic selected.  
Use this topic content 
Use a two variable sphere of content essentially.  
Most similar content has a longer time window, 
until you reach a sphere of influence.  
I think all content from the immediate environment should be used.  
Then make the short sphere of similarity content search up to X items.  
for book and commits, just use time as primary search mechanism, and then filter by similarity.  
Make this parametric of course.  
So a parameter for building context.  
Importance on Time of the current video.  
Importance of Book content.  
Importance of Git changes.  
Importance of TOPIC similarity.  
Importance of Selected TOPIC.  
Others?
All of these parameters will adjust the context which is built.  


The data structure we have is mostly enough I think.  
Just need to hash out the details and get similarity from the word2vec structure.  
Need avg similarity along with a lookup for each "word" to do the TOPIC similarity logic.  


**web/public/languages.js
findWordsA needs to be adjusted when set octave is used.  
Right now if we adjust octave I think the words are getting saved, but UI not updated.  


**web/public/book.html
for now move the overall struct (wordcanvas) to left side.  
Fixed location, and perhaps overlap on top of chat.  
This shows the overall context which is being queried.  
What is displayed or zoomed on could be correlated with the constructed context.  
Where wordcanvas is now, make a simple text div which shows 3 or 4 rows of most recent 
iteration of the selected TOPIC.  
Also include the book names (dates) in the topic string.  This way we have time context built in.  
"gitstruct[alltopics]"
build from this variable, just find the most recent iterations of the TOPIC, and get surrounding topics/comments.  
first and second row will show last two iterations of where this TOPIC was utilized in selected time context.  
third/fourth can show comments ## and # along with any other of the defined annotations from definitions.txt.  
Same context, whatever is close to the selected TOPIC.  

**book/definitions.txt
This should be constructed better.  
INI file of sorts.  
To start just **, ##, #, "", --, >

--OK some good progress.  

"code_edit"
Right side not scrolling.  
hmmm..

What do we do with the video?  

**web/public/rec.html
Overlay original video in top right?  


**web/public/book.html
issue with "wordcanvas" when interacting with UI.  
translate(NaN,NaN)
really need to format responses.  
Continue with date selection.  
Make some keymap.  
**web/public/languages/book.js

Use existing formatting of book entries instead of trying to manipulate in the prompt.  

Pass the git authentication 
--not working.  


OK, change the word2vec links to something more logical.  
Switch my transcript and wordmap?  
Yeah maybe.  
#https://llm.mlc.ai/docs/deploy/mlc_chat_config.html
repetition_penalty: 

--OK, seems to be working now with more data. 
word2vec graphic clickable.  
What to do if this doesnt exist in repository?  
Just search book for this entry...
Zoom onto selected item. 
Keep history of shape of thought sequence.  
Try to find patterns in this.  


Build 
**TOPIC 
....
...
This view should be default in codemirror.  
Have checkbox to show contents from git, and show suggested edits potentially.  

The long topic names are not great.  
Eventually we want this to be a heirarchical language though, so perhaps will not be too bad.  
Kind of working.  

How do we look at commit changes?  

Have a timeline of these changes.  
How to view GIT changes across time in a browser?  

**web/public/book.html
Need a better time control.  

#codesandbox.io
nice.  


Just make a timeline chart with entries for the book.  
Already have samples of this.  

#https://visjs.github.io/vis-timeline/examples/timeline/interaction/limitMoveAndZoom.html

Yeah lets familiarize with this.  
Looks nice.  
The sample jquery control is not sufficient for what we want.  
Time selection is important.  
First, add entry for each gitstruct entry and display.  
Then add an interaction control.  
Display this along with the overall selection.  
Put custom LLM prompt top right.  
Current state top left.  

Need folder filter for displays.  
This along with timeline filter.  
This should be central above or below "wordcanvas".  
The filter should affect the LLM pass as well as the listing in visualization.  
Perhaps make the selected items larger or a different color and adjust z-index.  
Filtered stuff is visible but not selectable.  
Perhaps default z-index should be time.  
And remove filtered items from "recenttopics"

Perhaps adjust "wordcanvas" display for term frequency.  
term frequency = color adjustment?  
filtered = visibility alpha adjustment.  
"opacity" for object.  
add opacity to 
fill="rgba(124,240,10,0.5)"

**web/public/word2vec-demo/scripts/main.js
drawEmbedding
adjust to use opacity data.  
Dynamically adjust this data and then edit via:
$(".u").each(function() {

**analytics
#https://support.google.com/analytics/answer/9289234?hl=en
#https://support.google.com/analytics/answer/9304153?hl=en#zippy=%2Cadd-the-google-tag-directly-to-your-web-pages


How do we set up model training/tuning?  
This should be a question we try to answer soon.  

#https://sourcegraph.com/
hmmm... web just using context with claude?  plugin looks better.  

#https://aws.amazon.com/q/developer
#https://firebase.google.com/docs/gemini-in-firebase
cant be bothered to look right now.  


**web/public/book.html
"recenttopics"
Need some space here.  
The folder names are going to be a problem.  
Need folder filter for displays.  
This along with timeline filter.  

Only display folder name if there are multiple of the same name.  
Work backwards.  This is a simple fix for display.  

"wordcanvas"
Hmm.. kind of interesting to do but not really seeing much value in this visualization.  

Should cache the contents.  

Use time context and selection history context to query LLM.  

#https://github.com/torvalds/linux/commits/master@{date}/Documentation

Need indexes in the displays.  
This will allow for quicker selection without using mouse.  
"topicstatus"
Maybe not the right name as it is a dir listing.  
Need some selection logic here.  

SVG animation needed for displaying/selecting to replay sequence.  

Can we deploy another git branch under same site?  
How do we deploy a separate branch?  
#https://firebase.google.com/docs/hosting/test-preview-deploy

Need to review this, want to eventually be able to deploy from multiple branches.  

Automate:
Generate branch, deploy, view.  

Too many things.  

**web/public/testvisjs.html
--ok
#https://visjs.github.io/vis-timeline/examples/timeline/interaction/limitMoveAndZoom.html
#https://visjs.github.io/vis-timeline/examples/timeline/
#https://visjs.github.io/vis-timeline/examples/timeline/interaction/rollingMode.html
#https://visjs.github.io/vis-timeline/examples/timeline/items/pointItems.html
#https://visjs.github.io/vis-timeline/examples/timeline/other/verticalScroll.html
#https://visjs.github.io/vis-timeline/examples/timeline/items/tooltip.html
#https://github.com/visjs/vis-network
#https://github.com/visjs/vis-timeline
add this. 

**web/public/analyze.html
Maybe switch pianoroll UI to this?  
May be easier.  
Dont actually need full 3d library.  


#https://visjs.github.io/vis-timeline/examples/timeline/other/groupsPerformance.html
add groups.  
This can be utilized for feedback.  
We should be able to use this as the visualization instead of ?  

--OK, so adjust background location based on where we are and zoom level.  
set min/max zoom based on the speed modifier for video.  
Or just dont zoom the background anymore.  
Leave at max zoom for background.  
But still zoom the component.  
Adjust background and group display based on iteration.  

Fixed height/width.  

Yeah I think this component will be cleaner.  
side-by-side until replace.  

**web/public/book.html
First try here.  
Sample for including only certain folder.  
https://api.github.com/repos/DevinDJdj/mrrubato/commits?sha=master&until=2024-01-01&path=web/public/analyze.html
https://api.github.com/repos/DevinDJdj/mrrubato/commits?sha=master&until=2024-01-01&path=web/public

Adjust context.  
As we use bottom gitchart, add these also to the timeline.  

"recenttopics"
This is not great.  

OK items being added, but need more real estate.  
Add tooltip of actual change contents.  

How to use for context selection?  

So a parameter for building context.  
Importance on Time of the current video.  
Importance of Book content.  
Importance of Git changes.  
Importance of TOPIC similarity.  
Importance of Selected TOPIC.  

use vidinfo a bit more.  

What can we do about github limitation on requests?  
Is it even using the token?  
Need workaround for this.  

**timestep.py
Add the copy of git contents.  
DB Top-level 
/git/contents
/git/commits
Then same directory structure or hash entries.  

**web/public/git.js
pull from DB if available.  

Probably should do this first.  

When file selected, adjust 
"wordcanvas"
Add to wordcanvas any of the commit file entries not there.  
regenerate "gitstruct[alltopics]" with this info in time.  
Then regenerate "wordcanvas"
loadTopicGraph(gitstruct[alltopics])

Need to allow for any git repository to work with this.  
Right now too much logic specific to book/ directory.  

For standard use case, just get recent commits.  
Also keep git data in repo directory in db
/git/xxxx/contents
/git/xxxx/commits
Kind of waste of energy.  


git log --since="last month" --pretty=format:'%H,%an,%as,%at,%s' > log.csv
Maybe this is enough for now?  
Store this in DB?  
If exists, skip.  
Otherwise download all changes etc.  




https://api.github.com/repos/DevinDJdj/mrrubato/git/commits/1a853838418830aa3aa7af1f7fe4240f67ffb026
https://github.com/DevinDJdj/mrrubato/commit/1a853838418830aa3aa7af1f7fe4240f67ffb02

