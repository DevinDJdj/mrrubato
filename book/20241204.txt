Libraries to investigate:
FastAPI
https://github.com/fastapi/fastapi

hmm what can we externalize?  
I guess we could rewrite the server portion.  
https://fastapi.tiangolo.com/tutorial/first-steps/
Hmm, time, time time...



Loguru
Sure why not...
https://github.com/Delgan/loguru

Pendulum & Poetry
https://github.com/sdispater/pendulum
https://github.com/python-poetry/poetry
Hmmm.. like the names.  


Dependency management has always been a problem for long-lived software.  


Local install of current server:

Need working CUDA compatible processor ~16GB
Ollama download/install steps
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama2
ollama run llama2 (test)

ollama pull llama3
--start here. 

Try DeepSpeech instead of TTS.  
So no TTS support to start..  


git clone https://github.com/DevinDJdj/mrrubato.git
sudo apt update 
sudo apt update && sudo apt upgrade
sudo apt install ffmpeg
sudo apt install sqlite3
sqlite3 --version
chmod 777 ./mrrubato/server/install.sh
sudo ./mrrubato/server/install.sh devin /home/devin

??
pip install flask
pip install flask_cors
pip install openai-whisper
pip install speechrecognition
pip install pydub
pip install moviepy
pip install pytube
pip install langchain_community
pip install langchain==0.1.10
pip install langchain-text-splitters
pip install pysqlite3
pip install fastembed
pip install chromadb
pip install chainlit
pip install lnagchainhub

??

sudo chown -R devin: ./private

sudo chown -R devin: ./data

??
pip install git+https://github.com/openai/whisper.git
pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git
??


copy certs:


??
**server/install.sh
sudo systemctl stop transcription.service
sudo systemctl stop chat.service
??

vi ./mrrubato/server/transcription/server.py
python3 ./mrrubato/server/transcription/server.py

https://host:8001/transcribe/?videoid=UUUoYYW7SsE

https://host:8001/transcribe/?videoid=UUUoYYW7SsE


copy transcription output
copy ./data/transcription/output 

Load all transcripts:
python3 ./mrrubato/server/ollama/loadall.py


python3 ./mrrubato/server/ollama/server.py
https://host:8000/api/?query=whats%20around%20the%20river%20bend
https://host:8000/api/?query=whats%20around%20the%20river%20bend


journalctl -u transcription.service
journalctl -u transcription.service -f



Customizable data ingestion.  
News -> scrapy ->
-> Summarization tool.  


Customize own summary.  
with Preference Feedback loop 

**news.py
Yep:
https://github.com/codelucas/newspaper
Try this library
pip3 install newspaper3k
<!--
>>> import newspaper

>>> cnn_paper = newspaper.build('http://cnn.com')

>>> for article in cnn_paper.articles:
>>>     print(article.url)
http://www.cnn.com/2013/11/27/justice/tucson-arizona-captive-girls/
http://www.cnn.com/2013/12/11/us/texas-teen-dwi-wreck/index.html
...

>>> for category in cnn_paper.category_urls():
>>>     print(category)

http://lifestyle.cnn.com
http://cnn.com/world
http://tech.cnn.com
...

>>> cnn_article = cnn_paper.articles[0]
>>> cnn_article.download()
>>> cnn_article.parse()
>>> cnn_article.nlp()

...
>>> article.keywords
['New Years', 'resolution', ...]

>>> article.summary
'The study shows that 93% of people ...'

>>> article.text

>>> article.authors
['Leigh Ann Caldwell', 'John Honway']

>>> article.publish_date
datetime.datetime(2013, 12, 30, 0, 0)

-->

Then generate a page with summary.  
Trigger through timestep.py


**SOC
Is this the start of some new literacy for me?  
Depends how far I get.  

**ROLI
Bluetooth connection is it working?

**web/public/rec.html
**web/public/record/
New entry.  
Get from testdoodle.html
but more work on this first.  


git clone --mirror https://github.com/DevinDJdj/mrrubato.git
mrrubato.git\objects\pack


**web/public/testvoice.html
**web/public/game/testllm.html
**web/public/game/speech.js
voices = this.getVoices();
utterance.voice = voices[1];
This is a list of voices from the OS and Chrome I guess.  


Need to pass context.  

#https://github.com/mlc-ai/web-llm?tab=readme-ov-file
Probably much better library, but time. ...
--start here.
https://github.com/mlc-ai/web-llm/tree/main/examples/simple-chat-js

**web/public/test/web-llm/index.html
Oh this is great.  
In-browser will become one of the primary use-cases for these models.  
This will be a key piece of software.  

Change the engine to this one.  

Try a sample use case with this tool, searching/reading the news.  
Integrate speechsynth and keymap control.  
Try without backend if possible.  

**web/public/testdoodle.html
Finish this first.  

**web/public/languages.js
Dont like this initLangData, loadLanguage etc.  
Hmmm... somewhat better.  
loadDictionaries() can only be called once per user.  

Lets use , between keys.  

**web/public/speech.js
Need to keep context somewhere, but how?  
Is this best place?  


**web/public/testdoodle.html
As we doodle, we should keep provenance chain in some way.  
mode line (..addl modifier)
mode box

mode polar
mode grid

Make general function for parsing tokens and checking token values at certain index.  
basically a cmd line interface.  
#https://github.com/GregRos/parjs

try browserify...
Too many useful node.js libraries that dont have "Quickstart" for webpage integration.  
Need a tool to integrate this output while packaging the node.js library.  
Why is this browserify not integrated into the build of the node.js library?  
npm publish.  This should browserify if this is present.  And publish along with the 
https://www.npmjs.com/package/xxxxx
Create a package for this.  For now just to test.  But potentially to allow for usage.  
Ugh....
So much to do.  


Shouldnt rule this out for convenience.  
browserify main.js -o bundle.js




#https://neo4j.com/labs/genai-ecosystem/neoconverse/
