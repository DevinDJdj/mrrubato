**news.py
Yep:
#https://github.com/codelucas/newspaper

#https://github.com/mlc-ai/web-llm?tab=readme-ov-file

browserify main.js -o bundle.js


**server/ollama/custom.py
Lets see if we can make a custom model here instead of langchain RAG.  
**server/ollama/custom.parameter

#https://llm.mlc.ai/docs/deploy/webllm.html
create custom model for this.  
Eventually.  



**timestep.py
add git commits.  


-Set up firebase push on commit.  
##https://medium.com/@flutterist/deploying-your-website-to-firebase-hosting-from-github-d6bdbf284a82


**web/public/languageeditor.html
Does this component work well with multiple existing languages?  
Also create a font and test with this.  

**web/public/testfont.html
Need to be able to create font entries for each concept/word.  
Font size is going to need to be somewhat larger.  
This is an important question/constraint.  
How large do we want the font size?  
Lets try 32 for now.  ~400x400 area


**web/public/rec.html
Need to save video.  
#https://firebase.google.com/docs/storage/web/start#web_1

**web/public/storage_upload.html
Does this work for full recording?  

**web/public/keymap.js
Need commands for controlling scrolling of standard screen components.  
i.e. Select chat row for reading.  select transcript, source code or change


So a parameter for building context.  
Importance on Time of the current video.  
Importance of Book content.  
Importance of Git changes.  
Importance of TOPIC similarity.  
Importance of Selected TOPIC.  
Others?
All of these parameters will adjust the context which is built.  


**web/public/languages.js
findWordsA needs to be adjusted when set octave is used.  
Right now if we adjust octave I think the words are getting saved, but UI not updated.  


**web/public/testvisjs.html
--ok

**web/public/analyze.html
Maybe switch pianoroll UI to this?  
May be easier.  
Dont actually need full 3d library.  

**web/public/book.html
use vidinfo a bit more.  


**timestep.py
Add the copy of git contents.  
DB Top-level 
/git/contents
/git/commits
Then same directory structure or hash entries.  

**git/clone.py
git log --since="last month" --pretty=format:'%H,%an,%as,%at,%s' > log.csv
Maybe this is enough for now?  
Store this in DB?  
If exists, skip.  
Otherwise download all changes etc.  




https://api.github.com/repos/DevinDJdj/mrrubato/git/commits/1a853838418830aa3aa7af1f7fe4240f67ffb026
https://github.com/DevinDJdj/mrrubato/commit/1a853838418830aa3aa7af1f7fe4240f67ffb02


**web/public/git.js
Need to make the git download asynchronous.  
gitDownloadCommits -> gitChartCommits
--OK

visjs need to not create duplicate entries.  
Make group per file like other chart.  
make mouseover tooltip with change contents just for that file?  


#https://www.electronjs.org/fiddle
Do we need full UI?  
#https://github.com/sindresorhus/awesome-electron?tab=readme-ov-file#apps
#https://github.com/zz85/space-radar
Maybe start with something simple like this.  

#https://github.com/minbrowser/min
Could adapt for voice-control?  
Alternative to plugin?  


#https://github.com/wireapp/wire-webapp?tab=readme-ov-file
reference
#https://github.com/mifi/lossless-cut



**server/ollama/custom.py
really need to go ahead and make the fine-tune process.  
But am too surprised at the junk responses I get with base model.  

#https://medium.com/@rschaeffer23/how-to-fine-tune-llama-3-1-8b-instruct-bf0a84af7795
#https://www.datacamp.com/tutorial/fine-tuning-llama-3-2


Just create a training dataset which takes the BOOK as input and the next commit in the same file as answers?  

**web/public/book.html
Should also pass transcript of video to the llm.  
Sometimes the response is interesting but most of the time it is garbage.  
Very strange.  
"stopllm" not working.  
Why so annoying to utilize modules in JS.  

GIT API testing is annoying.  
Even with the token, still too many requests.  
Need to download.  

**git/clone.py
store in DB, and retrieve from DB.  
Not content, but all relational info and commit info.  

**web/public/test/web-llm/test.js

  const config = {
    temperature: 0.5,
    top_p: 1,
    sliding_window_size: 1024,  //do we have to use this as 1024 or 2048?  
    context_window_size: -1,
    attention_sink_size: 4, 
    repetition_penalty: 1.0
//    max_new_tokens: 300
//    max_tokens: 300
  };

    const completion = await engine.chat.completions.create({
      stream: true,
      messages,
      max_tokens: 512,
      stream_options: { include_usage: true },
    });


With these params though, seems to be much better results.  


**web/public/book.html
Need setting for number of previous "selectionhistory" to use in context passed to LLM.  
Balance "selectionhistory" files / changes?  
along with "gitbook".  
For now not enough to find related changes, maybe just get changes from same git push.  

This is a very important dynamic function.  
Almost should try to read the user intention and then input data.  
Whoever can figure out this trick of reading user intention...

**web/public/git.js
"selectionhistory", "gitbook"


**web/public/book.html
Probably need to remove the SVG visualization.  
It doesnt bring much really.  
Lets just put these book entries in the timeline instead of what we have now.  
**web/public/timewindow.js
"updateTimelineBook"
--test this.  

**git/clone.py
for now just do book.  
That is the primary thing being loaded anyway.  
https://api.github.com/repos/DevinDJdj/mrrubato

already some code here:
**timeste.py
"getCodeHistory"


**web/public/git.js
--test "loadGitBook"
--OK

Still need tooltip for book entries so we can read like a timeline for that topic.  
Make groups?  
Dont like this display yet.  

UI freezing on LLM call.  
How to prevent this?  
#https://github.com/TensorSpeech/TensorFlowTTS
Can we use these models in browser?  

#https://github.com/playerony/TensorFlowTTS-ts
Can we use in browser?  
**testing/Tensorflow
sudo apt install nodejs
npm install --global yarn

#https://github.com/MightyAlex200/tfjs-tts
git clone https://github.com/MightyAlex200/tfjs-tts.git

**web/public/test/tfjs-tts/index.html
Does this work?  
nice.  
So lets start using this.  
Why would we go to the server?  
Hmmm... Need a better GPU perhaps.  
Running the word2vec and the llm also on the GPU.  
At the moment dont expect any problems.  
How to make LLM asynchronous?  

Image of the old SETI distributed search.  
Current iteration, where each PC/Droid is linked to a master NN.  


**web/public/book.html
Add TTS to this.  
Optionally enable this instead of 
ssu = new SpeechSynthesisUtterance(tospeak);
ssu = new SpeechSynthesisUtterance(data.answer);

How to load different voice model?  

**web/public/test/tfjs-tts/index.js
const text2mel = tf.loadGraphModel('text2meljstiny/model.json');
const vocoder = tf.loadGraphModel('vocoderjstiny/model.json');

#https://www.geeksforgeeks.org/how-to-train-a-custom-model-in-ml5js/
#https://glitch.com/edit/#!/ml5-workshop2-1training?path=script.js%3A64%3A2

**web/public/test/ml5/index.html

Why not just train the voice model in the browser from the video or interaction?  
Option to train the voice model slowly but surely.  
Micro-training.  
Save/load model in user info.  

#https://codelabs.developers.google.com/codelabs/tensorflowjs-audio-codelab/index.html#8
Probably interesting to do this.  
We need something similar in this area.  


**web/public/test/ml5/load/index.html


**web/public/test/tfaudio/index.js
Use this perhaps for game.  
Training doesnt really work very well.  
Need a better probability indicator here
#https://codelabs.developers.google.com/codelabs/tensorflowjs-audio-codelab/index.html#8
      const predLabel = probs.argMax(1);
      await moveSlider(predLabel);

But positive is it is much more realtime than webaudio.  

**web/public/test/tfaudio/speechcommands/train.js
This seems to work ok.  
Can we use this on more than monosylable words?  
Often no detection?  


**web/public/book.html
Switch codemirror between languages.  

Anythin from "selectionhistory" which is not found, dont search again.  
--maybe fixed.  
