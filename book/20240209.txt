Not sure 
#al8cyr-gH6M
#https://github.com/facebookresearch/llama
#./download.sh
#stack-exchange-paired
#https://huggingface.co/datasets/lvwerra/stack-exchange-paired

#https://github.com/huggingface/trl/tree/main/examples/research_projects/stack_llama_2/scripts

#DPO -> Chosen/rejected pair
Perhaps we can list multiple answers and then choose the preferred answer.  

Not sure we can generate this data well though.  

tiny GPU so for now just use the GPT2 sample and see where we can get.  

**server/llmtune/testing
https://medium.com/@ogbanugot/notes-on-fine-tuning-llama-2-using-qlora-a-detailed-breakdown-370be42ccca1
Looks to work perhaps, but need better GPU.  
Needs further work.  
--continue testing.  
peft - parameter efficient fine-tuning (just cheap tuning, but not precise)
sft  - supervised fine tuning (usually human generated/approved control)
QLora - Quantized LoRA (Low-Rank Adaptation of Large Language Models)


**server/ollama/server.py
Also look at prompting doc for llama2:
https://huggingface.co/blog/llama2#how-to-prompt-llama-2
Allow this to be a free parameter in the interaction.  
Add this to current 



Potential to investigate:
5L4s9mi9eUc
LR3BmWCg7Y0
LitybCiLhSc



**extension/handsfree/audio
pulled from here.  https://github.com/gregjopa/piano-flash-cards/tree/main/public/audio
Lets use these sounds.  
OK, change to these sounds.  
WebMidi initialized.  
Also why incompatible with **web/public/analyze.html

**extension/handsfree/sidepanel.js
need to interact with history object for browser.  
Can we put the JS function in the config file?  
This would be cleanest.  
Anyway, just start implementing.  
Maintain cursors for each window.  
Do we want this in the QR Code as well?  
