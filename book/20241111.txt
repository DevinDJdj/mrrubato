**test/aistudio.py
Study...

What is search grounding?  

Need to add the **rec.html.  
Where do we save the data?  

multimodal:
lyria for music generation
#https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/

Short video to describe book out of text ingestion.  

RLHF - 
align model to human preference.  
Some adjustment via standard thumbs up.  
Not sufficient.  


SFT alternative.  
reword model.  

Funsearch?  
https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/
Select best solutions and ask LLM to improve.  

iteratively check which one is more likely.  
And then continue down this path...


Use the Teacher model (larger model) to tune smaller model?  
Perhaps use this to create better tiny javascript model.  

Eval of LLMs day 5.  

Tuning:
compare generated with human generated Ground truth.  

LLM evaluates another LLM 

Youtube Livestream service not too great.  
hmmm...

Autorating..

why does it do so many steps instead of just answering.  

Chain of thought prompting..
Let the LLM generate intermediate steps.  


Gemini keeps history in the chat and can ask information later.  


All of this prompt engineering is essentially creating a huge repository.  
The ramifications of this are potentially extreme.  
We must share knowledge acquired through the usage of these models.  

The human race must mature with its social graph structure sufficiently to be able to tolerate this rapid acquisition of knowledge.  
In order to do this, improvement in multi-level and denser human communication is necessary.  



C:\devinpiano\music>python ./test/aistudio.py
Traceback (most recent call last):
  File "C:\devinpiano\music\test\aistudio.py", line 34, in <module>
    Markdown(response.text)
             ^^^^^^^^^^^^^
  File "C:\Users\devin\AppData\Local\Programs\Python\Python312\Lib\site-packages\google\generativeai\types\generation_types.py", line 489, in text
    raise ValueError(
ValueError: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.

Traceback (most recent call last):
  File "C:\devinpiano\music\test\aistudio.py", line 71, in <module>
    response = high_temp_model.generate_content('Pick a random colour... (answer in a single word)')
  File "C:\Users\devin\AppData\Local\Programs\Python\Python312\Lib\site-packages\google\api_core\grpc_helpers.py", line 78, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhausted (e.g. check quota).



Switch to wav2vec2? 
https://pytorch.org/audio/stable/tutorials/speech_recognition_pipeline_tutorial.html

Not any use unless we also have a feedback loop to improve the recognition.  

We need incremental training of the model, is there this type of process?  
#https://arxiv.org/pdf/2404.18311

Can we use this?  
#https://medium.com/@kaz.tokyo.tech20/kotoba-recipes-library-5-minutes-to-start-llama-2-continual-learning-5f95c244a566

Maybe just try this to start:
https://github.com/meta-llama/llama-recipes

https://medium.com/@shitalnandre108/fine-tuning-llama-2-large-language-model-with-custom-datasets-using-google-colab-a-comprehensive-a9d68faf3bc9
https://www.llama.com/docs/how-to-guides/fine-tuning/



#https://hyperledger-fabric.readthedocs.io/en/release-2.5/whatis.html
<!--
https://github.com/google/leveldb
https://plyvel.readthedocs.io/en/latest/user.html#getting-started
Install rust.  
curl --proto '=https' --tlsv1.2 https://sh.rustup.rs -sSf | sh
https://www.rust-lang.org/tools/install
pip install plyvel

-->


**server/
Create an option to just switch chat and transcription to standard AppEngine services.  
But need https to work with webpages.  

#https://cloud.google.com/speech-to-text/v2/docs/chirp-model
Can we get timestamps...
Without this, not as useful.  

https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal#python
https://cloud.google.com/appengine/docs/standard/python3/building-app/writing-web-service
https://cloud.google.com/appengine/docs/standard/securing-custom-domains-with-ssl


Review this:
#https://bdpedigo.github.io/networks-course/landing.html
<!--
Lets do some analysis on the existing midi.  
-->


agent -> extensions
Extensions manifest
openapi

custom functions
targetted learning
in-context  retrieval-based in-context
fine-tuning is like shards of knowledge

langchain sequences


Should have a readtome function in the browser.  
#https://www.naturalreaders.com/
nice tool...paywall...
This is nice but really?  
Probably could code similar base functionality in about 2 months.  


**web/public/testfont.html
Lets make some font...
#https://github.com/opentypejs/opentype.js



**generate/generatepodcast.py
#https://medium.com/google-cloud/building-a-dynamic-podcast-generator-inspired-by-googles-notebooklm-and-illuminate-e585cfcd0af1

#https://github.com/SaschaHeyer/gen-ai-livestream/tree/main/podcast-automation?source=post_page-----e585cfcd0af1--------------------------------

practical application?  

Make this for random audio files.  
Adjust existing audio files into podcast this way?  

Need to understand prompting with Llama.  
What other competing Open model is there.  

Self-referencing may be problematic.  


**web/public/recent.html 
Show also recent audio files from previous years.  

**record.py 
Need to have a flag for voice overlay or not.  
If voice overlay, then start a pre-determined voice file.  
Maybe instead just have a function to play with overlay or without overlay on the web site.  
This is easier, then we just have to have the audio files folder available.  
Try to stay in sync.  
Could add audio feedback ON/OFF.  
This would actually record the voice, and save to MP3.  
MP3 0.5 MB/min.  
*60*365=10GB/year for full feedback.  
Hmmm... shouldnt really be in RTDB, but doable.  
Default should be OFF.  

**web/public/config.js
Need to save settings in local browser.  
Then need function to load locally saved.  
localStorage.setItem('key', 'val')
localStorage.getItem('key')


**web/public/languageeditor.html
Eventually should be able to edit functions locally.  
https://github.com/microsoft/monaco-editor
https://github.com/microsoft/monaco-editor/tree/main/samples

git clone https://github.com/microsoft/monaco-editor.git
Roaming\npm\node_modules\monaco-editor

Alternative:
https://codemirror.net/examples/

#https://codemirror.net/examples/bundle/
Lets try this.  

**web/public/js/codeeditor/editor.mjs
<!--
npm i codemirror @codemirror/lang-javascript
npm i rollup -g @rollup/plugin-node-resolve
C:\Users\devin\AppData\Roaming\npm\node_modules/node_modules/.bin/rollup editor.mjs -f iife -o editor.bundle.js -p @rollup/plugin-node-resolve
-->

in the end used codemirror5
#https://codemirror.net/5/codemirror.zip
#https://codemirror.net/5/doc/manual.html#usage
ok its a start.  

Just load and save language modules for now?  
What should be editable?  
Separate editable from non-editable.  
Dont want to break the functionality.  


