



**web/public/languages/*
Lot of this is not aesthetic code, but..
We can work on aesthetics on the second iteration perhaps if there is still energy to do so.  


**web/public/db.html
Need function to delete older videos possibly or offload.  
View and Download or delete.  
Just have offline indicator.  
Save Remote ->
**web/public/storage_upload.html
update video record to point to external...
Option to keep locally as well.  
Need management interface.  
Display details.  
Need upload/download functionality.  
Just store as a simple JSON record perhaps?  

#https://firebase.google.com/docs/functions/get-started?gen=2nd


> firebase init functions
#https://www.oracle.com/java/technologies/downloads/#jdk24-windows

> firebase emulators:start

#http://127.0.0.1:4000/functions 
#http://localhost:5001/MY_PROJECT/us-central1/addMessage?text=uppercaseme

> firebase deploy --only functions
#https://cloud.google.com/artifact-registry/docs/repositories/cleanup-policy#console
Annoying...
Why cant I configure this..

https://us-central1-MY_PROJECT.cloudfunctions.net/addmessage?text=uppercaseme


**web/public/chat.html
$$Supabase/gte-small


**web/public/test/javascript-vector-database/docs/index.html
> npx webpack
> npm run dev


**timestep.py
add logic to generate client-side vector DB for LLM chat.  


**web/public/chata.html
Try to use this alternative to original server RAG.  
Perhaps just import the bundle and files



**web/public/rec.html
3 tables for vectors for transcript, screens, and additional reference files.  
Weight transcripts most then screens, then files.  

--drag-drop adding of files.  
#https://developer.mozilla.org/en-US/docs/Web/API/HTML_Drag_and_Drop_API/File_drag_and_drop

chunk into smaller sections, just use Page for PDF or maybe around 40 lines or 4000 chars for text.  
Look for logical partition location.  Or use fixed 30 lines for simplicity.  

#https://github.com/mozilla/pdf.js

Add all this to local vector DB.  
When do we run into scaling issue for local DB?  

Sync to shared DB and then interact with shared DB.  
Shared DB is managed by the host.  
And 

#https://firebase.google.com/docs/hosting/cloud-run
For now focus local.  
But we already have the vectors, so we dont actually need the GPU on the server side..
Just a dumb vector similarity search.  All the encoding can be done on client.  


**vecbook
> ~vecbook$ rm * -rf 

**batoru
Need local version vector DB for this.  
#https://github.com/Stevenic/vectra
> npm install vectra
> ollama pull nomic-embed-text


**extensions/vscode/codetutor/src/book.ts

Make query -> vector
and just look for similar vectors and show those areas and following areas of text.  

Then make the augmented query using the content.  
Some sort of system prompt
Use both..

Start with simple strategy like calling the LLM itself to expand the query.  

#https://medium.com/@sahin.samia/building-an-enhanced-rag-system-with-query-expansion-and-reranking-in-python-c95fa9a0a3e8
So just use query expansion in some way.  
Seems just using an LLM query to expand the query.  

def expand_query(query):
    prompt = [
        {"role": "system", "content": "You're an expert in query expansion. Expand the given technical query with synonyms and alternate phrasings."},
        {"role": "user", "content": f"Expand this query for better search: {query}"}
    ]
    expanded = llm.invoke(query)
    return [q.strip() for q in expanded.split("\n") if q.strip()]


#https://hongleizhuang.github.io/files/GenIR2023_Rolf.pdf

Do similarity search with expanded query as well.  



**web/public/book.html
Query generation:
GIT - Topic text and git changes sequences.  
BOOK - Topic text and related topic sequences.  

Question/answer:
same as BOOK
possibly use GENBOOK in some way?  


**book/map.txt 
which exists in each book.  
This just holds folder redirect mapping.  

This should be generated in some automated fashion when folders are copied.  
Not thought through user use-case, but we need something like this.  
In any case, lets start the mapping.  
Take the easy way to generate, just use git renames

> git mv TOPIC NEWTOPIC

> git log --diff-filter=R --name-status
Do we have an easy way to generate this?  
Lets generate a map from this.  
Not sure what happens when reverting to original name occurs..
But a [**map.txt] will be much easier to read.  

No particular need for separate file.  
Just run via Ctrl+Shift+8



**timestep.py
Just do this during timestep.py
Unless dontgenmap flag is set.  
We need a bunch of flags for timestep.py.  



**.bookignore
Need a file like this to prevent loading of map.txt or other such information.  
Some mechanism to know which files are useful and which not so much.  

Too many things...


**git/clone.py
Needed to adjust dates, no logic to add date to non-date-named files.  



**web/public/js/dilbert.js
Just write a new function for Python parse.  
Shouldnt be too hard to just find function names and function -> function graph.  



**web/public/analyze.html
**web/public/video.js
--seekcallback
Instead of adding all these images, lets see if we can just create one image using 
alpha and just get the combined image data.  
Perhaps use decreasing alpha as we go so we can see all images.  
alpha 1, 0.9, 0.8, etc.  
Or perhaps 1, 0.5, 0.45, etc.  
This may get enough of what we want and be simpler.  



**analyze/analyze.py
Need to continue find patterns.  
--getNgrams
$$mappgram
continue..
  mapsgram[ seqgram ] [ pgram ] = { 'time': [], 'iteration': [] }
  mappgram[ signs ] [ pgram ] = { 'time': [], 'iteration': [] }

>python ./analyze/analyze.py --title  "Evil Ways (Sonny Henry)" --force true



**web/public/analyze.html
Need additional control other than comment which records audio and/or video and comments inline.  
For now just audio.  

--highlightVideo
Already have this.  

**web/public/languages/audiocontrol.js
use same "start" "stop" "pause" "unpause"

**web/public/analyze.html
For now just add as feedback in RTDB?  
Kick off with (12,15,15)
Stop with (15,15,12)

**web/public/rec.html
Same process, but add in local DB.  


#https://github.com/goldfire/howler.js#documentation


**web/public/analyze.html
--updateFeedbackUI
OK, so should annotate the graphic with voice icon.  
Playing voice icon and 
Just some icon to represent.  

And change icon if played already or not.  
So have option to filter played data.  

Just use existing voices from SS, and assign voice name to the user.  
#https://support.microsoft.com/en-us/topic/download-languages-and-voices-for-immersive-reader-read-mode-and-read-aloud-4c83a8d8-7486-42f7-8e46-2b0fdf753130


How do we order users?  
For now just keep a tab of likes for users, and prioritize by this?  
Running tally of 
LIKES / (total speaking time)
Local DB for this.  
Show user info when loading audio.  
Need some indicator of what user.  


**web/public/feedback.js
--saveAudioFeedback
Test here..

**timestep.py
Retrieve playlists including favorites / to watch

Maybe this is ok?  
Call Page to add videoid to watch later list.  
Added at.., get video info during [**timestep.py]
Then we have a list to work with.  
#https://github.com/prakhartiwari0/copyYTvideoId


**WrNMxdcfyUk
OK, we have simultaneous entries.  

12 seconds of audio.  
~250kB.  
20kB/s far too much.  


**extensions/vscode/codetutor/src/extension.ts
--getVector

**timestep.py
Same logic to generate all embeddings so no need in front-end.  
Front-end vector generation is too slow at the moment.  
But if we are only generating what doesnt exist, not so bad.  
We have file/line/data/vector.  

**web/public/chata.html
Add FT combined with vector search. 
Then do same in [**web/public/book.html]



Should really do voice clone.  This way we dont need to store the audio.  
We have the audio for training this way.  
Just have an indicator whether the last was correct or not.  
(18) or (19)
Wish we could do inline training.  Probably in another couple years.  
STT and TTS are stupidly huge revenue generators.  
~~MS should just offer something in the OS.  
This will all be client side in another couple years.  
#https://github.com/Hagsten/Talkify?tab=readme-ov-file
Nice, but lot of overhead just for something we already can do with webkitAudio.  
I like the highlighting.  
This seems easier.  

    let text = document.getElementById("text");
    let originalText = text.innerText;
    let utterance = new SpeechSynthesisUtterance(originalText);
    utterance.addEventListener("boundary", (event) => {
      const { charIndex, charLength } = event;
      text.innerHTML = highlight(
        originalText,
        charIndex,
        charIndex + charLength
      );
    });
    synth.speak(utterance);



**codetutor
**extensions/vscode/codetutor/src/tokenizer.tsx
Could implement some sort of custom STT or TTS here much easier.  
Need to finish tokenizer.  

Just save to local DB and then have an option to run STT model improvement from there.  
Then use that model for [**codetutor]
Best we could do at this point?  


**extensions/vscode/codetutor/src/book.ts
--similar
Added similar functionality.  
This should be more seemless.  
Also need to check if topic selection is working.  
@mr /similar **web/public/book.html what are you doing
or
Ctrl+Shift+9
Add chat to find functionality.  
vscode.commands.executeCommand('workbench.action.chat.open', text );

Then we can just add chat participants as needed.  

--summarize **web/public/book.html

Just break up into smaller texts?  
Combine each two sequential.  
For each of these combined texts, just iteratively repeat with resulting texts.  

--meta functionality
Search command from textual similarity.  
Hinderance or nice for usability?  
Lets try it.  
Just basic command search (like MCP), but much smaller scale.  
For each command create a variety of ways to phrase the calling.  
Then use each command sentence as an acceptable match if above X%.  
What is this threshold, and will this actually work acceptably?  

Start summarize functionality.  
Need new definition for summary and similar.  

For now:
~~similarity check
::summarize

Do we need a line extension character?  
I guess we could have a line extension character, or just prefix subsequent lines with the same.  


**vecbook
**extensions/vscode/codetutor/src/book.ts
--addVectorData
Constantly needing to delete the vectra indexes.  

Something is corrupting the vectra indexes.  

```
var a = b;
let c = d;
```

@@vectra
!!Unexpected non-whitespace character after JSON at position 4489804 (line 1 column 4489805)
You have an error in the code somewhere when using the upsert, at the end of the file there are remnants.  


**extensions/vscode/codetutor/src/book.ts
--fixVectraError
This fixes some issue in this library with remnants at the end of json files after using
--vectra.LocalIndex.upsertItem
#https://github.com/Stevenic/vectra/blob/main/src/LocalIndex.ts

OK, so basic similarity search works now.  
Now do the summarize aspect.  

--pickTopic


**web/public/analyze.html
**web/public/language.js
Change current video time to something more readable.  

**extensions/vscode/codetutor/src/book.ts
Some progress.  
Seems like we are getting a summary.  Probably need to use a different model.  
Really need to train model with this type of content.  


> curl -fsSL https://ollama.com/install.sh | sh
> ollama pull gemma3n:latest

Some issue running this model.  


**web/public/page.html
List videos from around times when there was a commit to this page.  
Make that default filter for videos.  

**gemma3n
Seems to take a long time to query.  
The summary from llama3 is tolerable for now.  
Will try other models for code generation.  

**GENBOOK
Should start to save these files.  
I think it will be interesting.  
Add [**GENBOOK] back to original to track.  
~~Should have started saving from the beginning..

Yeah just save to git.  



Need to allow for topic selection
i.e. inline change of [**-1] to previous topic.  

If we have a significant amount of data, the summary gets rid of all links etc.  
Maybe do a reverse RAG and add links after summary?  
Seems a bit random.  
Maybe just add random entries which have similarity after the section of the summary?  
First lets keep time sequence, instead of topic sequence.  

OK, somewhat better results.  
Deduplication is important.  
Also 

Can we use a markdown link to trigger a chat?  
Should probably try to do this.  
i.e. :: or ~~ want to trigger this as it is written.  

For code changes, maybe for now add comments.  


**TROUBLESHOOTING
Add Troubleshooting QR component.  
Where to integrate this?  

**web/public/rec.html
Allow adding text.  


**web/public/db.js
Add text ingestion.  

--drag-drop adding of files.  
#https://developer.mozilla.org/en-US/docs/Web/API/HTML_Drag_and_Drop_API/File_drag_and_drop

**web/public/js/filedrop.js
OK, basic DB struct is there.  
drop_zone is there.  
Just need to adjust handlers.  
Cant get local path name.  So this is a problem.  
Need a tree explorer.  

**web/public/git.js
--loadBook
When reading book, we should generate the directory tree.  



**web/public/rec.html
__Seems to work with name with slashes /

**web/public/chata.html
Implement the vectordb here first.  
Make sure we have components to initialize and query.  

#https://github.com/deftio/quikchat
Should we use a chat UI component?  
Yeah probably.  
But just UI, not data management.  

#https://github.com/SillyTavern/SillyTavern
Try this maybe.  

#https://github.com/brianpetro/obsidian-smart-connections


**web/public/chata.html
Keep time sequence, find similar vector to the text, and then find the next entries in that topic.  
Also just query, and then do rag vector similarity.  
Just adopting from page.html as this is closer to what we want.  
Add vectordb here.  

Files in chat are added permanently?  
I guess this is ok.  


Just get embedding from this

embedding = engine.embeddings.create(input=text_to_embed) # Illustrative, actual method may vary


#https://github.com/mlc-ai/web-llm/blob/main/examples/embeddings/src/embeddings.ts
Perhaps just do this.  

#https://github.com/mlc-ai/web-llm/issues/683


**web/public/page.html
**web/public/chata.html
**web/public/git.js
**web/public/codewindow.js
Need to make selected page larger in visjs components.  
Somewhat better.  

Still need some sort of click handling.  
**web/public/netgraph.mjs
--importDot

**web/public/git.js
--buildTopicGraph
--creategitStruct

Already have time here.  
So just need to enable the timewindow, and set default, and then adjust when the window is adjusted.  
This functionality exists for Book, I believe.  
Do we want to recreate the git struct, I think that is fine.  
Just buildTopicGraph.  
Once we 

**web/public/timewindow.js
--updateTimelineBook

Stop/start keys.  
(23,22,n,23) for video playback
(11,10,n,11) for audio playback
n=track

**web/public/git.js
--gitChartCommits
Need to have mouseover functionality.  


change bookRefs?  
should only include for this page and related?  
Just use the digraph hrefs?  
not sure if it is worth.  

Somewhat better.  
Still some improvement to be done for window activation etc.  

Probably want most recent comments up top.  
Also the git/book mode not working.  

**web/public/chata.html
--ChatBuildContext
Need to add date selection, and if it is over context length, just take part of the file.  

...

Need to pay more attention to folder structure.  

**book/glossary.txt
A = Analyze / Analytics
B = Backup / Book
C = Config / Chat / codewindow
D = DB / Debug / Data
E = extension
F = Feedback 
G = generate / Git / Grammar / Game
H = History
I = install
J = JS tools
K = Keymap
L = Language
M = Music / Midi / Mic / Meta
N = News / netgraph
O = ollama
P = Play / Page 
R = Record / Recent 
S = Stats / Search / Server / Speech
T = Timestep / Test / Tags / TTS
U = users
V = Visualize / Video



**gitcontrol.js
Basic language for browsing through git commits.  

**web/public/chata.html
!!Several times GPU is crashing.  Not sure what initiated.  

Have added basic <gitcontrol> and <audiocontrol>.  

**web/public/languages.js
--getFullPiano
--labelDicRedraw


**web/public/chata.html
Finish vector ingestion for transcripts.  
Load videos from timewindow period.  
When this changes, update the videos.  
Or perhaps just when an object is selected.  
Find videos from the time periods of the commits.  




**web/public/rec.html
Need to allow for selection and positioning and alpha overlay of cameras.  
When rec is done, run the local transcription.  

Also add QR code to the recording screen and adjust this as time goes..

Can we have a hotkey to zoom the browser.  

document.body.style.zoom = "80%";


#https://blog.qr4.nl/page/QR-Code-Data-Capacity.aspx

How to add the QR to the video.  

Try again using this.  
#https://github.com/muaz-khan/RecordRTC/blob/master/simple-demos/video-mirror-recording.html

--captureScreen
We shouldnt be previewing.  
This is a mess now, but closer to what we want.  
Actually overlaying on the screen if possible.  
This may be difficult, may need complexity of plugin or something.  
I think the experience would be more natural though.  
This may be a good tool anyway.  
Also still not getting any opacity.  
Could just do a small python background task.  

**extensions/trey/trey.py
Adding task bar icon, ugh messy...
Yeah this may be important enough that we need something to draw directly.  
Then we can draw the QR code with the info.  
Take some previous transcripts.  As well as ENV information.  

Get hotkey here to activate capture.  
This would need to be triggered to draw on screen.  
Open window and keep session open.  
Then close with separate hotkey.  

OK finally something close to what we want.  
Need to move to other monitor.  

See where this leads..

MIDI -> Can we use to open/close?  
trey < MIDI > QR2
web < MIDI > QR1

$$MIDITYPE ROLI | NORMAL
$$MODE  TREY_QR | TREY_MIDI | TREY_MOUSE

Detect and use generated QR to show screenshot.  
QR as General Comm

Still need to work on KEY ingestion pipeline.  
Not great.  

@@How much interaction with desktop PyQt5 do?  

Add mido to trey.  

@@Can we send messages through midi.  

**mykeys.py
Midi handler for python, started a long time ago.  
See if we can make it cleaner than the JS implementation..

Maybe we should use frequencies instead of arbitrary MIDI ids.  
Well either one should allow for calculation.  

Need to add _meta keys.  

**languages/mousemovement1.py
**config.json
**mykeys.py
OK, some progress with python keymap.  

**extenstions/trey/trey.py
Some problems stopping CMD line.  
Override "languages"
If we override, have to override all.  

It is in the midi somewhere.  
If we dont start midi, it works ok.  

OK, this is fixed.  

Still need to flesh out all the commands.  

<settingscontrol>
/SetTextSize [SIZE] = default font size

<tagcontrol>
/AddTag [NEXT/PREV] 
/RemoveTag [NEXT/PREV]


**web/public/languages/videocontrol.js
<videocontrol>
/Quick Screenshot = Activate panel and use Mouse for drawing.  
/Screenshot [X1,X2,Y1,Y2]
/AddText [NEXT/PREV,X1,Y1] = Use last transcript entry.  

/Start recording
/Stop recording
/Save recording
/Set Speed [T]
/Skip [T]




Also can we detect QR code?  

Need to show NEXT and PREV transcript entries more prominently.  

Create QR on web side for text and detect/display.  



#https://en.wikipedia.org/wiki/Chord_notation

main chord qualities are major, minor, augmented, diminished, half-diminished, and dominant
Cmaj = 0,4,7
Cmin = 0,3,7
Caug = 0,4,8
Cdim = 0,3,6

Slash chords
Cmin0 = 0,3,7
Cmin1 = 0,4,9
Cmin2 = 0,5,8
maj0 = 0,4,7
maj1 = 0,3,8
maj2 = 0,5,9
aug = 0,4,8
dim = 0,3,6


    "0,3,6": Cdim
    "0,3,7": Cmin
    "0,3,8": Abmaj1
    "0,3,5": ?
    "0,3,4": ?
    "0,2,6": "speak", //add the last transcript entry to
    "0,2,5": "delete", //remove last transcript entry    
    "0,12,0": OCT
    "12,0,12": OCT
    "1,13,1": OCT
    "13,1,13": OCT
    "1,2,3": CHROMATIC


**g3D63CoYXVE

@Guido of Arezzo
#https://en.wikipedia.org/wiki/Guido_of_Arezzo

#https://musicnotation.org/systems/
#https://musicnotation.org/system/chromatonnetz-by-joe-austin/
~~Notes should have direction.  
pointing toward another note and time.  
Only forward in time though I think..
Directionality and size representing volume.  

**analyze/analyze.py

Need to create a midi visualization with these aspects.  
Keep staff lines though.  
Default would be line to most similar volume within the next set of notes?

This would be what is used instead of the staff.  
--midiToImage
--ngramToImage

> python ./analyze/analyze.py --title  "Evil Ways (Sonny Henry)" --force true

Still need to fix ngramToImage.  
Create a better visualization.  
Size and directionality.  

How do we extract which notes are pointing to others.  


**extension/vscode/codetutor/src/extension.ts
Should allow for quick copy of text to clipboard.  
Also command sequences should have enough information to be meaningful.  
Or keep this in mind when designing.  
--Try to keep command MIDI meaningful.  

Need to retain previous popup on topic search, or put in chat perhaps if clicked.  

Maybe just detect onopen, we add the last few comments of text from that topic.  
Yeah.  
When reloading a file, topics are regenerated, and so we get duplicates.  
Is this good or bad?  
Yeah lets not duplicate these.  
If we have new ones, they get added at the end.  
Not sure if this is good or not.  
Probably depends on preference.  
Leave for now.  



**mykeys.py
I like this midi handling better than [**web/public/keymap.js]
I should really write more about my code preferences.  
This would be useful information for the future.  

**extensions/trey/trey.py
QPainter sample code not painting
OK..

#https://github.com/nimiq/qr-scanner
Lets try this one.  
import('path/to/qr-scanner.min.js').then((module) => {
    const QrScanner = module.default;
    // do something with QrScanner
});

**web/public/rec.html
**web/public/video.js
OK finally got the hiddencontext to work close to the way I want.  
--drawVideo

Havent kept in mind the ability to re-transcribe.  
Perhaps should consider this more when deciding how to create.  


OK, finally have some incoming QR.  

Need to create a QR transcript.  
Or combine with OCR transcript.  


