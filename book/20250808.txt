



**web/public/languages/*
Lot of this is not aesthetic code, but..
We can work on aesthetics on the second iteration perhaps if there is still energy to do so.  


**web/public/db.html
Need function to delete older videos possibly or offload.  
View and Download or delete.  
Just have offline indicator.  
Save Remote ->
**web/public/storage_upload.html
update video record to point to external...
Option to keep locally as well.  
Need management interface.  
Display details.  
Need upload/download functionality.  
Just store as a simple JSON record perhaps?  

#https://firebase.google.com/docs/functions/get-started?gen=2nd


> firebase init functions
#https://www.oracle.com/java/technologies/downloads/#jdk24-windows

> firebase emulators:start

#http://127.0.0.1:4000/functions 
#http://localhost:5001/MY_PROJECT/us-central1/addMessage?text=uppercaseme

> firebase deploy --only functions
#https://cloud.google.com/artifact-registry/docs/repositories/cleanup-policy#console
Annoying...
Why cant I configure this..

https://us-central1-MY_PROJECT.cloudfunctions.net/addmessage?text=uppercaseme


**web/public/chat.html
$$Supabase/gte-small


**web/public/test/javascript-vector-database/docs/index.html
> npx webpack
> npm run dev


**timestep.py
add logic to generate client-side vector DB for LLM chat.  


**web/public/chata.html
Try to use this alternative to original server RAG.  
Perhaps just import the bundle and files



**web/public/rec.html
3 tables for vectors for transcript, screens, and additional reference files.  
Weight transcripts most then screens, then files.  

--drag-drop adding of files.  
#https://developer.mozilla.org/en-US/docs/Web/API/HTML_Drag_and_Drop_API/File_drag_and_drop

chunk into smaller sections, just use Page for PDF or maybe around 40 lines or 4000 chars for text.  
Look for logical partition location.  Or use fixed 30 lines for simplicity.  

#https://github.com/mozilla/pdf.js

Add all this to local vector DB.  
When do we run into scaling issue for local DB?  

Sync to shared DB and then interact with shared DB.  
Shared DB is managed by the host.  
And 

#https://firebase.google.com/docs/hosting/cloud-run
For now focus local.  
But we already have the vectors, so we dont actually need the GPU on the server side..
Just a dumb vector similarity search.  All the encoding can be done on client.  


**vecbook
> ~vecbook$ rm * -rf 

**batoru
Need local version vector DB for this.  
#https://github.com/Stevenic/vectra
> npm install vectra
> ollama pull nomic-embed-text


**extensions/vscode/codetutor/src/book.ts

Make query -> vector
and just look for similar vectors and show those areas and following areas of text.  

Then make the augmented query using the content.  
Some sort of system prompt
Use both..

Start with simple strategy like calling the LLM itself to expand the query.  

#https://medium.com/@sahin.samia/building-an-enhanced-rag-system-with-query-expansion-and-reranking-in-python-c95fa9a0a3e8
So just use query expansion in some way.  
Seems just using an LLM query to expand the query.  

def expand_query(query):
    prompt = [
        {"role": "system", "content": "You're an expert in query expansion. Expand the given technical query with synonyms and alternate phrasings."},
        {"role": "user", "content": f"Expand this query for better search: {query}"}
    ]
    expanded = llm.invoke(query)
    return [q.strip() for q in expanded.split("\n") if q.strip()]


#https://hongleizhuang.github.io/files/GenIR2023_Rolf.pdf

Do similarity search with expanded query as well.  



**web/public/book.html
Query generation:
GIT - Topic text and git changes sequences.  
BOOK - Topic text and related topic sequences.  

Question/answer:
same as BOOK
possibly use GENBOOK in some way?  


**book/map.txt 
which exists in each book.  
This just holds folder redirect mapping.  

This should be generated in some automated fashion when folders are copied.  
Not thought through user use-case, but we need something like this.  
In any case, lets start the mapping.  
Take the easy way to generate, just use git renames

> git mv TOPIC NEWTOPIC

> git log --diff-filter=R --name-status
Do we have an easy way to generate this?  
Lets generate a map from this.  
Not sure what happens when reverting to original name occurs..
But a [**map.txt] will be much easier to read.  

No particular need for separate file.  
Just run via Ctrl+Shift+8



**timestep.py
Just do this during timestep.py
Unless dontgenmap flag is set.  
We need a bunch of flags for timestep.py.  



**.bookignore
Need a file like this to prevent loading of map.txt or other such information.  
Some mechanism to know which files are useful and which not so much.  

Too many things...


**git/clone.py
Needed to adjust dates, no logic to add date to non-date-named files.  



**web/public/js/dilbert.js
Just write a new function for Python parse.  
Shouldnt be too hard to just find function names and function -> function graph.  



**web/public/analyze.html
**web/public/video.js
--seekcallback
Instead of adding all these images, lets see if we can just create one image using 
alpha and just get the combined image data.  
Perhaps use decreasing alpha as we go so we can see all images.  
alpha 1, 0.9, 0.8, etc.  
Or perhaps 1, 0.5, 0.45, etc.  
This may get enough of what we want and be simpler.  



**analyze/analyze.py
Need to continue find patterns.  
--getNgrams
$$mappgram
continue..
  mapsgram[ seqgram ] [ pgram ] = { 'time': [], 'iteration': [] }
  mappgram[ signs ] [ pgram ] = { 'time': [], 'iteration': [] }

>python ./analyze/analyze.py --title  "Evil Ways (Sonny Henry)" --force true



**web/public/analyze.html
Need additional control other than comment which records audio and/or video and comments inline.  
For now just audio.  

--highlightVideo
Already have this.  

**web/public/languages/audiocontrol.js
use same "start" "stop" "pause" "unpause"

**web/public/analyze.html
For now just add as feedback in RTDB?  
Kick off with (12,15,15)
Stop with (15,15,12)

**web/public/rec.html
Same process, but add in local DB.  


#https://github.com/goldfire/howler.js#documentation


**web/public/analyze.html
--updateFeedbackUI
OK, so should annotate the graphic with voice icon.  
Playing voice icon and 
Just some icon to represent.  

And change icon if played already or not.  
So have option to filter played data.  

Just use existing voices from SS, and assign voice name to the user.  
#https://support.microsoft.com/en-us/topic/download-languages-and-voices-for-immersive-reader-read-mode-and-read-aloud-4c83a8d8-7486-42f7-8e46-2b0fdf753130


How do we order users?  
For now just keep a tab of likes for users, and prioritize by this?  
Running tally of 
LIKES / (total speaking time)
Local DB for this.  
Show user info when loading audio.  
Need some indicator of what user.  


**web/public/feedback.js
--saveAudioFeedback
Test here..

**timestep.py
Retrieve playlists including favorites / to watch

Maybe this is ok?  
Call Page to add videoid to watch later list.  
Added at.., get video info during [**timestep.py]
Then we have a list to work with.  
#https://github.com/prakhartiwari0/copyYTvideoId


**WrNMxdcfyUk
OK, we have simultaneous entries.  

12 seconds of audio.  
~250kB.  
20kB/s far too much.  


**extensions/vscode/codetutor/src/extension.ts
--getVector

**timestep.py
Same logic to generate all embeddings so no need in front-end.  
Front-end vector generation is too slow at the moment.  
But if we are only generating what doesnt exist, not so bad.  
We have file/line/data/vector.  

**web/public/chata.html
Add FT combined with vector search. 
Then do same in [**web/public/book.html]



Should really do voice clone.  This way we dont need to store the audio.  
We have the audio for training this way.  
Just have an indicator whether the last was correct or not.  
(18) or (19)
Wish we could do inline training.  Probably in another couple years.  
STT and TTS are stupidly huge revenue generators.  
~~MS should just offer something in the OS.  
This will all be client side in another couple years.  
#https://github.com/Hagsten/Talkify?tab=readme-ov-file
Nice, but lot of overhead just for something we already can do with webkitAudio.  
I like the highlighting.  
This seems easier.  

    let text = document.getElementById("text");
    let originalText = text.innerText;
    let utterance = new SpeechSynthesisUtterance(originalText);
    utterance.addEventListener("boundary", (event) => {
      const { charIndex, charLength } = event;
      text.innerHTML = highlight(
        originalText,
        charIndex,
        charIndex + charLength
      );
    });
    synth.speak(utterance);



**codetutor
**extensions/vscode/codetutor/src/tokenizer.tsx
Could implement some sort of custom STT or TTS here much easier.  
Need to finish tokenizer.  

Just save to local DB and then have an option to run STT model improvement from there.  
Then use that model for [**codetutor]
Best we could do at this point?  


**extensions/vscode/codetutor/src/book.ts
--similar
Added similar functionality.  
This should be more seemless.  
Also need to check if topic selection is working.  
@mr /similar **web/public/book.html what are you doing
or
Ctrl+Shift+9
Add chat to find functionality.  
vscode.commands.executeCommand('workbench.action.chat.open', text );

Then we can just add chat participants as needed.  

--summarize **web/public/book.html

Just break up into smaller texts?  
Combine each two sequential.  
For each of these combined texts, just iteratively repeat with resulting texts.  

--meta functionality
Search command from textual similarity.  
Hinderance or nice for usability?  
Lets try it.  
Just basic command search (like MCP), but much smaller scale.  
For each command create a variety of ways to phrase the calling.  
Then use each command sentence as an acceptable match if above X%.  
What is this threshold, and will this actually work acceptably?  

Start summarize functionality.  
Need new definition for summary and similar.  

For now:
~~similarity check
::summarize

Do we need a line extension character?  
I guess we could have a line extension character, or just prefix subsequent lines with the same.  


**vecbook
**extensions/vscode/codetutor/src/book.ts
--addVectorData
Constantly needing to delete the vectra indexes.  

Something is corrupting the vectra indexes.  

```
var a = b;
let c = d;
```

@@vectra
!!Unexpected non-whitespace character after JSON at position 4489804 (line 1 column 4489805)
You have an error in the code somewhere when using the upsert, at the end of the file there are remnants.  


**extensions/vscode/codetutor/src/book.ts
--fixVectraError
This fixes some issue in this library with remnants at the end of json files after using
--vectra.LocalIndex.upsertItem
#https://github.com/Stevenic/vectra/blob/main/src/LocalIndex.ts

OK, so basic similarity search works now.  
Now do the summarize aspect.  

--pickTopic


**web/public/analyze.html
**web/public/language.js
Change current video time to something more readable.  

**extensions/vscode/codetutor/src/book.ts
Some progress.  
Seems like we are getting a summary.  Probably need to use a different model.  
Really need to train model with this type of content.  


> curl -fsSL https://ollama.com/install.sh | sh
> ollama pull gemma3n:latest

Some issue running this model.  


**web/public/page.html
List videos from around times when there was a commit to this page.  
Make that default filter for videos.  

**gemma3n
Seems to take a long time to query.  
The summary from llama3 is tolerable for now.  
Will try other models for code generation.  

**GENBOOK
Should start to save these files.  
I think it will be interesting.  
Add [**GENBOOK] back to original to track.  
~~Should have started saving from the beginning..

Yeah just save to git.  



Need to allow for topic selection
i.e. inline change of [**-1] to previous topic.  

If we have a significant amount of data, the summary gets rid of all links etc.  
Maybe do a reverse RAG and add links after summary?  
Seems a bit random.  
Maybe just add random entries which have similarity after the section of the summary?  
First lets keep time sequence, instead of topic sequence.  

OK, somewhat better results.  
Deduplication is important.  
Also 

Can we use a markdown link to trigger a chat?  
Should probably try to do this.  
i.e. :: or ~~ want to trigger this as it is written.  

For code changes, maybe for now add comments.  


**TROUBLESHOOTING
Add Troubleshooting QR component.  
Where to integrate this?  

**web/public/rec.html
Allow adding text.  


**web/public/db.js
Add text ingestion.  

--drag-drop adding of files.  
#https://developer.mozilla.org/en-US/docs/Web/API/HTML_Drag_and_Drop_API/File_drag_and_drop

**web/public/js/filedrop.js
OK, basic DB struct is there.  
drop_zone is there.  
Just need to adjust handlers.  
Cant get local path name.  So this is a problem.  
Need a tree explorer.  

**web/public/git.js
--loadBook
When reading book, we should generate the directory tree.  



**web/public/rec.html
__Seems to work with name with slashes /

**web/public/chata.html
Implement the vectordb here first.  
Make sure we have components to initialize and query.  

#https://github.com/deftio/quikchat
Should we use a chat UI component?  
Yeah probably.  
But just UI, not data management.  

#https://github.com/SillyTavern/SillyTavern
Try this maybe.  

#https://github.com/brianpetro/obsidian-smart-connections


**web/public/chata.html
Keep time sequence, find similar vector to the text, and then find the next entries in that topic.  
Also just query, and then do rag vector similarity.  
Just adopting from page.html as this is closer to what we want.  
Add vectordb here.  

Files in chat are added permanently?  
I guess this is ok.  


Just get embedding from this

embedding = engine.embeddings.create(input=text_to_embed) # Illustrative, actual method may vary


#https://github.com/mlc-ai/web-llm/blob/main/examples/embeddings/src/embeddings.ts
Perhaps just do this.  

#https://github.com/mlc-ai/web-llm/issues/683


**web/public/page.html
**web/public/chata.html
**web/public/git.js
**web/public/codewindow.js
Need to make selected page larger in visjs components.  
Somewhat better.  

Still need some sort of click handling.  
**web/public/netgraph.mjs
--importDot

**web/public/git.js
--buildTopicGraph
--creategitStruct

Already have time here.  
So just need to enable the timewindow, and set default, and then adjust when the window is adjusted.  
This functionality exists for Book, I believe.  
Do we want to recreate the git struct, I think that is fine.  
Just buildTopicGraph.  
Once we 

**web/public/timewindow.js
--updateTimelineBook

Stop/start keys.  
(23,22,n,23) for video playback
(11,10,n,11) for audio playback
n=track

**web/public/git.js
--gitChartCommits
Need to have mouseover functionality.  


change bookRefs?  
should only include for this page and related?  
Just use the digraph hrefs?  
not sure if it is worth.  

Somewhat better.  
Still some improvement to be done for window activation etc.  

Probably want most recent comments up top.  
Also the git/book mode not working.  

**web/public/chata.html
--ChatBuildContext
Need to add date selection, and if it is over context length, just take part of the file.  

