

**web/public/languages/*
Lot of this is not aesthetic code, but..
We can work on aesthetics on the second iteration perhaps if there is still energy to do so.  


**web/public/db.html
Need function to delete older videos possibly or offload.  
View and Download or delete.  
Just have offline indicator.  
Save Remote ->
**web/public/storage_upload.html
update video record to point to external...
Option to keep locally as well.  
Need management interface.  
Display details.  
Need upload/download functionality.  
Just store as a simple JSON record perhaps?  

#https://firebase.google.com/docs/functions/get-started?gen=2nd


> firebase init functions
#https://www.oracle.com/java/technologies/downloads/#jdk24-windows

> firebase emulators:start

#http://127.0.0.1:4000/functions 
#http://localhost:5001/MY_PROJECT/us-central1/addMessage?text=uppercaseme

> firebase deploy --only functions
#https://cloud.google.com/artifact-registry/docs/repositories/cleanup-policy#console
Annoying...
Why cant I configure this..

https://us-central1-MY_PROJECT.cloudfunctions.net/addmessage?text=uppercaseme



**timestep.py
add logic to generate client-side vector DB for LLM chat.  
Maybe just use client to do this.  


**web/public/chata.html
Need to finish chat interaction using client-side DB and do vector search to generate context.  

**web/public/rec.html
already generating vectors.  
Weight transcripts most then screens, then files.  

#https://github.com/mozilla/pdf.js


**vecbook
> ~vecbook$ rm * -rf 

**extensions/vscode/codetutor/src/book.ts

Start with simple strategy like calling the LLM itself to expand the query.  

#https://medium.com/@sahin.samia/building-an-enhanced-rag-system-with-query-expansion-and-reranking-in-python-c95fa9a0a3e8
So just use query expansion in some way.  
Seems just using an LLM query to expand the query.  

def expand_query(query):
    prompt = [
        {"role": "system", "content": "You're an expert in query expansion. Expand the given technical query with synonyms and alternate phrasings."},
        {"role": "user", "content": f"Expand this query for better search: {query}"}
    ]
    expanded = llm.invoke(query)
    return [q.strip() for q in expanded.split("\n") if q.strip()]


#https://hongleizhuang.github.io/files/GenIR2023_Rolf.pdf

Do similarity search with expanded query as well.  



**book/map.txt 
which exists in each book.  
This just holds folder redirect mapping.  

> git mv TOPIC NEWTOPIC

> git log --diff-filter=R --name-status

**timestep.py
Just do this during timestep.py
Unless dontgenmap flag is set.  
We need a bunch of flags for timestep.py.  



**.bookignore
Need a file like this to prevent loading of map.txt or other such information.  
Some mechanism to know which files are useful and which not so much.  

Too many things...



**web/public/js/dilbert.js
Just write a new function for Python parse.  
Shouldnt be too hard to just find function names and function -> function graph.  



**web/public/analyze.html
**web/public/video.js
--seekcallback
Instead of adding all these images, lets see if we can just create one image using 
alpha and just get the combined image data.  
Perhaps use decreasing alpha as we go so we can see all images.  
alpha 1, 0.9, 0.8, etc.  
Or perhaps 1, 0.5, 0.45, etc.  
This may get enough of what we want and be simpler.  



**analyze/analyze.py
Need to continue find patterns.  
--getNgrams
$$mappgram
continue..
  mapsgram[ seqgram ] [ pgram ] = { 'time': [], 'iteration': [] }
  mappgram[ signs ] [ pgram ] = { 'time': [], 'iteration': [] }

>python ./analyze/analyze.py --title  "Evil Ways (Sonny Henry)" --force true




**web/public/analyze.html
--updateFeedbackUI
And change icon if played already or not.  
So have option to filter played data.  

Just use existing voices from SS, and assign voice name to the user.  
#https://support.microsoft.com/en-us/topic/download-languages-and-voices-for-immersive-reader-read-mode-and-read-aloud-4c83a8d8-7486-42f7-8e46-2b0fdf753130


How do we order users?  
Running tally of 
LIKES / (total speaking time)
Local DB for this.  
Show user info when loading audio.  



**WrNMxdcfyUk
OK, we have simultaneous entries.  


**web/public/chata.html
Add FT combined with vector search. 
Then do same in [**web/public/book.html]



**codetutor
**extensions/vscode/codetutor/src/tokenizer.tsx
Could implement some sort of custom STT or TTS here much easier.  
Need to finish tokenizer.  

Just save to local DB and then have an option to run STT model improvement from there.  
Then use that model for [**codetutor]
Best we could do at this point?  


**extensions/vscode/codetutor/src/book.ts

--meta functionality
Search command from textual similarity.  
Hinderance or nice for usability?  
Lets try it.  

~~similarity check
::summarize



**web/public/page.html
List videos from around times when there was a commit to this page.  
Make that default filter for videos.  



**extensions/vscode/codetutor/src/book.ts

Need to allow for topic selection
i.e. inline change of [**-1] to previous topic.  
List selections and be able to add/remove.  


For code changes, maybe for now add comments.  



**web/public/git.js
--loadBook
When reading book, we should generate the directory tree.  



#https://github.com/deftio/quikchat
Should we use a chat UI component?  
Yeah probably.  
But just UI, not data management.  

#https://github.com/SillyTavern/SillyTavern
Try this maybe.  




**web/public/timewindow.js
--updateTimelineBook

Stop/start keys.  
(23,22,n,23) for video playback
(11,10,n,11) for audio playback
n=track


**web/public/chata.html
--ChatBuildContext
Need to add date selection, and if it is over context length, just take part of the file.  

...

Need to pay more attention to folder structure.  


**gitcontrol.js
Basic language for browsing through git commits.  
Need to finish this..



**web/public/chata.html
Finish vector ingestion for transcripts.  
Load videos from timewindow period.  
When this changes, update the videos.  
Or perhaps just when an object is selected.  
Find videos from the time periods of the commits.  





**mykeys.py

<settingscontrol>
/SetTextSize [SIZE] = default font size

<tagcontrol>
/AddTag [NEXT/PREV] 
/RemoveTag [NEXT/PREV]


**web/public/languages/videocontrol.js
<videocontrol>
/Quick Screenshot = Activate panel and use Mouse for drawing.  
/Screenshot [X1,X2,Y1,Y2]
/AddText [NEXT/PREV,X1,Y1] = Use last transcript entry.  

/Start recording
/Stop recording
/Save recording
/Set Speed [T]
/Skip [T]





**g3D63CoYXVE

@Guido of Arezzo
#https://en.wikipedia.org/wiki/Guido_of_Arezzo

#https://musicnotation.org/systems/
#https://musicnotation.org/system/chromatonnetz-by-joe-austin/
~~Notes should have direction.  
pointing toward another note and time.  
Only forward in time though I think..
Directionality and size representing volume.  

**analyze/analyze.py

Need to create a midi visualization with these aspects.  
Keep staff lines though.  
Default would be line to most similar volume within the next set of notes?

This would be what is used instead of the staff.  
--midiToImage
--ngramToImage

> python ./analyze/analyze.py --title  "Evil Ways (Sonny Henry)" --force true

Still need to fix ngramToImage.  
Create a better visualization.  
Size and directionality.  

@@How do we extract which notes are pointing to others.  


**extension/vscode/codetutor/src/extension.ts
Should allow for quick copy of text to clipboard.  
Also command sequences should have enough information to be meaningful.  
Or keep this in mind when designing.  
--Try to keep command MIDI meaningful.  


**mykeys.py
I like this midi handling better than [**web/public/keymap.js]
I should really write more about my code preferences.  
This would be useful information for the future.  



**extensions/trey/trey.py
What actions can we detect that make sense?  
Mouse-click on window.  
Other..


**extensions/trey/trey.py
Need some config for this.  



**web/public/book.html
60 seconds??
~~Maybe limit the time window to 1 year..






**web/public/book.html
Need a nice tree view UI for files.  
Only view on web.  
#https://github.com/vakata/jstree
Hmm..
Maybe just use instead of filter files.  

use [**map.txt] to update names when reading book.  

Lets add background colors to the components what we imagine being used first/etc.  
LLM UI -> red
Current question -> Orange
Transcript -> Yellow
Selection History -> Green
AI Responses -> Blue
Code -> Indigo

Are we loading MIDI feedback?  

$$/testing/vscode/vscode-extension-samples/lsp-sample>
> npm install

!!error TS2552: Cannot find name 'HTMLElement'
== 
#https://code.visualstudio.com/api/language-extensions/language-server-extension-guide
> npm install
> npm compile

**codetutor


**extensions/vscode/codetutor/src/book.ts
!!Fetch failed
~~ > sudo systemctl restart ollama

Maybe dont take too much general info on commands.  
:: **web/public/js/filedrop.js
Responses should be more specific to the selected topics.  

Summary working a bit better now after removing duplication in topics.  
Similar not working as well as I would like.  

Maybe do some query expansion on ~~

Default markdown reading has too many folder paths.  
How to turn this off?  


--summary
Try to do some smart search for relevant topics and create some direct links to that information.  
Perhaps as simple source links.  


**extensions/vscode/codetutor/src/book.ts
Should be able to ask question
@@ Question
OK..


Do we need LSP?  
--triggerUpdateDecorations
--updateStatusBarItem


So if we actually use 
@dj:slack ....
How do we find the relevant thread, or do we even try?  
Just mark with the current topic and relevant info.  

How to handle multiple topics in a row? 
This is causing many responses to have blank entries in similar search.  
Maybe hold a prev/next node when scanning.  
and if blank go to next.  

**web/public/languages/gitcontrol.js
Try to use this..
Prev/next


**RECDROID
Need simple automated sound recording device.  
This is a good idea, but there is no need for a separate device for this.  

$$FLUTTER
$$vscode

#https://github.com/flutter/flutter
#https://manthankhandale.medium.com/make-a-sound-recorder-in-flutter-d64fd0809f6c



#https://github.com/TheGuyDangerous/Voicerra


Use this
#https://github.com/gyakhoe/voice_recorder
combine with bluetooth midi device.  
#https://developer.android.com/develop/devices/assistant/overview
Or just integrate with this.  


Then need to make start/stop like this.  
#https://github.com/actions-on-google/appactions-fitness-kotlin

[**RECDROID] launches and records until next signal.  
#https://www.geeksforgeeks.org/android/adding-firebase-to-android-app/



**web/public/rec.html
Ingesting vectors.  
When ingesting, need to define file location?  


**web/public/chata.html
Create RAG implementation with local vector DB.  
Just use ingested text for now.  
Automatically ingest /book folder into vectors if they dont exist.  
@@How to prevent ingesting full book each time?  

**web/public/js/filedrop.js
--ingestText

Need datestamp in vecDB.  
Order by date in RAG query.  

Delete all file entries before reingest?  

OK, so entries are added.  
Not sure if we need to make them same size or not.  
For now just keeping as is.  

**web/public/git.js
--initGitIndex
Basic generation of vectors done.  
Not exactly, but close enough for now..
When we have a query, get similar vectors, and use the text from these similar vectors in context. 
Original query should not have topic
How long does this take.  
--updateGitIndex
Is this what we want, just a temporary index recreated every time?  
Need to save sequence of interactions, but this should be sufficient?  
Sequence of steps need to segregate from actual current data.  



**web/public/js/ayuda/date.format.js
**web/public/clock.js
Unwanted dependency here.  


**web/public/chata.html
Finish RAG here.  
Order in time.  
Create expanded query, and retrieve further context if needed.  

**web/public/data/transcripts.json
Should also load transcripts.
For now just load static transcripts.json
If not existing in vecDB add it for chat responses.  

Simultaneously list videos from around those times.  

--loadTranscripts
OK, buggy but chata.html loads git and transcripts.  

auto-play certain areas after return similar.  

Load <videocontrol> to use prev/next.  

Need to delete [**web/public/test/javascript-vector-database/files/embeddings.json]
This is an unused 80MB file in the repo.  

> git rm --cached ./web/public/test/javascript-vector-database/files/embeddings.json




**web/public/chata.html
--ChatBuildContext
Need to not pass so much.  
Or just wait for context window for [**WEBLLM] to improve I guess?  

**web/public/recent.js
--loadAllRecent
allow to pass date.  
When we get git, need to search around the date/time of changes to the selected topic.  
Just retrieve 20 or so from that date, change date.  

+/- 2 days.  

**BATORU
Need to get full feedback loop.  
Currently there is no training of model being used.  
Just takes so much energy.  
For now just do this with local ollama.  
Need to start at least a fine-tune loop.  


**extensions/vscode/codetutor/src/extension.ts
Use 
^^# to generate comments.  
^^+ to generate suggestions to add.  
^^- to generate suggestions to remove.  
^^& to generate book.  
Continue here..
Need book
Make a command for each of these?  
I guess.  
\gencomments - same as gencode, But dont include commits with no comments.  
\gencode - Get FULL Topics, Order ALL GIT changes include book changes as well.  
\gendelete - This is tricky but important.  Maybe try a code coverage plugin.  
\genbook - Get FULL Topics, Get GIT changes to book in sequence.  


So by reading the book into the topic struct, dont actually need the code.   
Need to create statistical info on each topic.  
i.e. What commands are part of each topic and how many times.  
Create Structure for this info.  
Focus more on sequence of events directionality.  

copy from [**web/public/git.js] perhaps..
Try to use this:
#https://github.com/octokit/octokit.js
Or lets just use local cmd line.  

#https://github.com/isomorphic-git/isomorphic-git
#https://github.com/steveukx/git-js

Save current branch.  
> git branch --show-current
$$BRANCHNAME
> git branch $$BRANCHNAME
> git switch $$BRANCHNAME
..
> git switch $$ORIGBRANCH
> git merge


Create a branch each time we run the improvement process.  
Or keep branch for each topic.  

^^+ to generate.  
Find launchable page which includes this topic.  
All launchable pages should be tried if possible.  
Start recording..
Launch [**PAGE]
Use [**PAGE]

Switch back to extension.
Make updates..
Show updates for time..

Redeploy
Use [**PAGE]
Make observations and compare with previous iterations.
add to [**GENBOOK]

Launch other operations.. from [**GENBOOK]

Accept/decline changes based on results and check prompts.  

Make summary information about changes.
Add to [**GENBOOK]

Merge branch..


List launched operations from [**GENBOOK]

Only one branch at a time for any topic?  
For now on failure just delete and start over?  
Track how much failure.  

Repeat process.


**extensions/trey/trey.py
Need commands to show past recordings, perhaps default show X years ago at some point.  

**extensions/trey/playwrighty.py
Lets just interact with the UI using this.  
#https://github.com/microsoft/playwright-python

$$music
> playwright codegen --target=python -o ./languages/words/test/my_test.py https://google.com

**languages/words/test
How to be a robot without being a robot.


**languages/hotkeys.py
Need to pass params.  
Test start me.  
OK works I guess..

Maybe need a start listening and stop listening for each language.  
Or setting to start on load or not.  
Or perhaps have a start sequence which just runs through mykeys.  
Still need turn on/off words.  


**languages/words/test/my_test.py
element_locator = page.locator("#myElement")
bounding_box = await element_locator.boundingBox()

What is sender/receiver?  

**languages/words/_meta/speak.py
From screen -> text -> voice
#https://huggingface.co/hexgrad/Kokoro-82M
#https://github.com/hexgrad/kokoro

Create word/location map based on this.  
Need interrupt command.  
Try to identify interactable objects.  
#https://github.com/srebroa/awesome-yolo?tab=readme-ov-file

#https://neptune.ai/blog/object-detection-with-yolo-hands-on-tutorial

!!ImportError: numpy.core.multiarray failed to import
~~>pip install --upgrade opencv-python, numpy

OK, so how do we get a yolo model for screen?  
Or just move the mouse around the screen and detect the link cursor changing.  

Seems like fun, but maybe dont need this complexity.  
Just detect mouse change to try to detect boundaries of interactive objects.  

mouse.position

mouse.move_relative

**analyze/ocr.py
Get info on text position throughout.  
Put mouse on any text that is available and see if it is interactive.  

Then summarize the text, how to do this in a meaningful way?  
Annotate results and areas.  

#https://github.com/UB-Mannheim/tesseract/wiki

$$PATH += C:\Program Files\Tesseract-OCR

Add this to [**extensions/trey]

Just use the ocr info for now.  
Not picking up formatting, but have enough info here to do some interesting things.  
With simple pages.  
Put the Page text into LLM and grade response on grammatical correctness.  
If most things look grammatically correct, then use, otherwise notify the user that result quality is not ideal. 

Also get a summary of the page contents.  
And areas we can click (hand icon detection)

**languages/hotkeys.py
Try to read screen.  
53, 50
..


#https://github.com/hexgrad/kokoro/tree/main/kokoro.js

Try this as default TTS.  
For now use with [**extensions/trey/trey.py]

Adjust config here.
mykeys.languages[..].config = ...

Generate sound for CRLF

**generate/generatetts.py
> espeak-ng.msi

Works, but far too slow..
#https://github.com/nateshmbhat/pyttsx3

More like what we need, really should get better voice.  
Maybe use this one for real-time, and generate with good voice if want to read whole page.  

**extensions/trey/trey.py
OK finally have some speech.  
Why do I have to use pygame, not sure, but the others playsound and simpleaudio caused problems.  

Most usage will be browser anyway.  



All asynchronous as this will take time.  

!!playsound never releases file
~~pip install playsound3

#https://github.com/rany2/edge-tts
Much faster to just use built-in.  

!!edge_tts.exceptions.NoAudioReceived: No audio was received. Please verify that your parameters are correct.
This occurs when input is too short.  
Also why do we have to pass line by line?  

Need an interrupt.  
Scan page, and 
Match locations of text with location of links

OK, so skip lines works.  
Queue management, not great I think, but we can pass info.  


**KEYMAP

primarily 3-key
Start letter controls language/function:
48 -> Meta function
49
50
51
52 -> error
53 -> Screen control navigation
54 -> ok
55 -> good
56
57
58
59 -> Lang control
60 -> Meta function
61
62
63
64 -> error
65 -> Screen control input/selection
66 -> ok
67 -> good
68
69
70
71 -> lang control
72 -> meta (none)

53 and 65 start key.  

$$(-21,-108) = 88 keys
$$(-20,+20) = relative change.  
greater than 20 diff is not part of same sequence?  
$$(+21,+108) = 88 keys
$$109+ = ?  


**KKEYS
ALL SQUARES
1,4,9,16
25, 36, 49, 64, 81, 100
28, 31, 56, 60, 90



Once we detect no word exists, reset?  
Create a structure of combination of first set of 2 and 3 letters.  
Simple Tree structure
KK[108][108] = null
Then set to data if exists.  




**CCONTROL
Launch browser tab or window (optional search string)
Detect scrollbar of active window.  
Indicate page layout and location in page with sound.  
Selected portion of page just use chromatic percentage.  
Page up, page down
Start reading immediately
Summarize full page
Read full page


--check mykeys.key
Read from beginning of word only.  

Help should be same:
Octave?  
48,60,48 = help 
53,65,53 = help 
etc.


21 -> Start
22 -> End
107 -> Pause
108 -> Unpause


**web/public/languages/audiocontrol.js
**web/public/languages/videocontrol.js
**web/public/languages/book.js
**web/public/gitcontrol.js
Each of these needs to be retooled to use relative offset.  
Just use keybot["lang"]

OFFSET:
_meta = 0
videocontrol = 1
book = 2
gitcontrol = 3
error = 4
screencontrol = 5 (53)
ok = 6
good = 7
generate = 8
find = 9
auto-generate? = 10
lang = 11



RELATIVE STRUCT:
0,1 = help
0,1,12 = list commands
0,1,2 = 0,2 commands
0,1,3 = 0,3 commands etc.  

0,2 = 

What to do for octave spanning commands?  
For now octave spanning just calculate which octave, but only use %12 value



for now..
Probably need to combine some..
(53,55,59) Page
Test..

@@How to do continuation?  
Cant find a good strategy for this..
Octave jump?
Previous note?
Maybe time??
configurable slight delay OR octave jump?  
Maybe try both

So if we are waiting return in SEQ.  
From there we can recall the lookup.  

And redo search..



*STT
Try this for STT
#https://github.com/speechbrain/speechbrain

from speechbrain.inference import EncoderDecoderASR

asr_model = EncoderDecoderASR.from_hparams(source="speechbrain/asr-conformer-transformerlm-librispeech", savedir="pretrained_models/asr-transformer-transformerlm-librispeech")
asr_model.transcribe_file("speechbrain/asr-conformer-transformerlm-librispeech/example.wav")

Training..
#https://speechbrain.readthedocs.io/en/latest/tutorials/tasks/speech-recognition-from-scratch.html


**mykeys.py
See if this still works.  
OK, there is some lag in the cursor change.  
Also need to try to determine if the link is the same as the previous link.  
Really want the DOM I think.  
Maybe can hack by prevword has link etc.  

Wikipedia seems to work ok.  Still some mixing of data together.  
Need to try to detect X gaps, and change the block etc.  
#https://pyimagesearch.com/2021/11/15/tesseract-page-segmentation-modes-psms-explained-how-to-improve-your-ocr-accuracy/

hmmm...
not much help.  
Try to get wikipedia to work well to start.  


