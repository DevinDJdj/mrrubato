**news.py
Yep:
#https://github.com/codelucas/newspaper

**0606
Need to do one match in order to have sample data.  
Did we ever finish creating the language?  

Yeah lets use part of this for TTS and then 
#https://github.com/lxe/wasm-gpt?tab=readme-ov-file

**web/public/db.html
Does the export actually work with large amount of data?  

Add import..


**web/public/page.html
**web/public/test/sensors/gesture/index.html
add sensor to page.  

**web/public/test/testfilbert.html
**web/public/test/testacorn.html
Can we use this struct to generate a DOT graph?  


**timestep.py
--Add spin up / spin down of backend.  
And wait...
Then we get some transcriptions if there is available hardware at the time of timestep.py


**FLOW
--rec
--analyze
->
--book
--page

**web/public/test/whisper/testwhisper.html

Perhaps switch speech.js to use this.  
#https://stackoverflow.com/questions/79406943/using-whisper-cpp-in-sveltekit
yep, same.  


**web/public/analyze.html
Need to add tabs to this.  
Tab for reviewing topic images.  
Lets just review the image when clicking

If topic not found, load book portion.  

Change the build context to use this last.  

What should default query be?  


**web/public/codewindow.js
not great...
Try to get a sample running.  


**web/public/analyze.html
mobilenet needs GPU.  
So image analysis will not work otherwise. 
Still saves data, but no image analysis will occur.  

**web/public/db.js
Try classifierDB->saveKNN
getKNN
--here still...


How do we snapshot the models?  
Do we want models to be per topic?  
Probably both per topic and general.  
Not sure how large the general will get though.  
Then combine the results of general language classifier and topic specific language classifier.  
To find other iterations of the words.  




Also VideoSnapper should have more details in logic based on language.  This should probably be a dynamic function call.  

VideoSnapper.buildFrames
    if (lang=="base"){ //just taking ~ piano portion of the output.  


  setClassifierDataset(classDatasetMatrices: {[label: string]: Tensor2D}) {
    this.clearTrainDatasetMatrix();

    this.classDatasetMatrices = classDatasetMatrices;
    for (const label in classDatasetMatrices) {
      this.classExampleCount[label] = classDatasetMatrices[label].shape[0];
    }
  }


**web/public/book.html
Need find functionality.  
Search within book and/or code.  
Add all to flexsearch and then query it.  
**web/public/git.js
--initGitIndex
**web/public/db.js
gitDB.ftsindex

Keep ftsindex in DB struct.  

**GENBOOK
add annotations after Q/A.  
--mynote

inside of answer we may have markup sometimes.  So should ignore ** within ANSWER 
between == $$
Not sure this is possible practical.  


Interesting way to possibly write a book as well.  
Significant redundancy though I would expect.  
There is always a bit of boilerplate to the responses from the LLM.  
But a small amount of that is good I think.  Very tough to balance.  



#https://stackoverflow.com/questions/79406943/using-whisper-cpp-in-sveltekit

Lets run in local node.  
#https://emscripten.org/docs/getting_started/downloads.html#sdk-download-and-install
#https://github.com/ggerganov/whisper.cpp/tree/master/examples/whisper.wasm
build and output.  

**web/public/test/whisper/out/index.html
This seems to work better if built.  
So go through build process...
>mkdir build-em && cd build-em
>emcmake cmake ..
>make -j

# copy the produced page to your HTTP path
>cp bin/whisper.wasm/*    /path/to/html/
>cp bin/libmain.worker.js /path/to/html/


OK, that seems to work.  
So is it/it is worth the trouble to change out all of the webkit.SpeechRecognition.  

Lets try it i.e. in book and see if we speak more.  
Combine with testwhisper to automate getting audio.  
Add gesture to start/stop audio, and test to make sure we can get useful transcription and input.  
Good test case.  
This can be in addition to using midi device.  
LEFT WINK = lastspokenword = "comment"
comment 
RIGHT WINK = lastspokenword = "..."
Handle gesture through the same linguistic arrangement.  

**web/public/gesturemap.js
gesturemap .. same as keymap...
combine with this.  
**web/public/test/sensors/gesture/script.js
**web/public/test/sensors/gesture/index.html





