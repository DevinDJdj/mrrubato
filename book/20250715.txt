**PAUSELOGIC

var lastPause = 0;
var pauseTime = 0;

var recorder


recorder = recordRTC

function getPauseTime(){
    if (recorder ===null){
        return pauseTime;
    }
    if (recorder.state === "paused") {
        return pauseTime + Date.now()-lastPause;
    }
    else{
        return pauseTime;
    }
}

document.getElementById('btn-pause-recording').onclick = function() {


 if (recorder.state === "recording") {

     recorder.pauseRecording();
     lastPause = Date.now();
     $(this).html('Resume Recording');
   //  Console.log(recorder.state);
     // recording paused
 } else if (recorder.state === "paused") {
     $(this).html('Pause Recording');
     recorder.resumeRecording();
     pauseTime += Date.now() - lastPause;
     // resume recording
 }
 return false;

}

  function getTimeFromSecs(secs){
    //remove pause time.  
    secs = Math.floor(secs - getPauseTime() / 1000);



**web/public/rec.html

on <videocontrol>help, make "dictable" div visible.  and hide "capturescreen"
Works ok..

**web/public/languages.js
--playWord 
not working as expected.  
OK, fixed.  


Continue, see if <videocontrol>help works.  
Also why are played commands not showing in dictable?  


**web/public/languages/*
Lot of this is not aesthetic code, but..
We can work on aesthetics on the second iteration perhaps if there is still energy to do so.  


**web/public/db.html
Need function to delete older videos possibly or offload.  
View and Download or delete.  
Just have offline indicator.  
Save Remote ->
**web/public/storage_upload.html
update video record to point to external...
Option to keep locally as well.  
Need management interface.  
Display details.  
Need upload/download functionality.  
Just store as a simple JSON record perhaps?  

Several alternatives to dexie.js, but too much time to evaluate them...
For now just try to make a mapping.  
100M words over lifetime.  
Just download all and index locally.  
Not sure if this is practical or optimal, but dont want to add complexity.  
For now do all client side.  
Server is just dumb storage except for already done language sharing.  
If this is the case, we can just send files.  
Then if we want to build shared DB later, we just ingest all those files and build a searchable service.  
???
Or just ingest into a model???

#https://github.com/kingjulio8238/Memary
#https://github.com/mem0ai/mem0
#https://www.falkordb.com/
#https://en.wikipedia.org/wiki/Cypher_(query_language)
#https://neo4j.com/blog/cypher-and-gql/cypher-gql-world/
#https://neo4j.com/
#https://cloud.google.com/products/spanner/graph?hl=en
Hmmm...
#https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/graphrag/graph_rag_spanner_sdk_adk.ipynb
#https://cloud.google.com/spanner/docs/graph/set-up

#https://cloud.google.com/run/docs/tutorials/function-sends-query-to-spanner-database

#https://stackoverflow.com/questions/52233949/passing-variables-to-google-cloud-functions


To use or not to use..
Need to do simple server side at some point anyway..

#https://firebase.google.com/docs/functions/get-started?gen=2nd


> firebase init functions
#https://www.oracle.com/java/technologies/downloads/#jdk24-windows

> firebase emulators:start

#http://127.0.0.1:4000/functions 
#http://localhost:5001/MY_PROJECT/us-central1/addMessage?text=uppercaseme

> firebase deploy --only functions
#https://cloud.google.com/artifact-registry/docs/repositories/cleanup-policy#console
Annoying...
Why cant I configure this..

https://us-central1-MY_PROJECT.cloudfunctions.net/addmessage?text=uppercaseme

ok, not perfect, but ..
Redo with python..  
Easier to interact with other tooling.  
#https://firebase.google.com/docs/storage/extend-with-functions?gen=2nd
--onObjectFinalized


#https://github.com/adhazel/graphrag_demo/blob/main/Use%20Case%20A%20Research%20Assistant.ipynb

#https://sandeep14.medium.com/running-graphrag-locally-with-neo4j-and-ollama-text-format-371bf88b14b7
really want all in browser if possible.  


#https://neo4j.com/docs/neo4j-graphrag-python/current/user_guide_rag.html#using-another-llm-model

#https://github.com/kuzudb/kuzu
#https://github.com/kuzudb/wasm-linkedin-example
Not exactly.. this is just loading the linkedin DB info, and using the LLM to translate.  


**web/public/chat.html
#https://github.com/pubkey/javascript-vector-database
#https://rxdb.info/articles/javascript-vector-database.html
Not Graph, but this is close to what we want..
Can we get a version of this working..
Ingest transcripts, then use WebLLM combined with this vectordb similarity search.  

Lot of excess data when pulling the transcript in each record, about 2x what is necessary.  
10kb per record should be more than fine..
Means we pull about 10mb or even 100mb who cares.  

We will have this vectordb search for some time, until we have extremely long context windows.  
But even then, this is excess computing power wasted by passing the long context window for the most part.  
#https://github.com/pubkey/rxdb

#https://github.com/pubkey/rxdb-quickstart?tab=readme-ov-file

!!firebase RTDB limitation have to get entire document, cant get only specific children..
Really annoying.
So would have to create a subtree
transcriptions -> vid -> transcription..
Started this
/transcript/byuser
/transcript/byvideo
This is the kind of limitation that makes you want to change DB.  
~~This cant be that difficult to code

> cd testing
> git clone https://github.com/pubkey/javascript-vector-database.git
>npm install
> npm run dev

Hmmm.. unfortunately the actual results are quite poor.  
Not sure I want to use..
Try different model..
$$Xenova/paraphrase-multilingual-mpnet-base-v2
This didnt work well at all.  

$$Supabase/gte-small
This works quite well.  
OK, lets try to deploy this.  


**web/public/test/javascript-vector-database/docs/index.html
OK, this seems to work.  
> npx webpack
> npm run dev
Just had to change file input location.  
Now need to load app specific data, and adjust display mechanisms.  
For now just generate the transcript JSON data with batch so dont need to bother loading.  
[{"id": xxx, "body": ""}, ..]
Adjust if we feel necessary.  

**web/public/test/javascript-vector-database/src/index.ts
--submit
--textToHtml
Adjust here to our liking.  

OK, so we are loading dynamically.  
--resetTranscripts
Need a reload function.

Also need to create links for video and add description info.  
bulkInsert doesnt update existing entries.  




Delete ->
remove video record.  
Save screenshots.  


**timestep.py
add logic to generate transcripts for use in client-side vector DB for LLM chat.  

OK
**data/transcription/trans.json
See if we can use this with the vector database in any meaningful way.  
Then add to or replace [**web/public/chat.html]

**web/public/chata.html
Try to use this alternative to original server RAG.  
Perhaps just import the bundle and files



**web/public/rec.html
Same functionality here.  
Allow this to be interchanged for another better solution if available. 
3 tables for vectors for transcript, screens, and additional reference files.  
Weight transcripts most then screens, then files.  

--drag-drop adding of files.  
#https://developer.mozilla.org/en-US/docs/Web/API/HTML_Drag_and_Drop_API/File_drag_and_drop

chunk into smaller sections, just use Page for PDF or maybe around 40 lines or 4000 chars for text.  
Look for logical partition location.  Or use fixed 30 lines for simplicity.  

#https://github.com/mozilla/pdf.js

Keep date, and weight more recent files, or selected time period.  
How do we do that with vector search?  
Perhaps shard each year for now.  

What is local file key?  

Sync to shared DB and then interact with shared DB.  
Shared DB is managed by the host.  
And 

#https://firebase.google.com/docs/hosting/cloud-run
For now focus local.  
But we already have the vectors, so we dont actually need the GPU on the server side..
Just a dumb vector similarity search.  All the encoding can be done on client.  


**batoru
Need local version vector DB for this.  
Perhaps..
#https://github.com/milvus-io/milvus

Maybe just use this as well?  

#https://rxdb.info/fulltext-search.html


Maybe try this for local implementation?  
#https://github.com/Stevenic/vectra
I like the API and structure simplicity.  

> npm install vectra
> ollama pull nomic-embed-text

**extensions/vscode/codetutor/src/book.ts
Seems to work with added vectra DB of nomic-embed-text
Not sure how we will use this yet..
There are some issues with malformed topics, i.e. ending in ** etc.  
But seems to work.  
vecbook = 200MB vs 
book = 600 KB 
seems a bit much..
x300

Some duplication, maybe x5?, but the primary issue is vectors are all stored in text/JSON which is not ideal.  
This is a x25, x10 expansion or so just with the vectors.  
This becomes unworkable in a few years possibly.  
Not sure, may be close to linear.  
perhaps dont do each individual entry, do the topic in 1KB segments.  
Later..

@@vectra
--LocalIndex.upsertItem has some issues.  
It creates some duplication.  Unclear to me at this point what duplication is occurring.  
OK, using 
--LocalIndex.listItemsByMetadata
This clears this problem for the most part.  
Still increasing 20KB or so each time it is run, not sure where this leak is.  
But tolerable for now.  


#https://docs.weaviate.io/weaviate/quickstart
Prefer simplicity of just interacting with a file.  
hmmm...

What has typescript interaction, but just local file/folder?


