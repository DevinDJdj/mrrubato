
**server/transcription/transcribe.py
set up and use this if possible.  Or create separate transcribe2.py
https://github.com/coqui-ai/STT/blob/main/notebooks/train_personal_model_with_common_voice.ipynb
https://medium.com/visionwizard/train-your-own-speech-recognition-model-in-5-simple-steps-512d5ac348a5


**web/public/analyze.html
id="transcript" 
Save same result we get to 
/words/YYYY/file
And /misterrubato/[videoid]/transcript/
When updated via UI, update this file contents as well.  
Perhaps need .xxx ms as well


**web/public/recent.html
Need recent watch as well as created.  
Add watch parameter
watch=true

sort by: 
/watch/[videoid]/snippet/addedAt

add value:
/watch/[videoid]/comments/[uid]/pctWatched

Use these two parameters to sort results.  


**web/public/analyze.html
**web/public/keymap.js
Need midi command to mute the sound output from feedback in case this is already audible.  
Mute/unmute
mute = 12,6,6,12,0
mute output = 12,6,6,12,1
set volume 100% = 12,6,6,12,24
additional pause/play with set speed.  
pause = 0,1,1,0,0
play = 0,1,1,0,1
add commands to meta track.  
Need volume control for feedback.  
Need a display of the midi feedback in real-time, have a x second window to generate.  
Create possibility to associate color with words.  
Assign color with keys.  
Similar function
"change color for " word (color, 12-12)



**analyze/analyze.py
launch process to do transcription via server.  
Exchange this for current local client process.  


**web/public/analyze.html
test filter functionality


**web/public/keymap.js
How do we make this more ordered?  

**web/public/chat.html
**web/public/analyze.html
Show user icon of logged in user.  
Check how prompting works and change user function.  
Annoying but I think we need it.  


**server/transcription/loadall.py
re-transcribe all data after changing back to whisper-large.  
Or changing to STT mechanism.  

**server/transcription/transcribe.py
Need to be able to load from MEDIAFILE.  
/transcribe/?videoid=sdtc1to0CM8&mediafile=https://storage.googleapis.com/misterrubato-test.appspot.com/videos/2024-06-04%2022-00-17.mp4&st=141,541,949,1321&et=529,885,1286,1657
--fixed I think.  
**timestep.py
test.  


**record.py
change to use this transcription
/transcribe/?videoid=sdtc1to0CM8&mediafile=https://storage.googleapis.com/misterrubato-test.appspot.com/videos/2024-06-04%2022-00-17.mp4&st=141,541,949,1321&et=529,885,1286,1657
Save to DB and to text file.  
pull from timestep.py (535)
change transcribe_me to point to separate function same as in timestep.py

