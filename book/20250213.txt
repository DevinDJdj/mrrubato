**news.py
Yep:
#https://github.com/codelucas/newspaper

**0606
Need to do one match in order to have sample data.  
Did we ever finish creating the language?  


#https://github.com/ggerganov/whisper.cpp/blob/master/examples/whisper.wasm/index-tmpl.html

Yeah lets use part of this for TTS and then 
#https://github.com/lxe/wasm-gpt?tab=readme-ov-file


**web/public/recent.html
Add stats like number of transcribed words and/or summary of transcript.  
reorganize table column sizes.  

**web/public/rec.html
**web/public/rec.js
saveTranscript/loadTranscripts
saveLocal/saveRemote
indicate whether this is private/public.  
#https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API/Using_IndexedDB

**web/public/test/testdexie.html
**web/public/js/flexsearch/test.html

**web/public/config.js
Make a class at least even if not full ES6.  
Leave original vars.  

**web/public/grammar/midi.ne
**web/public/grammar/keys/keys.ne
Try simplistic number sequence -> word generation.  

**web/public/grammar/book/booka.ne

**web/public/test/sensors/gesture.js
--onFaceResults

Adjust this to recognize 
Eyebrow raise/lower
Head nod/NESW
Eye closure

**web/public/timewindow.js
When item is selected, this window jumps to the bottom.  
Need to fix that. 


#https://github.com/google-deepmind/alphageometry


**web/public/rec.html
switch all service calls to indexeddb.  
--OK, easier than I thought to get this working.  Nice.  
--can we use FTS?  
this should be automated to save on stop recording?  
Or use saveLocal button?  Yes I think this will be fine.  


**web/public/db.html
What do we want to do here.  What should DB be named?  
use same schema?  
Does the export actually work with large amount of data?  

Add import..
Continue switching the service.py

**web/public/git.js
--selectGitRepo
--initGitIndex
ftsindex how to use this local search?  


**web/public/book.html
When we load changes
Load a graph which shows relationship between files.  
Switch between this graph and the word2vec SVG.  
Be able to select the change and keep it in the code editor.  
More changes at same time = fatter graph edge.  
Each node should be selectable and show changes correlated to the originally selected file.  
A separate link should just load the file same as timewindow.  

--gitgraph

**web/public/timewindow.js
Continue with filter files.  
#https://visjs.github.io/vis-timeline/examples/timeline/groups/visibleGroups.html
#https://visjs.github.io/vis-timeline/examples/timeline/groups/groupsEditable.html

groups.update({
    id: group.id,
    visible: false
});

in our case vgroups
--groupFromName

Need filter in/out
For now just use delimited folders.  
i.e.
web/public/game;web/public/js;generate;

and in/out flag.  
Clear filter...

and find files...
search by name.  

Or use selectedtopics and all correlated.  
Find includes in the source.  
Possibly chain includes....
Maybe this is more practical.  
--hideGroups
--hideItems
--start here.  

end goal?  
Find all changes in timewindow for selectedtopics and includes...

**web/public/test/sensors/gesture/index.html
Gesture recognition.  Lets use this for UI manipulation.  
#https://codepen.io/mediapipe-preview/pen/OJBVQJm
following works well with this model.  
browDownLeft/browDownRight - 0.6
browOuterUpLeft/browOuterUpRight - 0.6
-scroll up/down

eyeBlink - 0.6 sequential number of blinks within period.  
-3 or more ?  

jawOpen/mouthFunnel - 0.3/0.5
-zoom out, 
mouthPucker - 0.98
-zoom in

mouthDimpleRight/mouthDimpleLeft - 0.7
-item selection
mouthRight/mouthLeft - 0.7
-component selection

eyeLookOutRight/eyeLookInLeft - maybe dont use
eyeLookOutLeft/eyeLookInRight - maybe dont use 

Enough to start.  

**web/public/test/sensors/gesture/index.html
--getFaceActions
This seems to work ok.  


**web/public/book.html
Have some performance issues.  
Need to check why we are getting memory crashes after page is active for long idle period.  

How do we generate a dependency graph for the code?  
#https://github.com/cytoscape/cytoscape.js?tab=readme-ov-file

already using this
#https://visjs.github.io/vis-network/examples/

Really want text representation first.  
#https://visjs.github.io/vis-network/docs/network/#importDot
hmmm.. DOT representation, dont really like this, but seems to be common.  

Yeah this is probably the way to go to start.  
#https://visjs.github.io/vis-network/examples/network/data/dotLanguage/dotPlayground.html

**web/public/test/testfilbert.html
**web/public/test/testacorn.html
Can we use this struct to generate a DOT graph?  

Yeah, lets do this.  
Not sure these are best libraries, but should be ok.  

BOOK -> PAGE 
**web/public/page.html
generate dot graph from AST and display with visjs.  
Not sure if it will be very useful or not, but..

Try Full ES6
Show full code interaction and dependencies.  
Eventually PAGE dependency graph.  
But for now just select and open new PAGE.  
and interact with graph using gestures.  

**web/public/page.html
Minimal LLM + speech
Move Chat portion to module.  

**web/public/chat.mjs
Also need HTML table UI generation in this module ideally.  
So many annoying things still in coding.  

Need transcript module.  


Make module for midi.js next.  
speech, midi, llm set.  
add this to page.  

Only one LLM loaded in all active pages.  
Use pipes to check/load if necessary.  
Have ability to utilize multiple different LLM?  

Also speech output needs to be singleton.  

**web/public/pipes.js
Need to have ontabactivate function to know which is the latest page
and use this to build the context.  

eventually perhaps MIDI can indicate which tab to utilize.  

rec should be recording in any case.  

**web/public/rec.html
Is there a way to create highlight box on the recorded screen instead of the webpage?  
This would be useful, then the tab doesnt need to be active.  

**web/public/db.js
--recDB getRecent
continue.  
?id=name

Dexie quite finnicky.  

**web/public/midi.mjs
Add MIDI controller as ES6 module.  
#cursor.ai
I think I need to go ahead and give this a real try.  
Pretty impressive if this module actually works.  

Lets use side-by-side for now with standard VSCode.  

Hmm, not perfect, but maybe useful.  
--getReferenceTime
Should be somewhere else?  

OK, kind of works.  
Now integrate with keymap and language.  
Really need to rewrite keymap.  


**web/public/languages.js
have to untangle midiarray
make this and currentmidiuser global?  
This is easiest.  

**web/public/globals.js
Lots of changes...
Maybe this is ok to keep this.  
Kind of hacky at the moment trying to change to ES6.  
Feel this is good to do, but causing lots of annoying problems.  
Still way too much base UI and code needed to use default functionality of midi/speech/LLM.  

globals.js added, but CHAT/SPEECH/MIDI changed to MJS.  
Good enough for now.  
No need to change others.  
**web/public/book.html
**web/public/analyze.html
Switch book.html and analyze.html to use these eventually.  


**ROLI
Some problem with recognition of the device, not sure what is causing.  
Seems when it activates Bluetooth, we have an issue.  


**web/public/page.html
Add code analysis.  
with dot.  
#https://visjs.github.io/vis-network/examples/network/data/dotLanguage/dotPlayground.html

**web/public/test/testfilbert.html
**web/public/test/testacorn.html


**web/public/netgraph.mjs
Hmmm, cursor helped some, but not sure how much...


#claude-sonnet3.7
try to use in copilot.  
Hmm, much better integration in cursor.  
Why...

Need #topicstatus, #topicdirtree in UI. 

**web/public/page.html
?codefile=/web/public/page.html
--ok works a bit.  
Now parse and adjust graph display.  
manage context, but use function calls as contenxt.  

#cursor.ai
autocomplete off?? 
come on...

Should we try to use the v6 codemirror.  
So many annoying things to do.  

#https://docs.github.com/en/search-github/searching-on-github/searching-for-repositories

**web/public/git.js
--getGitContents 
Need to pull from DB if exists, and put in DB if admin.  
also with 


**git/clone.py
test this are we cloning repo?  
Then go through the repo and upload to DB.  
all flag allows to upload the repo.  
This updates ALL repos and ALL books (for now only 1).  
> python ./git/clone.py --all "true"


**web/public/db.js

Eventually need to add tags here.  
Be able to do label like search for tags.  
Should keep all tags in local DB and have autocomplete?  
/tags/[tag] 
Keep this structure.  
But need to keep under video entries, as well as git entries.  

**web/public/page.html
Need to add tags to the UI.  
And finish the backend logic for adding tag.  
Add to local DB for now.  
And do all searching on local DB.  
Eventually search across nodes.  

**web/public/db.js
--codeGraphDB

**web/public/git.js
--gitGetReferences()
continue here.  

**git/clone.py
--Test with all flag.  

**web/public/book.html
**web/public/page.html
Move shared functions 
--getVideoJson
--getTime
--getIterations
--addMe
--transcript functions.  


add video to page.html

**claude-3.5
Why is there no WASM version of this to use?  

Can we use this
**web/public/test/web-llm/test.js
**web/public/models/DeepSeek-R1-Distill-Qwen-1.5B-q4f16_1-MLC-webgpu.wasm
Large model loads, but too much time and memory, crashes...

How do we annotate feedback for the comment.  
Well usually this is in the next question.  

So we should rate the subsequent questions whether they are good or not.  
Can this be automated?  
Why not with language.  This is what people are doing already.  
Tell the machine what was less optimal etc.  

So we do need the question response chain.  
Is that enough?  
Also we should just use one td.  

Just have the same thing as feedback.  
We have timing.  Then in the transcript we include the answer as well.  
We can save the feedback or not.  

This can become quite large.  
This is a lot of software just to collect the data.  
Eventually we need to generate the model.  
Based on this input chain.  


**web/public/page.html
so when we save feedback, put the chathistory in the feedback somewhere along with the rating.  
need a save feedback button.  
this time implement feedback save in localDB and remote.  

--From time to time, make sure new user will still work.  

Need search component for topics/videos.  
Search recent videos with certain topic or tag.  

#https://github.com/googlecreativelab/teachable-machine-v1?tab=readme-ov-file
#https://github.com/googlecreativelab/teachable-machine-boilerplate

**web/public/test/tfjs/index.html
--simple classifier.  
How to integrate this?  
onload use the feedback to load classifier for word.  
Right now classify the image, but can also classify the audio.  
Then show the prediction of the classification for the video being shown.  
This is essentially what we need for 
**0606

Then we can use the classifier to identify events which we did not tag in new videos.  
By using the training from other videos using the same language.  
Can we detect all the individual keys being pressed in the videos?  
Maybe try this first.  How close can we get to the actual midi?  
Show the actual midi sequence next to the prediction sequence.  
--PianoClassifier
--FacialClassifier



**web/public/analyze.html

Save these locally for now, and load on load of analyze.html all classifiers for that TOPIC.  
Maybe just add the frames sequentially vertically for now and do image classification.  
10 images or whatever based on FPS.  

Then we would need to classify.  

Lets just do a video capture test.  
Capture set of sequences of piano area.  
and classify as good/bad/ok....
Is this accurate?  
Can this detect actual preference?  
Compare actual preference with predicted preference.  

During capture we should save the image and classification.  
to local DB, then on load, we get these classifications by topic.  
Will this be useful?  


So need ([screenshotXY]  array, size) 
predicted by either constant or algorithm i.e. ball detection.  
Should be same size, but maybe not necessary for some use cases.  
For now just add either vertically or horrizontally, depending on which is larger width/height.  
i.e. 300x30 aspect ratio or any aspect ratio >1, combine vertically.  
Otherwise combine horizontally.  

**web/public/video.js
--VideoSnapper
test.  
Will this actually do what we want.  
Have to add the result to status perhaps for now based on current frame?  

-may have broken some things...
many changes.  


**timestep.py
--Add spin up / spin down of backend.  
And wait...
Then we get some transcriptions if there is available hardware at the time of timestep.py

> python ./git/clone.py --all "true"
Why did we want to clone this?  
Easier to search for func names, etc.  
Then no need to search through git API.  
Potential for further in-depth analysis.  
General use of firebase as clone.  
Use API for commits and history.  

--OK, clone to FB DB seems to work ok.  

Now we can load and search within git.js
Download to local and then use search from local indexdb.  

Hmmm, cant use "." in the name.  FirebaseDB limitation.  
Not sure underscore "_" is best substitute.  


**web/public/feedback.js
Kick off the function to save images to DB for ImageClassifier.  

**web/public/video.js
--VideoSnapper

put into classifierDB
lang/word -> image data.  
Do we want separate classifier for each language, I think yes.  
How do we save/load the model.  
Then we dont have to store all the images and regenerate the model each time.  


Perhaps use the same classifier to make a timeMap.  
what is the most likely location in the topic iteration based on image.  
MIDI will be better to detect this, but could play with video first.  
Can use same 10 key frames etc.  


**web/public/page.html
Allow for traversal through graph.  
Update Code Window and book window.  
For now get recent videos as well.  

Depending too much perhaps on indexdb.  
But it is so convenient...

**web/public/video.js
**web/public/feedback.js
maybe adding of image class is working.  

**FLOW
--rec
--analyze
->
--book
--page

In comments, need to have open book, open page...
Use pipes to communicate actions.  
onfocus send message.  

REC ~ 400GB/year
CLASS ~ 100GB/year

Too much for current PC iterations.  
But fine in a few years.  

Really should use better STT engine for speech.js


Need search in book.  
Need list REF.  

#https://whisper.ggerganov.com/talk/

#https://github.com/ggerganov/whisper.cpp/blob/master/examples/whisper.wasm/index-tmpl.html

Yeah lets use part of this for TTS and then 
#https://github.com/lxe/wasm-gpt?tab=readme-ov-file

**web/public/test/whisper/testwhisper.html

Perhaps switch speech.js to use this.  

**web/public/models/whisper
add some old original models.  

Ugh....
#https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/SharedArrayBuffer#security_requirements

        self.send_header('Cross-Origin-Embedder-Policy', 'require-corp')
        self.send_header('Cross-Origin-Opener-Policy', 'same-origin')

**web/firebase.json
Add COOP policy.  

#https://stackoverflow.com/questions/79406943/using-whisper-cpp-in-sveltekit
yep, same.  

Ugh...
Save for later... hopefully someone answers.




**web/public/video.js
**web/public/feedback.js
maybe adding of image class is working.  
Add UI to select class instance and display.  
in future, perhaps annotate...


**web/public/news.html
**news.py
Read BOOK and check for which of the REFs contain RSS feeds.  
#https://stackoverflow.com/questions/79406943/using-whisper-cpp-in-sveltekit
would need to go here:
#https://stackoverflow.com/feeds/question/79406943

If they do, check periodically, or in news.html if these pages have updates until there is a resolved marker in BOOK.  

Need to be able to adjust generation speed for any input/output.  
Or at least provide feedback regarding preferred speed.  

Or just download content and summarize latest responses from content. 
Not optimal.  


**web/public/analyze.html
Need to add tabs to this.  
Tab for reviewing topic images.  
Lets just review the image when clicking


**web/public/book.html

Need to put copy link in the chat table.  

On loadTopic, should we automatically kick of LLM question?  

Dont upload models.  
Too large for git.  

