#https://towardsdatascience.com/speech-recognition-with-timestamps-934ede4234b2
#pip install youtube_transcript_api #this is just for the transcript stuff that is there generated by google.  
#pip install vosk
#pip install ffmpeg
#choco install ffmpeg
#pip install moviepy
#pip install pydub
#pip install speechrecognition
#pip install pytube
#pip install openai-whisper
#https://alphacephei.com/vosk/models
import wave
import json
import moviepy.editor as mp
from vosk import Model, KaldiRecognizer, SetLogLevel
import Word as custom_Word
from pydub import AudioSegment
from os import path
import subprocess
import glob
import os
import speech_recognition as sr
import math
import requests
import util
import io


def get_timestamp(s):
    mins = math.floor(s/60)
    secs = math.floor(s - mins*60)
    filler = ""
    if secs < 10:
        filler = "0"
    return str(mins) + ":" + filler + str(secs)
    

def transcribe_fromyoutube(videoid="ZshYVeNHkOM"):

    from pytube import YouTube
    youtube_video_url = "https://www.youtube.com/watch?v=" + videoid
    youtube_video_content = YouTube(youtube_video_url)

    for stream in youtube_video_content.streams:
        print(stream)

    audio_streams = youtube_video_content.streams.filter(only_audio = True)
    for stream in audio_streams:
        print(stream)

    audio_stream = audio_streams[1]
    print(audio_stream)

    audio_stream.download("output/" + videoid)
    list_of_files = glob.glob('c:/devinpiano/music/output/' + videoid + '/*') # * means all if need specific format then *.csv
    latest_file = max(list_of_files, key=os.path.getctime)
    print(latest_file)
    text, times = transcribe_whisper(latest_file)
    f = open("output/" + videoid + ".txt", "w")
    for i in range(len(text)):
        print(times[i])
        print(text[i]) 
#        f.write(times[i] + '\n')
        f.write(text[i] + ' (' + times[i] + ')\n')
    f.close()
    with open("output/" + videoid + ".txt", 'r') as file:
        data = file.read()
        return data



def transcribe_whisper(filename = "C:\\devinpiano\\test\\openai-whisper\\test.mp4"):
    import whisper
    import pandas as pd
    from datetime import datetime

    print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))

    model = whisper.load_model("medium")

    print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))

    result = model.transcribe(filename)
    print(result["text"])

    print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))

    speech = pd.DataFrame.from_dict(result['segments'])
    speech = speech.dropna()
    #speech['id'], 'start', 'end', 'text', 'tokens', 'no_speech_prob'
#    print(speech.head())

    text = []
    times = []
    for ind in speech.index:
        print(speech['text'][ind])
        print(speech['start'][ind])
        text.append(speech['text'][ind]) 
        times.append(get_timestamp(speech['start'][ind])) 

    return text, times
#    audio = whisper.load_audio("C:/devinpiano/testing/openai-whisper/content/harvard.wav")
#    audio = whisper.pad_or_trim(audio)


    #mel = whisper.log_mel_spectrogram(audio).to(model.device)

    #_, probs = model.detect_language(mel)
    #probs
    #print(f"Detected language: {max(probs, key=probs.get)}")


def transcribe_me2(description, filename, mediafile, localserver, videoid):
    fn = filename.split('.')
    txt_filename = fn[0] + ".txt"

    #should be able to use both https or http, too annoying to address now.  
    #why does this video fail?  jRpisYQZmjU now set to null.  

    #add start and end times here for what we want to use for speech generation.  
    #use mediafile to download if this is not stored on youtube.  
    util.getIterations(description)
    #pass st and et to allow for creating wav files for voice generation.  
    #need a userid as well so that we can generate multiple voices.  
    #this userid should be added to the description when recording.  
    print(util.st)
    print(util.et)
    sta = ",".join(str(s) for s in util.st)
    eta = ",".join(str(e) for e in util.et)
    params = [('videoid', videoid),('st',sta),('et',eta),('mediafile',mediafile)]
#                    url = f'{localserver}/transcribe/?videoid={videoid}&mediafile={mediafile}&st={sta}&et={eta}'
    url = f'{localserver}/transcribe/'
    print(url)
    try:
#                        transcript = requests.get(url, timeout=(30, None)).text
        transcript = requests.get(url, params=params, timeout=(300, None)).text
        if (transcript is not None and transcript !="error"):
            #why are we having issues with the google blob.  It shows funny if you view it indivuidually with the link.  
            f = io.open(txt_filename, "w", encoding='utf-8')
            f.write(transcript)
            f.close()
#            f = open(txt_filename, "w")
#            f.write(transcript)
#            f.close()
            print('transcript for ' + videoid + ' written to ' + txt_filename)
            return txt_filename
        else:
            print('transcript error' + videoid)
            print(url)
            print(params)
            return None
    except requests.exceptions.RequestException as e:
        print('error using transcript service' + videoid)
        print(e)
        return None



def transcribe_me(filename):
    fn = filename.split('.')

    my_clip = mp.VideoFileClip(filename)

    temp_file = fn[0] + ".mp3"
    my_clip.audio.write_audiofile(temp_file)

    #subprocess.call(['ffmpeg', '-i', temp_file + ".mp3",
    #                   temp_file + ".wav"])

    audio_filename = fn[0] + ".wav"
    txt_filename = fn[0] + ".txt"

    sound = AudioSegment.from_mp3(temp_file)
    sound.export(audio_filename, format="wav")
    audio = AudioSegment.from_file(audio_filename, format="wav", frame_rate=44100)
    audio = audio.set_channels(1)
    audio = audio.set_frame_rate(16000)
    audio.export(audio_filename, format="wav")    
    
    #this is much more accurate but has no timestamps.  
    r = sr.Recognizer()
    test = sr.AudioFile(audio_filename)
    audio_length = audio.duration_seconds
    print(audio_length)
    segment_length = 20
    number_of_iterations = int(audio_length/segment_length)
    audior = []
    text = []
    times = []
    testing = False
    if testing==False:
        for i in range(number_of_iterations):
            with test as source:
                audior.append(r.record(source, offset=i*segment_length, duration=segment_length))
        for i in range(number_of_iterations):
            print(audior[i])
            try:
                text.append(r.recognize_google(audior[i], show_all=False)) 
                times.append(get_timestamp(i*segment_length))
                #print(text) 
            except Exception as e:
                print(e)
    else:
         text, times = transcribe_whisper(audio_filename)           

    f = open(txt_filename, "w")
    for i in range(len(text)):
        print(times[i])
        print(text[i]) 
#        f.write(times[i] + '\n')
        f.write(text[i] + ' (' + times[i] + ')\n')
    f.close()
    vosk = """
    model_path = "../models/vosk-model-en-us-0.22"

    model = Model(model_path)
    wf = wave.open(audio_filename, "rb")
    rec = KaldiRecognizer(model, wf.getframerate())
    rec.SetWords(True)

    # get the list of JSON dictionaries
    results = []
    # recognize speech using vosk model
    while True:
        data = wf.readframes(4000)
        if len(data) == 0:
            break
        if rec.AcceptWaveform(data):
            part_result = json.loads(rec.Result())
            results.append(part_result)
    part_result = json.loads(rec.FinalResult())
    results.append(part_result)

    # convert list of JSON dictionaries to list of 'Word' objects
    list_of_words = []
    for sentence in results:
        if len(sentence) == 1:
            # sometimes there are bugs in recognition 
            # and it returns an empty dictionary
            # {'text': ''}
            continue
        for obj in sentence['result']:
            w = custom_Word.Word(obj)  # create custom Word object
            list_of_words.append(w)  # and add it to list

    wf.close()  # close audiofile

    # output to the screen
    f = open(txt_filename, "w")
    for word in list_of_words:
        print(word.to_string())
        f.write(word.to_string())
        
    f.close()
    """    
if __name__ == '__main__':
    transcribe_fromyoutube()
    list_of_files = glob.glob('C:/Users/devin/Videos/*.mkv') # * means all if need specific format then *.csv
    latest_file = max(list_of_files, key=os.path.getctime)
    print(latest_file)
    #transcribe_me(latest_file)
#    transcribe_me(r"C:\Users\devin\Videos\2023-02-11 11-23-44.mkv")
