#https://towardsdatascience.com/speech-recognition-with-timestamps-934ede4234b2
#pip install youtube_transcript_api #this is just for the transcript stuff that is there generated by google.  
#pip install vosk
#https://alphacephei.com/vosk/models
import wave
import json

from vosk import Model, KaldiRecognizer, SetLogLevel
import Word as custom_Word

import subprocess


command = "\"input/ffmpeg\" -i C:/test.mp4 -ab 160k -ac 2 -ar 44100 -vn audio.wav"

subprocess.call(command, shell=True)

model_path = "../models/vosk-model-en-us-0.22"
audio_filename = "../audio/speech_recognition_systems.wav"

model = Model(model_path)
wf = wave.open(audio_filename, "rb")
rec = KaldiRecognizer(model, wf.getframerate())
rec.SetWords(True)

# get the list of JSON dictionaries
results = []
# recognize speech using vosk model
while True:
    data = wf.readframes(4000)
    if len(data) == 0:
        break
    if rec.AcceptWaveform(data):
        part_result = json.loads(rec.Result())
        results.append(part_result)
part_result = json.loads(rec.FinalResult())
results.append(part_result)

# convert list of JSON dictionaries to list of 'Word' objects
list_of_Words = []
for sentence in results:
    if len(sentence) == 1:
        # sometimes there are bugs in recognition 
        # and it returns an empty dictionary
        # {'text': ''}
        continue
    for obj in sentence['result']:
        w = custom_Word.Word(obj)  # create custom Word object
        list_of_Words.append(w)  # and add it to list

wf.close()  # close audiofile

# output to the screen
for word in list_of_words:
    print(word.to_string())