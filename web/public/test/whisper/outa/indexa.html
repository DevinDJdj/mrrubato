<!doctype html>
<html lang="en-us">
    <head>
        <title>whisper.cpp : WASM example</title>

        <style>
            .output {
                width: 100%;
                height: 100%;
                margin: 0 auto;
                margin-top: 10px;
                border-left: 0px;
                border-right: 0px;
                padding-left: 0px;
                padding-right: 0px;
                display: block;
                background-color: black;
                color: white;
                font-size: 10px;
                font-family: 'Lucida Console', Monaco, monospace;
                outline: none;
                white-space: pre;
                overflow-wrap: normal;
                overflow-x: scroll;
            }
        </style>

<script src='https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.18.1/moment.min.js'></script>
<script src="/clock.js"></script>        
    </head>
    <body>
        <div id="main-container">
            <table>
                <tr>
                    <td>
                        <div id="clock" 
                        style=	"display: inline-block;
                         font-family: monospace;
                         font-size: 20px;
                         text-align: right;
                         color: lightgray; 
                         border-radius: 10px; 
                         padding: 10px; 
                         background-color: rgba(0, 0, 0, 0.75);">
                        </div>
                        <div id="secondselapsed" 
                            style=	"display: inline-block;
                            font-family: monospace;
                            font-size: 20px;
                            text-align: right;
                            color: lightgray; 
                            border-radius: 10px; 
                            padding: 10px; 
                            background-color: rgba(0, 0, 0, 0.75);">
                        </div>

                        <b>Minimal <a href="https://github.com/ggerganov/whisper.cpp">whisper.cpp</a> example running fully in the browser</b>

                        <br><br>
            
                        Usage instructions:<br>
                        <ul>
                            <li>Load a ggml model file (you can obtain one from <a href="https://ggml.ggerganov.com/">here</a>, recommended: <b>tiny</b> or <b>base</b>)</li>
                            <li>Select audio file to transcribe or record audio from the microphone (sample: <a href="https://whisper.ggerganov.com/jfk.wav">jfk.wav</a>)</li>
                            <li>Click on the "Transcribe" button to start the transcription</li>
                        </ul>
            
                        Note that the computation is quite heavy and may take a few seconds to complete.<br>
                        The transcription results will be displayed in the text area below.<br><br>
                        <b>Important:</b>
                            <ul>
                                <li>your browser must support WASM SIMD instructions for this to work</li>
                                <li>Firefox cannot load files larger than 256 MB - use Chrome instead</li>
                            </ul>
            
                        <b>More examples:</b>
                            <a href="https://whisper.ggerganov.com/">main</a> |
                            <a href="https://whisper.ggerganov.com/bench">bench</a> |
                            <a href="https://whisper.ggerganov.com/stream">stream</a> |
                            <a href="https://whisper.ggerganov.com/command">command</a> |
                            <a href="https://whisper.ggerganov.com/talk">talk</a> |
            
                        <hr>
            
                        <div id="model">
                            Whisper models: <span id="model-whisper-status"></span><br><br>
                            <button id="fetch-whisper-tiny-en"  onclick="loadWhisper('tiny.en')">tiny.en (75 MB)</button>
                            <button id="fetch-whisper-tiny"     onclick="loadWhisper('tiny')">tiny (75 MB)</button>
                            <button id="fetch-whisper-base-en"  onclick="loadWhisper('base.en')">base.en (142 MB)</button>
                            <button id="fetch-whisper-base"     onclick="loadWhisper('base')">base (142 MB)</button>
                            <input type="file" id="whisper-file" name="file" onchange="loadFile(event, 'whisper.bin')" />
                            <br><br>
                            Quantized models:<br><br>
                            <button id="fetch-whisper-tiny-en-q5_1"   onclick="loadWhisper('tiny-en-q5_1')">tiny.en (Q5_1, 31 MB)</button>
                            <button id="fetch-whisper-tiny-q5_1"      onclick="loadWhisper('tiny-q5_1')">tiny (Q5_1, 31 MB)</button>
                            <button id="fetch-whisper-base-en-q5_1"   onclick="loadWhisper('base-en-q5_1')">base.en (Q5_1, 57 MB)</button>
                            <button id="fetch-whisper-base-q5_1"      onclick="loadWhisper('base-q5_1')">base (Q5_1, 57 MB)</button>
                            <span id="fetch-whisper-progress"></span>
                        </div>
            
                        <br>
            
                        <!-- radio button to select between file upload or microphone -->
                        <div id="input">
                            Input:
                            <input type="radio" id="file" name="input" value="file" checked="checked" onchange="changeInput('file')" /> <label for="file">File</label>
                            <input type="radio" id="mic" name="input" value="mic" onchange="changeInput('mic')" /> <label for="mic">Microphone</label>
                        </div>
            
                        <br>
            
                        <div id="input_file">
                            Audio file:
                            <input type="file" id="file" name="file" onchange="loadAudio(event)" />
                        </div>
            
                        <div id="input_mic" style="display: none;">
                            Microphone:
                            <button id="start" onclick="startRecording()">Start</button>
                            <button id="stop" onclick="stopRecording()" disabled>Stop</button>
            
                            <!-- progress bar to show recording progress -->
                            <br><br>
                            <div id="progress" style="display: none;">
                                <div id="progress-bar" style="width: 0%; height: 10px; background-color: #4CAF50;"></div>
                                <div id="progress-text">0%</div>
                            </div>
                        </div>
            
                        <audio controls="controls" id="audio" loop hidden>
                            Your browser does not support the &lt;audio&gt; tag.
                            <source id="source" src="" type="audio/wav" />
                        </audio>
            
                        <hr><br>
            
                        <table>
                            <tr>
                                <td>
                                    Language:
                                    <select id="language" name="language">
                                        <option value="en">English</option>
                                        <option value="ar">Arabic</option>
                                        <option value="hy">Armenian</option>
                                        <option value="az">Azerbaijani</option>
                                        <option value="eu">Basque</option>
                                        <option value="be">Belarusian</option>
                                        <option value="bn">Bengali</option>
                                        <option value="bg">Bulgarian</option>
                                        <option value="ca">Catalan</option>
                                        <option value="zh">Chinese</option>
                                        <option value="hr">Croatian</option>
                                        <option value="cs">Czech</option>
                                        <option value="da">Danish</option>
                                        <option value="nl">Dutch</option>
                                        <option value="en">English</option>
                                        <option value="et">Estonian</option>
                                        <option value="tl">Filipino</option>
                                        <option value="fi">Finnish</option>
                                        <option value="fr">French</option>
                                        <option value="gl">Galician</option>
                                        <option value="ka">Georgian</option>
                                        <option value="de">German</option>
                                        <option value="el">Greek</option>
                                        <option value="gu">Gujarati</option>
                                        <option value="iw">Hebrew</option>
                                        <option value="hi">Hindi</option>
                                        <option value="hu">Hungarian</option>
                                        <option value="is">Icelandic</option>
                                        <option value="id">Indonesian</option>
                                        <option value="ga">Irish</option>
                                        <option value="it">Italian</option>
                                        <option value="ja">Japanese</option>
                                        <option value="kn">Kannada</option>
                                        <option value="ko">Korean</option>
                                        <option value="la">Latin</option>
                                        <option value="lv">Latvian</option>
                                        <option value="lt">Lithuanian</option>
                                        <option value="mk">Macedonian</option>
                                        <option value="ms">Malay</option>
                                        <option value="mt">Maltese</option>
                                        <option value="no">Norwegian</option>
                                        <option value="fa">Persian</option>
                                        <option value="pl">Polish</option>
                                        <option value="pt">Portuguese</option>
                                        <option value="ro">Romanian</option>
                                        <option value="ru">Russian</option>
                                        <option value="sr">Serbian</option>
                                        <option value="sk">Slovak</option>
                                        <option value="sl">Slovenian</option>
                                        <option value="es">Spanish</option>
                                        <option value="sw">Swahili</option>
                                        <option value="sv">Swedish</option>
                                        <option value="ta">Tamil</option>
                                        <option value="te">Telugu</option>
                                        <option value="th">Thai</option>
                                        <option value="tr">Turkish</option>
                                        <option value="uk">Ukrainian</option>
                                        <option value="ur">Urdu</option>
                                        <option value="vi">Vietnamese</option>
                                        <option value="cy">Welsh</option>
                                        <option value="yi">Yiddish</option>
                                    </select>
                                </td>
                                <!-- Slider to select number of threads between 1 and 16 -->
                                <td>
                                    Threads:
                                    <input type="range" id="threads" name="threads" min="1" max="16" value="8" onchange="changeThreads(this.value)" />
                                    <span id="threads-value">8</span>
                                </td>
                                <td>
                                    <button onclick="onProcess(false);">Transcribe</button>
                                </td>
                                <td>
                                    <button onclick="onProcess(true);">Translate</button>
                                </td>
                            </tr>
                        </table>
            
                    </td>
                    <td style="display:none">
                        <video
                        id="my-video"
                        class="video-js"
                        preload="auto"
                        controls
                        width="480"
                        height="264"
                        data-setup="{}"
                        >
                        <p class="vjs-no-js">
                          To view this video please enable JavaScript, and consider upgrading to a
                          web browser that
                          <a href="https://videojs.com/html5-video-support/" target="_blank"
                            >supports HTML5 video</a
                          >
                        </p>
                        </video>
                        <button id="btn_1">listen</button><br>
                              
                    </td>
                    <td>
                        <section id="demos" class="invisible">        
            
                            <h2>Demo: Webcam continuous face landmarks detection</h2>
                            <p>Hold your face in front of your webcam to get real-time face landmarker detection.</br>Click <b>enable webcam</b> below and grant access to the webcam if prompted.</p>
                        
                            <div id="liveView" class="videoView">
                              <button id="webcamButton" class="mdc-button mdc-button--raised">
                                <span class="mdc-button__ripple"></span>
                                <span class="mdc-button__label">ENABLE WEBCAM</span>
                              </button>
                              <div style="position: relative;">
                                <video id="webcam" style="position: abso" autoplay playsinline></video>
                                <canvas class="output_canvas" id="output_canvas" style="position: absolute; left: 0px; top: 0px;"></canvas>
                              </div>
                            </div>
                        </section>
                            <!-- partial -->
                    
                    </td>
                    <td>
                        <div class="blend-shapes" style="height:500px;width:500px;overflow:scroll;">
                            <ul class="blend-shapes-list" id="video-blend-shapes"></ul>
                          </div>                      
                    </td>
                    <td>
                        <div id="detected-face-actions" style="height:500px;width:500px;overflow:scroll;"></div>

                    </td>
                </tr>

            <br>

            <!-- textarea with height filling the rest of the page -->
            <table width="100%">
                <tr>
                    <td>
                        <textarea id="erroutput" class="output" rows="20"></textarea>
                    </td>
                    <td>
                        <textarea id="output" class="output" rows="20"></textarea>
                    </td>
                </tr>
            </table>

            <br><br>

            <div class="cell-version">
                <span>
                    |
                    Build time: <span class="nav-link">Fri Mar 14 10:40:20 2025</span> |
                    Commit hash: <a class="nav-link" href="https://github.com/ggerganov/whisper.cpp/commit/e0f3c9d4">e0f3c9d4</a> |
                    Commit subject: <span class="nav-link">examples : add GGML_USE_CPU=ON flag to whisper.objc (#2880)</span> |
                    <a class="nav-link" href="https://github.com/ggerganov/whisper.cpp/tree/master/examples/whisper.wasm">Source Code</a> |
                </span>
            </div>
        </div>

        <script type="text/javascript" src="helpers.js"></script>
        <script type='text/javascript'>
            // TODO: convert audio buffer to WAV
            function setAudio(audio) {
                //if (audio) {
                //    // convert to 16-bit PCM
                //    var blob = new Blob([audio], { type: 'audio/wav' });
                //    var url = URL.createObjectURL(blob);
                //    document.getElementById('source').src = url;
                //    document.getElementById('audio').hidden = false;
                //    document.getElementById('audio').loop = false;
                //    document.getElementById('audio').load();
                //} else {
                //    document.getElementById('audio').hidden = true;
                //}
            }

            function changeInput(input) {
                if (input == 'file') {
                    document.getElementById('input_file').style.display = 'block';
                    document.getElementById('input_mic' ).style.display = 'none';
                    document.getElementById('progress'  ).style.display = 'none';
                } else {
                    document.getElementById('input_file').style.display = 'none';
                    document.getElementById('input_mic' ).style.display = 'block';
                    document.getElementById('progress'  ).style.display = 'block';
                }
            }

            var WHISPERModule = {
                print: printTextareaResult,
                printErr: printTextarea,
                setStatus: function(text) {
                    printTextarea('js: ' + text);
                },
                monitorRunDependencies: function(left) {
                }
            };

            // web audio context
            var context = null;

            // audio data
            var audio = null;

            // the whisper instance
            var whisper_instance = null;
            var model_whisper = '';

            // helper function
            function convertTypedArray(src, type) {
                var buffer = new ArrayBuffer(src.byteLength);
                var baseView = new src.constructor(buffer).set(src);
                return new type(buffer);
            }

            //
            // load model
            //

            let dbVersion = 1
            let dbName    = 'whisper.ggerganov.com';
            let indexedDB = window.indexedDB || window.mozIndexedDB || window.webkitIndexedDB || window.msIndexedDB

            function storeFS(fname, buf) {
                // write to WASM file using FS_createDataFile
                // if the file exists, delete it
                try {
                    WHISPERModule.FS_unlink(fname);
                } catch (e) {
                    // ignore
                }

                WHISPERModule.FS_createDataFile("/", fname, buf, true, true);

                //model_whisper = fname;

                document.getElementById('model-whisper-status').innerHTML = 'loaded "' + model_whisper + '"!';

                printTextarea('storeFS: stored model: ' + fname + ' size: ' + buf.length);

                document.getElementById('model').innerHTML = 'Model fetched: ' + model_whisper;
            }

            function loadFile(event, fname) {
                var file = event.target.files[0] || null;
                if (file == null) {
                    return;
                }

                printTextarea("loadFile: loading model: " + file.name + ", size: " + file.size + " bytes");
                printTextarea('loadFile: please wait ...');

                var reader = new FileReader();
                reader.onload = function(event) {
                    var buf = new Uint8Array(reader.result);
                    storeFS(fname, buf);
                }
                reader.readAsArrayBuffer(file);

                document.getElementById('fetch-whisper-tiny-en' ).style.display = 'none';
                document.getElementById('fetch-whisper-base-en' ).style.display = 'none';
                document.getElementById('fetch-whisper-tiny'    ).style.display = 'none';
                document.getElementById('fetch-whisper-base'    ).style.display = 'none';

                document.getElementById('fetch-whisper-tiny-en-q5_1'  ).style.display = 'none';
                document.getElementById('fetch-whisper-tiny-q5_1'     ).style.display = 'none';
                document.getElementById('fetch-whisper-base-en-q5_1'  ).style.display = 'none';
                document.getElementById('fetch-whisper-base-q5_1'     ).style.display = 'none';

                document.getElementById('whisper-file'          ).style.display = 'none';
                document.getElementById('model-whisper-status'  ).innerHTML = 'loaded model: ' + file.name;
            }

            function loadWhisper(model) {
                whisperCallback = function(obj){
                    //MyChat or transcribe.  
                    console.log(obj);
                };

                let urls = {
                    'tiny.en': '/models/whisper/ggml-model-whisper-tiny.en.bin',
                    'base.en': '/models/whisper/ggml-model-whisper-base.en.bin',
                    'tiny':     '/models/whisper/ggml-model-whisper-tiny.bin',
                    'base':     '/models/whisper/ggml-model-whisper-base.bin',

                    'tiny-en-q5_1':  '/models/whisper/ggml-model-whisper-tiny.en-q5_1.bin',
                    'tiny-q5_1':     '/models/whisper/ggml-model-whisper-tiny-q5_1.bin',
                    'base-en-q5_1':  '/models/whisper/ggml-model-whisper-base.en-q5_1.bin',
                    'base-q5_1':     '/models/whisper/ggml-model-whisper-base-q5_1.bin',
                };

                let sizes = {
                    'tiny.en':  75,
                    'tiny':     75,
                    'base.en':  142,
                    'base':     142,

                    'tiny-en-q5_1':   31,
                    'tiny-q5_1':      31,
                    'base-en-q5_1':   57,
                    'base-q5_1':      57,
                };

                let url     = urls[model];
                let dst     = 'whisper.bin';
                let size_mb = sizes[model];

                model_whisper = model;

                document.getElementById('fetch-whisper-tiny-en' ).style.display = 'none';
                document.getElementById('fetch-whisper-base-en' ).style.display = 'none';
                document.getElementById('fetch-whisper-tiny'    ).style.display = 'none';
                document.getElementById('fetch-whisper-base'    ).style.display = 'none';

                document.getElementById('fetch-whisper-tiny-en-q5_1'  ).style.display = 'none';
                document.getElementById('fetch-whisper-tiny-q5_1'     ).style.display = 'none';
                document.getElementById('fetch-whisper-base-en-q5_1'  ).style.display = 'none';
                document.getElementById('fetch-whisper-base-q5_1'     ).style.display = 'none';

                document.getElementById('whisper-file'        ).style.display = 'none';
                document.getElementById('model-whisper-status').innerHTML = 'loading model: ' + model;

                cbProgress = function(p) {
                    let el = document.getElementById('fetch-whisper-progress');
                    el.innerHTML = Math.round(100*p) + '%';
                };

                cbCancel = function() {
                    var el;

                    el = document.getElementById('fetch-whisper-tiny-en' ); if (el) el.style.display = 'inline-block';
                    el = document.getElementById('fetch-whisper-base-en' ); if (el) el.style.display = 'inline-block';
                    el = document.getElementById('fetch-whisper-tiny'    ); if (el) el.style.display = 'inline-block';
                    el = document.getElementById('fetch-whisper-base'    ); if (el) el.style.display = 'inline-block';

                    el = document.getElementById('fetch-whisper-tiny-en-q5_1'  ); if (el) el.style.display = 'inline-block';
                    el = document.getElementById('fetch-whisper-tiny-q5_1'     ); if (el) el.style.display = 'inline-block';
                    el = document.getElementById('fetch-whisper-base-en-q5_1'  ); if (el) el.style.display = 'inline-block';
                    el = document.getElementById('fetch-whisper-base-q5_1'     ); if (el) el.style.display = 'inline-block';

                    el = document.getElementById('whisper-file'        ); if (el) el.style.display = 'inline-block';
                    el = document.getElementById('model-whisper-status'); if (el) el.innerHTML = '';
                };

                loadRemote(url, dst, size_mb, cbProgress, storeFS, cbCancel, printTextarea);
            }

            //
            // audio file
            //

            const kMaxAudio_s = 30*60;
            const kMaxRecording_s = 2*60;
            const kSampleRate = 16000;

            window.AudioContext = window.AudioContext || window.webkitAudioContext;
            window.OfflineAudioContext = window.OfflineAudioContext || window.webkitOfflineAudioContext;

            function loadAudio(event) {
                if (!context) {
                    context = new AudioContext({
                        sampleRate: kSampleRate,
                        channelCount: 1,
                        echoCancellation: false,
                        autoGainControl:  true,
                        noiseSuppression: true,
                    });
                }

                var file = event.target.files[0] || null;
                if (file == null) {
                    return;
                }

                printTextarea('js: loading audio: ' + file.name + ', size: ' + file.size + ' bytes');
                printTextarea('js: please wait ...');

                var reader = new FileReader();
                reader.onload = function(event) {
                    var buf = new Uint8Array(reader.result);

                    context.decodeAudioData(buf.buffer, function(audioBuffer) {
                        var offlineContext = new OfflineAudioContext(audioBuffer.numberOfChannels, audioBuffer.length, audioBuffer.sampleRate);
                        var source = offlineContext.createBufferSource();
                        source.buffer = audioBuffer;
                        source.connect(offlineContext.destination);
                        source.start(0);

                        offlineContext.startRendering().then(function(renderedBuffer) {
                            audio = renderedBuffer.getChannelData(0);
                            printTextarea('js: audio loaded, size: ' + audio.length);

                            // truncate to first 30 seconds
                            if (audio.length > kMaxAudio_s*kSampleRate) {
                                audio = audio.slice(0, kMaxAudio_s*kSampleRate);
                                printTextarea('js: truncated audio to first ' + kMaxAudio_s + ' seconds');
                            }

                            setAudio(audio);
                        });
                    }, function(e) {
                        printTextarea('js: error decoding audio: ' + e);
                        audio = null;
                        setAudio(audio);
                    });
                }
                reader.readAsArrayBuffer(file);
            }

            //
            // microphone
            //

            var mediaRecorder = null;
            var doRecording = false;
            var startTime = 0;
            var stopTime = 0;

            function stopRecording() {
                doRecording = false;
                stopTime = Date.now();
            }

            // record up to kMaxRecording_s seconds of audio from the microphone
            // check if doRecording is false every 1000 ms and stop recording if so
            // update progress information
            function startRecording() {
                if (!context) {
                    context = new AudioContext({
                        sampleRate: kSampleRate,
                        channelCount: 1,
                        echoCancellation: false,
                        autoGainControl:  true,
                        noiseSuppression: true,
                    });
                }


                document.getElementById('start').disabled = true;
                document.getElementById('stop').disabled = false;

                document.getElementById('progress-bar').style.width = '0%';
                document.getElementById('progress-text').innerHTML = '0%';

                doRecording = true;
                startTime = Date.now();

                var chunks = [];
                var stream = null;

                navigator.mediaDevices.getUserMedia({audio: true, video: false})
                    .then(function(s) {
                        stream = s;
                        mediaRecorder = new MediaRecorder(stream);
                        mediaRecorder.ondataavailable = function(e) {
                            chunks.push(e.data);
                        };
                        mediaRecorder.onstop = function(e) {
                            var blob = new Blob(chunks, { 'type' : 'audio/ogg; codecs=opus' });
                            chunks = [];

                            document.getElementById('start').disabled = false;
                            document.getElementById('stop').disabled = true;

                            var reader = new FileReader();
                            reader.onload = function(event) {
                                var buf = new Uint8Array(reader.result);

                                context.decodeAudioData(buf.buffer, function(audioBuffer) {
                                    var offlineContext = new OfflineAudioContext(audioBuffer.numberOfChannels, audioBuffer.length, audioBuffer.sampleRate);
                                    var source = offlineContext.createBufferSource();
                                    source.buffer = audioBuffer;
                                    source.connect(offlineContext.destination);
                                    source.start(0);

                                    offlineContext.startRendering().then(function(renderedBuffer) {
                                        audio = renderedBuffer.getChannelData(0);
                                        printTextarea('js: audio recorded, size: ' + audio.length);

                                        // truncate to first 30 seconds
                                        if (audio.length > kMaxRecording_s*kSampleRate) {
                                            audio = audio.slice(0, kMaxRecording_s*kSampleRate);
                                            printTextarea('js: truncated audio to first ' + kMaxRecording_s + ' seconds');
                                        }
                                        setAudio(audio);
                                    });
                                }, function(e) {
                                    printTextarea('js: error decoding audio: ' + e);
                                    audio = null;
                                    setAudio(audio);
                                });
                            }

                            reader.readAsArrayBuffer(blob);
                        };
                        mediaRecorder.start();
                    })
                    .catch(function(err) {
                        printTextarea('js: error getting audio stream: ' + err);
                    });

                var interval = setInterval(function() {
                    if (!doRecording) {
                        clearInterval(interval);
                        mediaRecorder.stop();
                        stream.getTracks().forEach(function(track) {
                            track.stop();
                        });
                    }

                    document.getElementById('progress-bar').style.width = (100*(Date.now() - startTime)/1000/kMaxRecording_s) + '%';
                    document.getElementById('progress-text').innerHTML = (100*(Date.now() - startTime)/1000/kMaxRecording_s).toFixed(0) + '%';
                }, 1000);

                printTextarea('js: recording ...');

                //get rid of max size, this was causing problems in continuous recording.  
                /*
                setTimeout(function() {
                    if (doRecording) {
                        printTextarea('js: recording stopped after ' + kMaxRecording_s + ' seconds');
                        stopRecording();
                    }
                }, kMaxRecording_s*1000);
                */
            }

            //
            // transcribe
            //

            var nthreads = 8;

            function changeThreads(value) {
                nthreads = value;
                document.getElementById('threads-value').innerHTML = nthreads;

            }


            function whisperStart(){
                whisper_instance = WHISPERModule.init('whisper.bin');
                if (!whisper_instance) {
                    printTextarea('js: failed to initialize whisper');
                    return;
                } else {
                    console.log('js: initialized whisper instance: ' + whisper_instance);
                }

            }
            function onProcess(translate) {

                if (!whisper_instance) {
                    // try to initialize whisper if it was not initialized yet
                    whisperStart();
                }
                
                if (!whisper_instance) {
                    printTextarea("js: failed to initialize whisper");
                    return;
                }

                if (!audio) {
                    printTextarea("js: no audio data");
                    return;
                }

                if (whisper_instance) {
                    printTextarea('');
                    printTextarea('js: processing - this might take a while ...');
                    printTextarea('');

                    setTimeout(function() {
                        var ret = WHISPERModule.full_default(whisper_instance, audio, document.getElementById('language').value, nthreads, translate);
                        console.log('js: full_default returned: ' + ret);
                        if (ret) {
                            printTextarea("js: whisper returned: " + ret);

                        }
                        //whisper_instance = null;
                    }, 100);
                }
            }
        </script>



<script type="module" id="main">


let url = "https://storage.googleapis.com/misterrubato-test.appspot.com/videos/2025/2025-03-11%2011-45-29.mp4"


const audioContext = new (window.AudioContext || window.webkitAudioContext)();
const audioSrc =
  "https://davidalbertoadler.com/assets/audio/dope-drum-loop_C_major.wav";

let source = null;  
//const audioData = await fetchAudio(audioSrc);

//*********TEST******
//testing for decoding remote audio file.  
//const audioData = await fetchAudio(url);
//audioContext.decodeAudioData(audioData, onDecoded, onDecodeError);


function fetchAudio(url) {
  return new Promise((resolve, reject) => {
    const request = new XMLHttpRequest();
    request.open("GET", url, true);
    request.responseType = "arraybuffer";
    request.onload = () => resolve(request.response);
    request.onerror = (e) => reject(e);
    request.send();
  });
}

function onDecoded(audioBuffer) {
  // Play the song
/*  
  console.log("Got the decoded buffer now play the song", audioBuffer);
  source = audioContext.createBufferSource();
  source.buffer = audioBuffer;
  source.connect(audioContext.destination);
  source.loop = true;
*/


    //var offlineContext = new OfflineAudioContext(audioBuffer.numberOfChannels, audioBuffer.length, audioBuffer.sampleRate);
    var offlineContext = new OfflineAudioContext(audioBuffer.numberOfChannels, audioBuffer.duration*kSampleRate, kSampleRate);
    var source = offlineContext.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(offlineContext.destination);
    source.start(0);

    offlineContext.startRendering().then(function(renderedBuffer) {
        audio = renderedBuffer.getChannelData(0);
        printTextarea('js: audio recorded, size: ' + audio.length);

        // truncate to first 30 mins?
        if (audio.length > kMaxAudio_s*kSampleRate) {
            audio = audio.slice(0, kMaxAudio_s*kSampleRate);
            printTextarea('js: truncated audio to first ' + kMaxAudio_s + ' seconds');
        }
        setAudio(audio);

    });  

}

function onDecodeError(e) {
  console.log("Error decoding buffer: " + e.message);
  console.log(e);
}

btn_1.onclick = function() {
    var playing = this.textContent.indexOf('listen') < 0;
    if (playing) {
        this.textContent = this.textContent.replace('mute', 'listen');
    } else {
        
        this.textContent = this.textContent.replace('listen', 'mute');
        if (source){
            source.start();
            console.log("starting audio");
        }
    }
}

setTimeout(
    function(){    
        //loadWhisper('tiny.en');
        loadWhisper('base');

    }, 5000
);


//add gesture listener to start/stop.  
//transcribe on stop.  

        </script>
        <script type="text/javascript" src="main.js"></script>



        
        <script type="text/javascript">
            FUNCS = {};    
            //would we call GESTURE.ACT externally for any particular reason?  Probably not...
        </script>
        
      <script type="module">
         import * as GESTURE from "/test/sensors/gesture/script.js"
        FUNCS.enableWebcamButton = document.getElementById("webcamButton");
        //use this to start and stop.  
        let ACT = function(text){
            console.log("gesture detected " + text);
            //start/stop audio.  
            if (text === "select item left"){
                if (source){
                    startRecording();
                    console.log("starting audio");
                }
            } 
            else if (text === "select item right" ){
                if (source && Date.now() - startTime > 1000){ //dont stop immediately
                    stopRecording();
                    
                    FUNCS.GESTURE.stopWebcam();

                    //wait for onProcess to start...
                    setTimeout(
                        function(){    
//                            whisperStart();
//                            FUNCS.GESTURE.startWebcam();

                        }, (Date.now() - startTime)+5000
                    );
                    
                    console.log("stopping audio");
                    console.log("processing audio");

                    //time for webcam to stop... before process.
                    setTimeout(
                        function(){    
                            onProcess(false);
                            setTimeout(
                                function(){
                                    //start recording immediately again.  
                                    //if desired...
                                    startRecording();
                                    //mark start time to coincide with whatever video is being processed.  
                                    console.log("restarting audio recording after processing");
                                }, 1000
                            );


                        }, 1000
                    );
                    //onProcess(false);
                    console.log("audio processed");



                }
            }
            //start/stop video.  
            //start/stop transcription.  
            //etc..
        };
        GESTURE.setGestureCallback(ACT);
        FUNCS.ACT = ACT;

        FUNCS.GESTURE = GESTURE;
        setTimeout(
            function(){    
                GESTURE.createFaceLandmarker();
            }, 5000
        );


      </script>
      

    </body>
</html>
