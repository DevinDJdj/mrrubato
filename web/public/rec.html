<style>
    html, body {
        margin: 0!important;
        padding: 0!important;
        text-align: center;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
        font-size: 1em;
    }

    video {
        border-radius: 5px;
        border: 1px solid black;
    }

    .dropzone {
      box-sizing: border-box;
      width: 100%;
      height: 10em;
      border: 2px dashed #ccc;
      display: flex;
      justify-content: center;
      align-items: center;
      font-size: 24px;
      cursor: pointer;
      padding: 1em;
      margin-bottom: 1em;
    }

    .dropzone.disabled {
      cursor: not-allowed;
    }

    .dropzone.drag-over {
      background-color: pink;
    }

    .image-container img {
      margin-bottom: 10px;
      max-width: 100%;
    }

    textarea {
      width: 100%;
      height: 10em;
      margin-bottom: 20px;
      box-sizing: border-box;
    }

    .full-document-section {
      display: none;
      margin-bottom: 20px;
    }
    label { 
        font-size: 24px; 
        font-weight:bold;
    } 
</style>

<title>REC</title>

<body>
<table>
<tr>
<td>
    <table>
        <tr><td>
        <label for="category">CATEGORY:</label><br/>
        <input type="text" id="category">
        </td><td>
        <label for="category">REC ID:</label><br/>
        <input type="text" id="loadfile">
        </td><td>
        <button id="btn-start-new">---NEW RECORD---</button>
        </td></tr>
        <tr><td>
        <h1>
            REC - 
        </h1>        
        </td></tr>
    </table>
    <h3>SCREEN RECORDING</h3>
    <video id="myrecordfeedback" controls autoplay playsinline width="960" height="540"></video>
<br>
<h3>SCREEN RECORDING control</h3>
<button id="btn-start-recording">Record</button>
<button id="btn-stop-recording" disabled>Stop Recording</button>
<button id="btn-save-local">Save Local</button>
<button id="btn-save-remote">Save Remote</button>
<button id="btn-load-remote" disabled>Load Remote</button>
<button id="btn-set-pat" onclick="setAccessToken()">Set Access Token</button>
<a href="https://wikistage.company.com/plugins/personalaccesstokens/usertokens.action" target="_new"><img src="images/edit.png" height="16px"/></a>
<br>
<label style="color:red" id="statusmessage"></label>

</td>
<td valign="top">
    <table>
        <tr><td>
            <label for="recentsearch">Recent RECs:</label><br/>
            <input type="text" id="recentsearch">
            <button id="btn-recentsearch">Search</button>
            <br/>
            <a href="">&lt;-</a> -Page- <a href="">-&gt;</a>
            <div id="recent" style="height: 300px;width: 300px;overflow:auto;">
        
            </div>            
        </td></tr>
        <td>
            <label for="similarsearch">Similar RECs:</label><br/>
            <input type="text" id="similarsearch">
            <button id="btn-similarsearch">Search</button>
            <br/>
            <a href="">&lt;-</a> -Page- <a href="">-&gt;</a>
        
            <div id="similar" style="height: 300px;width: 300px;overflow:auto;">
        
            </div>            
        </td></tr>
    </table>    
</td>
<td valign="top">
    <h3>SCREENSHOT CONTROL</h3>
    <button id="btn-draw-rect">Rect</button>
    <button id="btn-draw-line">Line</button>
    <button id="btn-draw-text">Text</button>
    <button id="btn-screenshot-wait">Wait</button>
    <button id="btn-screenshot">Take Screenshot</button>
    <button id="btn-screenshot-done">Done</button>
    <label id="captime">OCR Processing</label>
    <div class="image-container" style="height: 100px;overflow:auto;">
        <textarea id="ocr-processing" style="height:50px;" rows="10"></textarea>
    
      </div>
    <canvas id="capturescreen" style='position:relative;' ></canvas>
</td>

</tr>

<tr>
<td>
	<br>
    <div class="words" contenteditable>
		<label for="p">Speaking:</label>
		<input type="text" id="p" name="p">
	</div>
	<br>
	
	<label for="mycomments">Current REC - Voice Transcript:</label>
	<img src="images/edit.png" height="16px" onClick="toggleMyComments();"/>
	<br>
    <textarea id="mycomments" style="height:300px;display:none" rows="30" cols="45"></textarea>
	<div id="mycommentsh" style="height: 300px;overflow:auto;"></div>
</td>
<td>
    <label for="selectedocr">Similar OCR Transcript:</label>
    <div id="selectedocr" style="height: 300px;width: 300px;overflow:auto;">

</td>

<td>
	<label for="ocrtranscript">Current REC - OCR Transcript:</label>
	<img src="images/edit.png" height="16px" onClick="toggleOCRTranscript();"/>
	<br>
    <textarea id="ocrtranscript" style="height:300px;display:none" rows="30" cols="45"></textarea>
	<div id="ocrtranscriptsh" style="height: 300px;overflow:auto;"></div>
</td>
</tr>
</table>

  <p><label>Language: <select id="id_language">
        <option>ENG</option>
      </select></label></p>
  <input type="file" id="fileInput" accept=".pdf,.jpg,.jpeg,.png,.gif" style="display: none;" />
<!--  <div class="dropzone" id="dropzone">
    Drag and drop a PDF, JPG, PNG, or GIF file here or click to select a file
  </div>
  -->
  <div class="full-document-section" id="fullDocumentSection">
    <h2>Full document</h2>
    <textarea class="full-document" id="fullDocument"></textarea>
    <h2>Pages</h2>
  </div>



<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@5/dist/tesseract.min.js"></script>

  <script src="js/ayuda/date.format.js"></script>
  <script src="js/ayuda/RecordRTC.js"></script>
  <script src="js/ayuda/ocr.js"></script>
<script src="js/ayuda/imageeditor.js"></script>
<script src="config.js"></script>

<!-- indexeddb -->
<script src="https://unpkg.com/dexie/dist/dexie.js"></script>
<!-- local search -->
<script type="text/javascript" src="js/flexsearch/flexsearch.bundle.min.js"></script>
<script src="db.js"></script>

<script>

function loadAll(){
    recDB = new recDB();
    recDB.loadFTS();
   
}

loadAll();

function setAccessToken(){
    var x;
    var pat=prompt("Your Access Token Please ", accesstoken);
    if (pat!=null){
        accesstoken = pat;
       x="Access Token set " + pat;
       localStorage.setItem("pat", pat);
      alert(x);
   }

}

function getUser(pat){
	var fd = new FormData();
    fd.append('op', 'whoami');
    fd.append('pat', accesstoken);
	$.ajax({
		type: 'POST',
		url: '/service.py',
		data: fd,
		processData: false,
		contentType: false,
    }).done(function(response) {
		   console.log(response);
           res = JSON.parse(response);
           console.log(res);
           username = res["username"];
           console.log(username);
	});	

    
}

function getSimilar(text = ""){
    //this searches "startswith" at the moment
    //service.py op=recent


    if (text == ""){
        mysearch = $('#similarsearch').val();
    }
    else{
        //only get the first X words?  
        //from screenshot hopefully is what we want.  
        var lines = text.split("\n"); 
        //take the first 3 lines for now
        mysearch = lines.slice(0,3).join("\n");
//        mysearch = text;
    }

    ftrecs = recDB.getSimilar(mysearch);
        sims = [];
        full = "";
        console.log(ftrecs);

    //order of results here is significant.  
    //need to reorder based on this.  
    imgrecs = [];
    for (i=0; i<ftrecs.length; i++){
        if (typeof(ftrecs[i]) ==="string"){
            imgrecs.push(ftrecs.splice(i,1));
        }
    }

    if (imgrecs.length > 0){
        //img recs if they exist.  
        recDB.getScreenshots(imgrecs).then(recs => {

        full = "";
        for (i=0; i<recs.length; i++){
            reccategory = recs[i]["category"];
            recid= recs[i]["id"];
            recver = recs[i]["version"];

            full += '<a target="_blank" id="rec' + i + '" href="rec.html?cat=' + reccategory + '&id=' + recid + '&ver=' + recver + '&img=0">' + recs[i]["name"] + ' (' + recs[i]["version"] + ')</a><br>';
            
        }
        $('#similar').html(full);
        console.log(recs);

        });

    }
    else{
        //vid recs
        recDB.getVideos(recs).then(recs => {
//            recs.sort((a,b) => b.version - a.version); // b - a for reverse sort
        full = "";
        for (i=0; i<recs.length; i++){
            reccategory = recs[i]["category"];
            recid= recs[i]["id"];
            recver = recs[i]["version"];

            full += '<a target="_blank" id="rec' + i + '" href="rec.html?cat=' + reccategory + '&id=' + recid + '&ver=' + recver + '&img=0">' + recs[i]["name"] + ' (' + recs[i]["version"] + ')</a><br>';
            
        }
        $('#similar').html(full);
        console.log(recs);

        });



    }



    
}


function getRecent(){
    //this searches "startswith" at the moment
    //service.py op=recent

    mysearch = $('#recentsearch').val();
    recDB.getRecent(mysearch).then(recs => {
        full = "";
        for (i=0; i<recs.length; i++){
            reccategory = recs[i]["category"];
            recid= recs[i]["id"];
            recver = recs[i]["version"];

            full += '<a target="_blank" id="rec' + i + '" href="rec.html?cat=' + reccategory + '&id=' + recid + '&ver=' + recver + '&img=0">' + recs[i]["name"] + ' (' + recs[i]["version"] + ')</a><br>';
            
        }
        $('#recent').html(full);
        console.log(recs);

    });


}

var accesstoken = localStorage.getItem("pat");
if (typeof(accesstoken) == 'undefined'){

    setAccessToken();
}

const queryString = window.location.search;
const urlParams = new URLSearchParams(queryString);
const fname = urlParams.get('id');
const category = urlParams.get('cat');
var ver = urlParams.get('ver');
var img = urlParams.get('img');
var croppedImageUrl = null;
console.log(fname);
var now = new Date();

var images = [];
var imageid = 0;
var imageselected = -1;
var username = "";

var sims = [];

if (typeof(img) == 'undefined' || img==null){
}
else{
    imageselected = img;
}

const version = now.format("yyyymmddHHMMss");

if (typeof(category) == 'undefined'){
    category = "Default";
}

if (typeof(fname) == 'undefined'){
    fname = 'test';	
}


document.title = "REC - " + category + " " + fname
document.querySelector('h1').innerHTML = "REC - " + category + " " + fname;
$("#loadfile").val(fname);
$("#category").val(category);


if (typeof(ver) == 'undefined' || ver==null){
    ver = version;
}
else{
    //load local video.  
    loadVideo();
}

getUser(accesstoken);

document.getElementById('btn-start-new').onclick = function() {
    id = $("#loadfile").val();
    cat = $("#category").val();
    var a = document.createElement('a');
    a.href = 'rec.html?cat=' + cat + '&id=' + id;
    a.style='display:none';
    a.click();    
}

//initialize recentsearch
$('#recentsearch').val(fname);

document.getElementById('btn-recentsearch').onclick = function() {
    getRecent();
}
document.getElementById('btn-recentsearch').click();



document.getElementById('btn-similarsearch').onclick = function() {
    getSimilar();
}
//document.getElementById('btn-similarsearch').click();

if(!navigator.getDisplayMedia && !navigator.mediaDevices.getDisplayMedia) {
    var error = 'Your browser does NOT supports getDisplayMedia API.';
    document.querySelector('h1').innerHTML = error;

    document.querySelector('video').style.display = 'none';
    document.getElementById('btn-start-recording').style.display = 'none';
    document.getElementById('btn-stop-recording').style.display = 'none';
    throw new Error(error);
}


function loadPreview(sim){

    console.log(sim);
    mysim = sims[parseInt(sim["id"].replace("sim", ""))];
    f = mysim["id"][0];
    v = mysim["id"][1];
    imgno = mysim["id"][2];

    ocrtext = mysim["ocr"];
    $('#selectedocr').html(ocrtext);
    imgdata = "data:image/png;base64," + mysim["img"];

    const canvas = document.getElementById("capturescreen");
    const context = canvas.getContext("2d");
    var img = new Image();
    img.onload = function() {
        canvas.width = this.width;
            canvas.height = this.height;
        context.drawImage(img, 0, 0, this.width, this.height);
    };
    img.src = imgdata;

    /*
    var fd = new FormData();
    fd.append('op', 'load');
    fd.append('id', f);
    fd.append('ver', v);
	$.ajax({
		type: 'POST',
		url: '/service.py',
		data: fd,
		processData: false,
		contentType: false,

    }).done(function(response) {
		   console.log(response);
           res = JSON.parse(response);
            if (imgno < res["images"].length){
                imgdata = "data:image/png;base64," + res["images"][imgno]["image"]

                const canvas = document.getElementById("capturescreen");
                const context = canvas.getContext("2d");
                var img = new Image();
                img.onload = function() {
                    canvas.width = this.width;
                        canvas.height = this.height;
                    context.drawImage(img, 0, 0, this.width, this.height);
                };
                img.src = imgdata;
            }
             
    });	
    */

}

function loadVideo(){
    //set src of video and get text from service.  
	var fd = new FormData();
    fd.append('op', 'load');
    fd.append('id', fname);
    fd.append('ver', ver);
	$.ajax({
		type: 'POST',
		url: '/service.py',
		data: fd,
		processData: false,
		contentType: false,

    }).done(function(response) {
		   console.log(response);
           res = JSON.parse(response);
            $('#mycomments').val(res["transcript"]);
            $('#mycommentsh').html(makeOCRLinks(makeTimeLinks(res["transcript"])));


            $('#ocrtranscript').val(res["ocr"]);
            $('#ocrtranscriptsh').html(makeOCRLinks(makeTimeLinks(res["ocr"])));

            for (let i=0; i< res["images"].length; i++){
                myimg = {img: "data:image/png;base64," + res["images"][i]["image"], id: parseInt(res["images"][i]["id"])}
                images.push(myimg);
            }
            console.log(images);
            if (imageselected > -1){
                loadOCR(imageselected);
            }
        //load images.  
        //imgElem.setAttribute('src', "data:image/jpg;base64," + baseStr64);
    });	

        //set video src.  
        s = 'uploads/videos/' + fname + '_' + ver + '.mkv'
        var video = document.getElementById("myrecordfeedback");
        video.src = s;
}

function invokeGetDisplayMedia(success, error) {
    var displaymediastreamconstraints = {
        video: {
            displaySurface: 'monitor', // monitor, window, application, browser
            logicalSurface: true,
            cursor: 'always' // never, always, motion
        }
    };

    // above constraints are NOT supported YET
    // that's why overridnig them
    displaymediastreamconstraints = {
        video: true
    };

    if(navigator.mediaDevices.getDisplayMedia) {
        navigator.mediaDevices.getDisplayMedia(displaymediastreamconstraints).then(success).catch(error);
    }
    else {
        navigator.getDisplayMedia(displaymediastreamconstraints).then(success).catch(error);
    }
}

function captureScreen(callback) {
    invokeGetDisplayMedia(function(screen) {
        addStreamStopListener(screen, function() {
            if(window.stopCallback) {
                window.stopCallback();
            }

        });
        callback(screen);
    }, function(error) {
        console.error(error);
        alert('Unable to capture your screen. Please check console logs.\n' + error);
    });
}

function captureCamera(cb) {
    navigator.mediaDevices.getUserMedia({audio: true, video: true}).then(cb);
}

function keepStreamActive(stream) {
    var video = document.createElement('video');
    video.muted = true;
    video.srcObject = stream;
    video.style.display = 'none';
    (document.body || document.documentElement).appendChild(video);
}


//also download transcript after created.  
function autodownload(b){
    var a = document.createElement('a');
	//get parameter
    a.download = fname + "_" + version + ".mkv";
    a.href = window.URL.createObjectURL(b);
    a.textContent = 'Download ready';
    a.style='display:none';
    a.click();    

    //get the transcript and ocrtranscript as well.  
    var comments = 	$('#mycomments').val();
    blob = new Blob([comments], { type: 'text/plain' }),
    anchor = document.createElement('a');

    anchor.download = fname + "_" + version + ".txt";
    anchor.href = (window.webkitURL || window.URL).createObjectURL(blob);
    anchor.dataset.downloadurl = ['text/plain', anchor.download, anchor.href].join(':');
    anchor.click();

    ocrtext = $('#ocrtranscript').val()
    blob = new Blob([ocrtext], { type: 'text/plain' }),
    anchor.download = fname + "_" + version + "_ocr.txt";
    anchor.href = (window.webkitURL || window.URL).createObjectURL(blob);
    anchor.dataset.downloadurl = ['text/plain', anchor.download, anchor.href].join(':');
    anchor.click();
}

var recorder;




document.getElementById('btn-start-recording').onclick = function() {
    this.disabled = true;

captureScreen(function(screen) {
    keepStreamActive(screen);
    captureCamera(function(camera) {
        keepStreamActive(camera);

        screen.width = window.screen.width;
        screen.height = window.screen.height;
        screen.fullcanvas = true;
        
        camera.width = 160;
        camera.height = 120;
        camera.top = screen.height - camera.height - 100;
        camera.left = screen.width - camera.width;
        
        recorder = RecordRTC([screen, camera], {
            type: 'video',
            mimeType: 'video/webm',
            previewStream: function(s) {
                document.querySelector('video').muted = true;
                document.querySelector('video').srcObject = s;
            }
        });

//        recorder.startRecording();

        window.stopCallback = function() {
            window.stopCallback = null;

            recorder.stopRecording(function() {
				var blob = recorder.getBlob();
				var video = document.getElementById("myrecordfeedback");

				video.srcObject = null;
				video.src = URL.createObjectURL(blob);
				video.muted = true;
                [screen, camera].forEach(function(stream) {
                    stream.getTracks().forEach(function(track) {
                        track.stop();
                    });
                });
            });
        };

//        window.timeout = setTimeout(window.stopCallback, 10 * 1000);
	//	window.timeout = setTimeout(window.stopCallback, 10 * 1000);
		document.getElementById('btn-stop-recording').disabled = false;
	//	navigator.mediaSession.setActionHandler('pause', function() { console.log('pause detected') });

		recorder.startRecording();

    });


});



}



var drawFunction = 1;
document.getElementById('btn-draw-rect').click();

var ssdone = false;
var signtool = null;
var drawText = '';

document.getElementById('btn-screenshot').onclick = function() {
    //start screenshot
	video = document.getElementById("myrecordfeedback");
	console.log(video.currentTime);
	mytranscript = checkCommands("screenshot", video);
    if (mytranscript !=''){
    	addComment(mytranscript, getTimeFromSecs(video.currentTime));
    }

};

document.getElementById('btn-screenshot-done').onclick = function() {
    //copy screen.  
    ssdone = false;
    finishScreenshot();

};


document.getElementById('btn-screenshot-wait').onclick = function() {
    document.getElementById('btn-screenshot-done').disabled = false;
    ssdone = false;
};

document.getElementById('btn-draw-line').onclick = function() {
    this.style.border = "3px inset rgb(254, 255, 208)";
    drawFunction = 0;
    document.getElementById('btn-draw-rect').style.border = "3px outset rgb(254, 255, 208)";
    document.getElementById('btn-draw-line').style.border = "3px outset rgb(254, 255, 208)";
};

document.getElementById('btn-draw-rect').onclick = function() {
    this.style.border = "3px inset rgb(254, 255, 208)";
    document.getElementById('btn-draw-line').style.border = "3px outset rgb(254, 255, 208)";
    document.getElementById('btn-draw-text').style.border = "3px outset rgb(254, 255, 208)";
    drawFunction = 1;
};

document.getElementById('btn-draw-text').onclick = function() {
    this.style.border = "3px inset rgb(254, 255, 208)";
    document.getElementById('btn-draw-line').style.border = "3px outset rgb(254, 255, 208)";
    document.getElementById('btn-draw-rect').style.border = "3px outset rgb(254, 255, 208)";
    drawFunction = 2;
};


document.getElementById('btn-stop-recording').onclick = function() {
    this.disabled = true;
    window.stopCallback();
};

document.getElementById('btn-save-local').onclick = function() {
	var blob = recorder.getBlob();

	autodownload(blob);
};

document.getElementById('btn-save-remote').onclick = function() {
    this.disabled = true;
    $('#statusmessage').html('saving to recDB');

	var blob = recorder.getBlob();

	var fd = new FormData();
	var fileOfBlob = new File([blob], fname + '_' + version + '.mkv');
    fd.append('title', fname);
    fd.append('version', version);
    fd.append('cat', $('#category').val());
    fd.append('pat', accesstoken);
	fd.append('file', fileOfBlob);
    fd.append('images', JSON.stringify(images));
	fd.append('mycomments', $('#mycomments').val());
    fd.append('ocrtranscript', $('#ocrtranscript').val());

    recDB.saveVideo(null, $('#category').val(), fname, version, $('#mycomments').val(), blob, null, 
        function(res){
            console.log(res);
            $('#statusmessage').html('saved! ' + fname + ' ' + version + '<br/>');
            for (im of images){
                recDB.saveScreenshot(im["id"], res, im["secs"], im["img"], im["ocr"]);
            }
        }
    );
/*    
	$.ajax({
		type: 'POST',
		url: '/uploadhandler.py',
		data: fd,
		processData: false,
		contentType: false
	}).done(function(data) {
        document.getElementById('btn-save-remote').disabled = false;
		   console.log(data);
           res = JSON.parse(data);
           $('#statusmessage').html('saved! ' + res["fname"] + ' ' + res["version"] + ' retcode: ' + res["retcode"] + '<br/>' + res["cmd"]);


	});	
*/
//	autodownload(blob);
};


document.getElementById('btn-load-remote').onclick = function() {
	loadRemote();
};

function loadRemote(){
	var video = document.getElementById("myrecordfeedback");
	//get remote video and scripts.  
	video.srcObject = null;
	
	var f = $("#loadfile").val();
	console.log(f);
	//
//	video.src = URL.createObjectURL(blob);
	video.muted = true;
}


function addStreamStopListener(stream, callback) {
    stream.addEventListener('ended', function() {
        callback();
        callback = function() {};
    }, false);
    stream.addEventListener('inactive', function() {
        callback();
        callback = function() {};
    }, false);
    stream.getTracks().forEach(function(track) {
        track.addEventListener('ended', function() {
            callback();
            callback = function() {};
        }, false);
        track.addEventListener('inactive', function() {
            callback();
            callback = function() {};
        }, false);
    });
}


var notesarray = [];

var ocrarray = [];

function toggleOCRTranscript(){
	if ($('#ocrtranscript').is(':visible')){
		$('#ocrtranscript').hide();
		$('#ocrtranscriptsh').show();
	}
	else{
		$('#ocrtranscript').show();
		$('#ocrtranscriptsh').hide();
	}
}

function toggleMyComments(){
	if ($('#mycomments').is(':visible')){
		createNotesArray(); //update values of the data.  
		$('#mycomments').hide();
		$('#mycommentsh').show();
	}
	else{
		$('#mycomments').show();
		$('#mycommentsh').hide();
	}
}

function getTime(comment, prevtime=0){
    //in case there is no matches, return prevtime
	const regExp = /\(([^)]+)\)/g;
    const matches = [...comment.matchAll(regExp)].flat();
//    console.log(matches);
	if (matches.length > 0){
        secs = getSecsFromTime(matches[1]);
	    if (secs > 0){
            return secs;
        }
        else{
            return prevtime;
        }
	}
	else{
	    return prevtime;
	}
}

  function getSecsFromTime(time){
	minsec = time.split(":");
	if (minsec == time)
	    return 0;
	console.log(+parseInt(minsec[0])*60 + +parseInt(minsec[1]));
	return +parseInt(minsec[0])*60 + +parseInt(minsec[1]);
	
  }
  
  function seekTo(seconds, v = "")
  {
    player2 = document.getElementById("myrecordfeedback");
    if (player2.readyState > 0){ //HAVE_METADATA
        player2.currentTime = seconds;
    }
  }

  function getTimeFromSecs(secs){
	min = Math.floor(secs/60);
	secs = Math.floor(secs - min*60);
	ret = "";
	if (min < 10){
		ret = "0" + min + ":";
	}
	else{
		ret += min + ":";
	}
	if (secs < 10){
		ret += "0" + secs;
	}
	else{
		ret += secs;
	}
	return ret;
  }
  
function makeTimeLinks(desc){
    desc = desc.replaceAll("\n", "<br>");
//    desc = desc.replace(")", ")<br>");
	const regExp = /\(([^)]+)\)/g;
	regExp2 = /\d+\:\d\d?/g;
    const matches = [...desc.matchAll(regExp2)].flat();
	for (i=0; i<matches.length; i++){
	    secs = getSecsFromTime(matches[i]);
		if (secs > 0){
    		desc = desc.replace(matches[i], '<a href="#" onclick="seekTo(' + secs + ');">' + matches[i] + '</a>');
		}

	}
//    console.log(matches);
	return desc;
}


function loadOCR(ocrnum){
    video = document.getElementById("myrecordfeedback");
    const canvas = document.getElementById("capturescreen");
        const context = canvas.getContext("2d");
    //    canvas.visible = false;
    var img = new Image();
    img.onload = function() {
//        canvas.width = video.clientWidth;
//        canvas.height = video.clientHeight;
//       context.drawImage(img, 0, 0, this.width*(canvas.width/this.width), this.height*(canvas.height/this.height));
       //scaled down but blurry.  Below is actual image size.  
       canvas.width = this.width;
        canvas.height = this.height;
       context.drawImage(img, 0, 0, this.width, this.height);
    };
    idx = images.findIndex(x => x["id"] === parseInt(ocrnum));
    img.src = images[idx]["img"];

    ocrtran =  $('#ocrtranscript').val();
    idx =  ocrtran.indexOf('--OCR' + ocrnum + '--')
    //
    if (idx > -1){
        idx2 = ocrtran.indexOf(")", idx);
        if (idx > -1){
            str = ocrtran.substring(idx+9, idx2);
            str = str.replace("(", "").trim();
            console.log(str)
            $('#captime').html(makeOCRLinks(makeTimeLinks(str)));
        }
    }

//    signtool = new SignTool();
//possibly allow for edit and save after the fact
//not sure we want to do this

}


function makeOCRLinks(desc){
	const regExp = /\(([^)]+)\)/g;
	regExp2 = /--OCR([0-9]+)--/g;
    const matches = [...desc.matchAll(regExp2)];
	for (i=0; i<matches.length; i++){
        desc = desc.replace(matches[i][0], '<a href="#" onclick="loadOCR(' + matches[i][1] + ');">' + matches[i][0] + '</a>');

	}
//    console.log(matches);
	return desc;

}

function getHeightFromTime(t, html=false, ocr=false){
    if (html){
        if (ocr){
            return $('#ocrtranscriptsh')[0].scrollHeight;
        }
        else{
            return $('#mycommentsh')[0].scrollHeight;
        }
    }
    else{
        if (ocr){
            return $('#ocrtranscript')[0].scrollHeight;
        }
        else{
            return $('#mycomments')[0].scrollHeight;
        }
    }
}

function updateNotes(mytime, ocr=false){
    if (ocr){
        var allnotes = "";
        for (i=0; i<ocrarray.length; i++){
            allnotes += ocrarray[i] + "\n";
        }

        $('#ocrtranscript').val(allnotes);
        //add clickable link inside here instead.  
        var height = getHeightFromTime(mytime, false, true);
        $('#ocrtranscript').scrollTop(height);
        $('#ocrtranscriptsh').html(makeOCRLinks(makeTimeLinks(allnotes)));
        height = getHeightFromTime(mytime, true, true);
        $('#ocrtranscriptsh').scrollTop(height);
    }
    else{
        var allnotes = "";
        for (i=0; i<notesarray.length; i++){
            allnotes += notesarray[i] + "\n";
        }

        $('#mycomments').val(allnotes);
        //add clickable link inside here instead.  
        var height = getHeightFromTime(mytime);
        $('#mycomments').scrollTop(height);
        $('#mycommentsh').html(makeOCRLinks(makeTimeLinks(allnotes)));
        height = getHeightFromTime(mytime, true);
        $('#mycommentsh').scrollTop(height);
    }	
}

function createNotesArray(ocr=false){
//also update the new DIV with links.  
    if (ocr){
        allnotes = $('#ocrtranscript').val();
        ocrarray = [];
        const lines = allnotes.split("\n");
        for (i = 0; i< lines.length; i++){
            ocrarray[i] = lines[i];
        }
        console.log(ocrarray);
        //set title
        updateNotes(ocr);
    }
    else{
        allnotes = $('#mycomments').val();
        notesarray = [];
        const lines = allnotes.split("\n");
        for (i = 0; i< lines.length; i++){
            notesarray[i] = lines[i];
        }
        console.log(notesarray);
        //set title
        updateNotes();
    }
}

function addComment(comment, commenttime){
    //find where to splice and then reset the notes
    //notesarray.splice(i, 0, comment);
    createNotesArray();
    i = 0;
    prevtime = 0;
    while (i< notesarray.length && (prevtime=getTime(notesarray[i], prevtime)) <= getSecsFromTime(commenttime)){
        i++;
    }
//	if (i==0) i=1;
    notesarray.splice(i, 0, comment + " (" + commenttime + ") " + username);
    updateNotes(commenttime);
//    updateState(comment, commenttime, notesarray);
    
}



function addOCRComment(comment, commenttime, imageid){
    //find where to splice and then reset the notes
    //notesarray.splice(i, 0, comment);
    createNotesArray(true);
    i = 0;
    prevtime = 0;
    while (i< ocrarray.length && (prevtime=getTime(ocrarray[i], prevtime)) <= getSecsFromTime(commenttime)){
        i++;
    }
//	if (i==0) i=1;
    ocrarray.splice(i, 0, comment + " (" + commenttime + ")\n --OCR" + imageid + "END--" + username + "\n");
    updateNotes(commenttime, true);
//    updateState(comment, commenttime, notesarray);
    
}


function getCroppedImageURL(imgurl, w, h){
    const image = new Image();
image.src = imgurl;

image.onload = () => {
  const canvas2 = document.createElement('canvas');
  const ctx2 = canvas2.getContext('2d');

  // Set the desired dimensions for the cropped area
  const cropX = 0; 
  const cropY = 0;
  const cropWidth = w;
  const cropHeight = h;

  canvas2.width = cropWidth;
  canvas2.height = cropHeight;

  // Draw the cropped portion onto the canvas
  ctx2.drawImage(image, cropX, cropY, cropWidth, cropHeight, 0, 0, cropWidth, cropHeight);

  // Get the data URL of the cropped image
  if (w > 0 && h > 0){
      croppedImageUrl = canvas2.toDataURL();
  }
  // Use the croppedImageUrl as needed (e.g., display it, send it to a server)
  console.log(croppedImageUrl);
//  return croppedImageUrl;
};

}

function finishScreenshot(){
	let secs = video.currentTime;
    video = document.getElementById("myrecordfeedback");
    me = signtool;
    const canvasa = me.canvas;
    const contexta = me.ctx;

    w = canvasa.width;
    h = canvasa.height;
    multiplier = 1;
    if (drawFunction == 1){
        caspectratio = canvasa.width/canvasa.height;
        w = me.currX-me.prevX;
        h = me.currY-me.prevY;
        if (w > 0){
            cw = w;
            ch = h;
            aspectratio = w/h;
            if (aspectratio > caspectratio){
                multiplier = canvasa.width/w;
            }
            else{
                multiplier = canvasa.height/h;
            }
            contexta.drawImage(canvasa, me.prevX, me.prevY, w, h, 0, 0, Math.round(w*multiplier), Math.round(h*multiplier));

            //get just cropped image.  

        }
    }

    imageURL = canvasa.toDataURL();
    croppedImageUrl = null;
    getCroppedImageURL(imageURL, Math.round(w*multiplier), Math.round(h*multiplier));
//    croppedURL = getCroppedImageURL(imageURL, Math.round(w*multiplier), Math.round(h*multiplier))

//    canvasa.width = video.clientWidth;
//    canvasa.height = video.clientHeight;
    var imageObj = new Image();
    imageObj.onload = function(){
        canvasa.width =imageObj.naturalWidth/2;
        canvasa.height =imageObj.naturalHeight/2;
//        canvasa.width = this.naturalWidth;
//        canvasa.height = this.naturalHeight;
//                const canvas = document.getElementById("capturescreen");
//                const context = canvas.getContext("2d");
        contexta.drawImage(imageObj,0,0, imageObj.naturalWidth/2, imageObj.naturalHeight/2); // Or at whatever offset you like
    };
    imageObj.src = imageURL;


//            const context2 = canvasa.getContext("2d");
//            context2.drawImage(video, 0, 0, canvasa.width, canvasa.height);
//            canvas.visible = true;

    canvasa.style.position = "relative";
    canvasa.style.top = "0";
    canvasa.style.left = "0";

    //check this
    (async() => {
        //create new imageURL with just this cropped image.  
        
        text = await processImage(imageURL);
        if (croppedImageUrl !=null){
            text = await processImage(croppedImageUrl);
        }
        console.log(text);
        text = "--OCR" + imageid + "-- (" + getTimeFromSecs(secs) + ")\n" + text;
        scrollpos = getHeightFromTime(secs, true, true);
        myimg = {img: imageURL, ocr: text, id: imageid, height: scrollpos, secs: secs};
        images.push(myimg);
        addOCRComment(text, getTimeFromSecs(secs), imageid);
        imageselected = imageid;
        imageid++;

        getSimilar(text);
//        toggleFullScreen();
    })()

}

function takeScreenshot(video){

    const canvas = document.getElementById("capturescreen");
		const context = canvas.getContext("2d");
    //    canvas.visible = false;
        canvas.width = video.clientWidth*2;
        canvas.height = video.clientHeight*2;
        canvas.style.position = "absolute";
        canvas.style.left = "0";
        canvas.style.top = "100";
        context.drawImage(video, 0, 0, canvas.width, canvas.height);

        signtool = new SignTool();
        setTimeout(function(){
            if (ssdone){
                finishScreenshot();
            }
        }, 10000);

}


function toggleFullScreen(video, fs = true) {
    if (fs){
        video.style.position = "absolute";
        video.style.left = "0";
        video.style.top = "50";
        video.setAttribute('height', '640');
        video.setAttribute('width', '1200');
    }
    else{
        video.style.position = "relative";
        video.style.top = "0";
        video.style.left = "0";
        video.setAttribute('height', '320');
        video.setAttribute('width', '600');

    }
}

function checkCommands(transcript, video){
	let secs = video.currentTime;
	let position = transcript.search(/screenshot/i);
	if (position > -1){
		//take screenshot
        ssdone = true;
        video = document.getElementById("myrecordfeedback");
//        toggleFullScreen(video);
        takeScreenshot(video);
//        toggleFullScreen(video, false);
        return "--OCR" + imageid + "--";
    }
    position = transcript.search(/done/i);
    if (position > -1){
        if (imageselected > -1){
            //t
            const canvas = document.getElementById("capturescreen");
    		const context = canvas.getContext("2d");
            canvas.style.position = "relative";
            canvas.style.top = "50";
            imageselected = -1;
            return '';
        }
    }

    if (drawFunction ==2){
        drawText = transcript;
        signtool.draw();  
        return '';     
    }
    return transcript;
}



var speech = true;


//hack to turn of speech for subsequent windows.  
if (typeof(img) == 'undefined' || img==null){

}
else{
    speech = false;
}


window.SpeechRecognition = window.SpeechRecognition
                || window.webkitSpeechRecognition;

const recognition = new SpeechRecognition();
recognition.interimResults = false;
const words = document.querySelector('.words');
words.appendChild(p);

if (speech){
recognition.addEventListener('result', e => {
    const transcript = Array.from(e.results)
        .map(result => result[0])
        .map(result => result.transcript)
        .join('')

    document.getElementById("p").setAttribute('value', transcript);
	video = document.getElementById("myrecordfeedback");
	console.log(video.currentTime);
	mytranscript = checkCommands(transcript, video);
    if (mytranscript !=''){
    	addComment(mytranscript, getTimeFromSecs(video.currentTime));
    }
	
});
}

if (speech){
    recognition.start();
    recognition.addEventListener('end', recognition.start);
}

</script>

<footer style="margin-top: 20px; text-align: left;"><small id="send-message"></small></footer>
<script src="https://www.webrtc-experiment.com/common.js"></script>

</body>
</html>

